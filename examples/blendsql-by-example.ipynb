{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-26T18:37:06.645077Z",
     "start_time": "2024-10-26T18:37:01.331338Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import partial\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from blendsql.db import Pandas\n",
    "from blendsql.utils import tabulate\n",
    "import blendsql"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BlendSQL by Example\n",
    "\n",
    "This notebook introduces BlendSQL, and some of the usecases it can support. \n",
    "\n",
    "Importantly, the novelty of BlendSQL isn't from the ability to constrain language models according to some regular expression or context-free grammar. We can credit projects like [guidance](https://github.com/guidance-ai/guidance) and [outlines](https://github.com/dottxt-ai/outlines) for that. Instead, the novelty of BlendSQL is its ability to **infer these constraints according to the surrounding SQL syntax** and **closely align generation to the structure of the database**.\n",
    "\n",
    "SQL, as a grammar, has a lot of rules. Just take [this SQLite railroad diagram]() for example. These rules include things like, `IN` statement should be followed by a list of items, `<`, `>`, should contain numerics, but `=` could contain any datatype, etc. We can use these to inform language-model functions, which we call 'ingredients', and denote in double curly brackets (`{{` and `}}`)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21e929ec2204780a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## A Note on Models\n",
    "This demo uses the amazing Azure AI with serverside Guidance integration, described [here](https://github.com/guidance-ai/guidance?tab=readme-ov-file#azure-ai). It allows us to access a Phi-3.5-mini on Azure, and utilize it in a constrained setting (i.e. have it follow a regular expression pattern, interleave text with generation calls, etc.)\n",
    "\n",
    "If you don't have an Azure access key, you can swap out the model below for [any of the other model integrations that BlendSQL supports](https://parkervg.github.io/blendsql/reference/models/models/)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "619f4d7f620a1e6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "To begin, let's set up a local database using `from blendsql.db import Pandas`. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c34ef7a567ec3d81"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eras\n",
      "┌───────────┐\n",
      "│ Years     │\n",
      "├───────────┤\n",
      "│ 1800-1900 │\n",
      "│ 1900-2000 │\n",
      "│ 2000-Now  │\n",
      "└───────────┘\n",
      "People\n",
      "┌────────────────────┬──────────────────────────────────────────────────────┐\n",
      "│ Name               │ Known_For                                            │\n",
      "├────────────────────┼──────────────────────────────────────────────────────┤\n",
      "│ George Washington  │ Established federal government, First U.S. President │\n",
      "│ John Quincy Adams  │ XYZ Affair, Alien and Sedition Acts                  │\n",
      "│ Thomas Jefferson   │ Louisiana Purchase, Declaration of Independence      │\n",
      "│ James Madison      │ War of 1812, Constitution                            │\n",
      "│ James Monroe       │ Monroe Doctrine, Missouri Compromise                 │\n",
      "│ Alexander Hamilton │ Created national bank, Federalist Papers             │\n",
      "│ Sabrina Carpenter  │ Nonsense, Emails I Cant Send, Mean Girls musical     │\n",
      "│ Charli XCX         │ Crash, How Im Feeling Now, Boom Clap                 │\n",
      "│ Elon Musk          │ Tesla, SpaceX, Twitter/X acquisition                 │\n",
      "│ Michelle Obama     │ Lets Move campaign, Becoming memoir                  │\n",
      "│ Elvis Presley      │ 14 Grammys, King of Rock n Roll                      │\n",
      "└────────────────────┴──────────────────────────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "db = Pandas(\n",
    "    {\n",
    "        \"People\": pd.DataFrame(\n",
    "            {\n",
    "               'Name': [\n",
    "                   'George Washington', \n",
    "                   'John Quincy Adams', \n",
    "                   'Thomas Jefferson', \n",
    "                   'James Madison', \n",
    "                   'James Monroe', \n",
    "                   'Alexander Hamilton',\n",
    "                   'Sabrina Carpenter',\n",
    "                   'Charli XCX',\n",
    "                   'Elon Musk',\n",
    "                   'Michelle Obama',\n",
    "                   'Elvis Presley',\n",
    "               ],\n",
    "               'Known_For': [\n",
    "                   'Established federal government, First U.S. President',\n",
    "                   'XYZ Affair, Alien and Sedition Acts',\n",
    "                   'Louisiana Purchase, Declaration of Independence',\n",
    "                   'War of 1812, Constitution',\n",
    "                   'Monroe Doctrine, Missouri Compromise',\n",
    "                   'Created national bank, Federalist Papers',\n",
    "                   'Nonsense, Emails I Cant Send, Mean Girls musical',\n",
    "                   'Crash, How Im Feeling Now, Boom Clap',\n",
    "                   'Tesla, SpaceX, Twitter/X acquisition',\n",
    "                   'Lets Move campaign, Becoming memoir',\n",
    "                   '14 Grammys, King of Rock n Roll'\n",
    "               ]\n",
    "            }\n",
    "        ),\n",
    "        \"Eras\": pd.DataFrame(\n",
    "            {\n",
    "                'Years': [\n",
    "                    '1800-1900',\n",
    "                    '1900-2000',\n",
    "                    '2000-Now'\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "    }\n",
    ")\n",
    "# Print the tables in our database\n",
    "for tablename in db.tables():\n",
    "    print(tablename)\n",
    "    print(tabulate(db.execute_to_df(f\"SELECT * FROM {tablename};\")))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-26T18:37:06.933171Z",
     "start_time": "2024-10-26T18:37:06.644374Z"
    }
   },
   "id": "ce784e49b71969a8"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Define some utility functions to make query execution easier\n",
    "blend = lambda *args, **kwargs: blendsql.blend(*args, **kwargs)\n",
    "blend = partial(\n",
    "    blend, \n",
    "    db=db, \n",
    "    ingredients={blendsql.LLMQA, blendsql.RAGQA, blendsql.LLMMap, blendsql.LLMJoin}, \n",
    "    # This model can be changed, according to what your personal setup is\n",
    "    default_model=blendsql.models.AzurePhiModel(env=\"..\", caching=False),\n",
    "    verbose=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-26T18:37:17.875707Z",
     "start_time": "2024-10-26T18:37:17.700728Z"
    }
   },
   "id": "b9bcd7005a97ebff"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification with 'LLMMap' and GROUP BY', Constrained by a Column's Values\n",
    "Below, we set up a BlendSQL query leveraging the `LLMMap` ingredient. This is a unary function similar to the `LENGTH` or `ABS` functions in standard SQLite. It takes a single argument (a value from a column) and returns a transformed output, which is then assigned to a new column.\n",
    "\n",
    "Below, we set up a language-model function which takes in the values from the `Name` column of the `People` table, and outputs a value *exclusively* selected from the `Eras::Years` column."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e451e810f6f0cf14"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36mExecuting \u001B[96m `{{LLMMap('In which time period did the person live?', 'People::Name', options='Eras::Years')}}`...\u001B[39m\n",
      "\u001B[90mUsing options '['2000-Now', '1900-2000', '1800-1900']'\u001B[39m\n",
      "Making calls to Model with batch_size 5: |\u001B[36m          \u001B[39m| 3/? [00:01<00:00,  1.68it/s]    \n",
      "\u001B[33mFinished LLMMap with values:\n",
      "{\n",
      "    \"Thomas Jefferson\": \"1800-1900\",\n",
      "    \"Charli XCX\": \"2000-Now\",\n",
      "    \"Michelle Obama\": \"1900-2000\",\n",
      "    \"John Quincy Adams\": \"1800-1900\",\n",
      "    \"James Monroe\": \"1800-1900\",\n",
      "    \"Elon Musk\": \"2000-Now\",\n",
      "    \"George Washington\": \"1800-1900\",\n",
      "    \"Alexander Hamilton\": \"1800-1900\",\n",
      "    \"Elvis Presley\": \"1900-2000\",\n",
      "    \"James Madison\": \"1800-1900\"\n",
      "}\u001B[39m\n",
      "\u001B[36mCombining 1 outputs for table `People`\u001B[39m\n",
      "\u001B[36mCreated temp table ce5c_People\u001B[39m\n",
      "\u001B[92mFinal Query:\n",
      "SELECT GROUP_CONCAT(Name, ', ') AS \"Names\",  \"ce5c_People\".\"In which time period did the person live?\"  AS \"Lived During Classification\" FROM \"ce5c_People\" GROUP BY \"Lived During Classification\"\u001B[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────────────────────────────────────────────────────┬───────────────────────────────┐\n",
      "│ Names                                                 │ Lived During Classification   │\n",
      "├───────────────────────────────────────────────────────┼───────────────────────────────┤\n",
      "│ Sabrina Carpenter, Charli XCX, Elon Musk              │ 2000-Now                      │\n",
      "│ Michelle Obama, Elvis Presley                         │ 1900-2000                     │\n",
      "│ George Washington, John Quincy Adams, Thomas Jeffe... │ 1800-1900                     │\n",
      "└───────────────────────────────────────────────────────┴───────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "smoothie = blend(\"\"\"\n",
    "SELECT GROUP_CONCAT(Name, ', ') AS 'Names',\n",
    "{{LLMMap('In which time period did the person live?', 'People::Name', options='Eras::Years')}} AS \"Lived During Classification\"\n",
    "FROM People\n",
    "GROUP BY \"Lived During Classification\"\n",
    "\"\"\")\n",
    "print(smoothie.df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-26T18:37:21.380323Z",
     "start_time": "2024-10-26T18:37:19.429252Z"
    }
   },
   "id": "4d53d9c2de48693f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Constrained Decoding - The Presidents Challenge\n",
    "Why does constrained decoding matter? Imagine we want to select all the information we have in our table about the first 3 presidents of the U.S. \n",
    "In the absence of relevant data stored in our database, we turn to our language model. But one thing thwarts our plans - the language model doesn't know that we've stored the 2nd president's name in our database as `'John Quincy Adams'`, not `'John Adams'`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1be8d0ae27266c3"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36mExecuting \u001B[96m `{{LLMQA('First 3 presidents of the U.S?')}}`...\u001B[39m\n",
      "When inferring `options` in infer_gen_kwargs, encountered a column node with no table specified!\n",
      "Should probably mark `schema_qualify` arg as True\n",
      "\u001B[92mFinal Query:\n",
      "SELECT * FROM People WHERE Name IN  ('George Washington','John Adams','Thomas Jefferson') \u001B[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────────────────┬───────────────────────────────────────────────────────┐\n",
      "│ Name              │ Known_For                                             │\n",
      "├───────────────────┼───────────────────────────────────────────────────────┤\n",
      "│ George Washington │ Established federal government, First U.S. Preside... │\n",
      "│ Thomas Jefferson  │ Louisiana Purchase, Declaration of Independence       │\n",
      "└───────────────────┴───────────────────────────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "smoothie = blend(\"\"\"\n",
    "SELECT * FROM People\n",
    "WHERE Name IN {{LLMQA('First 3 presidents of the U.S?')}}\n",
    "\"\"\")\n",
    "# The final query 'SELECT * FROM People WHERE Name IN  ('George Washington','John Adams','Thomas Jefferson')' only yields 2 rows\n",
    "print(smoothie.df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-26T18:40:45.926562Z",
     "start_time": "2024-10-26T18:40:45.257676Z"
    }
   },
   "id": "ea77a9ee21a00efc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Constrained decoding comes to our rescue. By specifying `options='People::Name'`, we force the generation to only select from values present in the `Name` column - which leads to the expected response."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed4e14cb4135c095"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36mExecuting \u001B[96m `{{LLMQA('First 3 presidents of the U.S?', options='People::Name')}}`...\u001B[39m\n",
      "When inferring `options` in infer_gen_kwargs, encountered a column node with no table specified!\n",
      "Should probably mark `schema_qualify` arg as True\n",
      "\u001B[90mUsing options '{'James Monroe', 'George Washington', 'Thomas Jefferson', 'James Madison', 'John Quincy Adams', 'Michelle Obama', 'Elon Musk', 'Charli XCX', 'Elvis Presley', 'Alexander Hamilton', 'Sabrina Carpenter'}'\u001B[39m\n",
      "\u001B[92mFinal Query:\n",
      "SELECT * FROM People WHERE Name IN  ('George Washington','John Quincy Adams','Thomas Jefferson') \u001B[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────────────────┬───────────────────────────────────────────────────────┐\n",
      "│ Name              │ Known_For                                             │\n",
      "├───────────────────┼───────────────────────────────────────────────────────┤\n",
      "│ George Washington │ Established federal government, First U.S. Preside... │\n",
      "│ John Quincy Adams │ XYZ Affair, Alien and Sedition Acts                   │\n",
      "│ Thomas Jefferson  │ Louisiana Purchase, Declaration of Independence       │\n",
      "└───────────────────┴───────────────────────────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "smoothie = blend(\"\"\"\n",
    "SELECT * FROM People\n",
    "WHERE Name IN {{LLMQA('First 3 presidents of the U.S?', options='People::Name')}}\n",
    "\"\"\")\n",
    "print(smoothie.df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-26T18:38:31.370877Z",
     "start_time": "2024-10-26T18:38:30.816364Z"
    }
   },
   "id": "b59038996327dc7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Constrained Decoding - The Alphabet Challenge\n",
    "\n",
    "In BlendSQL, we can utilize the power of constrained decoding to guide a language model's generation towards the structure we expect. In other words, rather than taking a \"prompt-and-pray\" approach in which we meticulously craft a natural language prompt which (hopefully) generates a list of 3 strings, we can interact with the logit space to ensure this is the case<sup>1</sup>.\n",
    "\n",
    "> [!NOTE]  \n",
    "> These guarantees are only made possible with open models, i.e. where we can access the underlying logits. For closed-models like OpenAI and Anthropic, we rely on prompting (i.e. 'Datatype: List[str]') and make predictions \"optimistically\"\n",
    "\n",
    "To demonstrate this, we can use the `LLMQA` ingredient. This ingredient optionally takes in a table subset as context, and returns either a scalar value or a list of scalars. \n",
    "\n",
    "Since BlendSQL can infer the shape of a valid generation according to the surrounding SQL syntax, when we use the `LLMQA` ingredient in a `VALUES` or `IN` clause, it will generate a list by default."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8563f8913cefc01e"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36mExecuting \u001B[96m `{{LLMQA('What are the first letters of the alphabet?')}}`...\u001B[39m\n",
      "\u001B[92mFinal Query:\n",
      "SELECT * FROM (VALUES ( 'A' ))\u001B[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────┐\n",
      "│ col0   │\n",
      "├────────┤\n",
      "│ A      │\n",
      "└────────┘\n"
     ]
    }
   ],
   "source": [
    "smoothie = blend(\"\"\"\n",
    "SELECT * FROM ( VALUES {{LLMQA('What are the first letters of the alphabet?')}} )\n",
    "\"\"\")\n",
    "print(smoothie.df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-26T18:07:28.939066Z",
     "start_time": "2024-10-26T18:07:28.610558Z"
    }
   },
   "id": "b6e9868188f0c338"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ok, so we were able to generate the first letter of the alphabet... what if we want more? \n",
    "\n",
    "Rather than modify the prompt itself (which can be quite finicky), we can leverage the regex-inspired `modifier` argument. This will take either the strings `'*'` (zero-or-more) or `'+'` (one-or-more), in addition to tighter bounds of `'{3}'` (exactly 3) or `'{1,6}'` (between 1 and 6)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea1ac65d394cf1e0"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36mExecuting \u001B[96m `{{LLMQA('What are the first letters of the alphabet?', modifier='{3}')}}`...\u001B[39m\n",
      "\u001B[92mFinal Query:\n",
      "SELECT * FROM (VALUES ( 'A','B','C' ))\u001B[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────┬────────┬────────┐\n",
      "│ col0   │ col1   │ col2   │\n",
      "├────────┼────────┼────────┤\n",
      "│ A      │ B      │ C      │\n",
      "└────────┴────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "smoothie = blend(\"\"\"\n",
    "SELECT * FROM ( VALUES {{LLMQA('What are the first letters of the alphabet?', modifier='{3}')}} )\n",
    "\"\"\")\n",
    "print(smoothie.df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-26T18:07:32.051570Z",
     "start_time": "2024-10-26T18:07:31.613094Z"
    }
   },
   "id": "5d186b8588d96ac1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "What if we want to generate the letters of a different alphabet? We can use the `options` argument for this, which takes either a reference to another column in the form `'tablename::columnname'`, or a set of semicolon-separated strings."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55e0405c455ecb9"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36mExecuting \u001B[96m `{{LLMQA('What are the first letters of the alphabet?', options='α;β;γ;δ', modifier='{3}')}}`...\u001B[39m\n",
      "\u001B[90mUsing options '{'α', 'δ', 'γ', 'β'}'\u001B[39m\n",
      "\u001B[92mFinal Query:\n",
      "SELECT * FROM (VALUES ( 'α','β','γ' ))\u001B[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────┬────────┬────────┐\n",
      "│ col0   │ col1   │ col2   │\n",
      "├────────┼────────┼────────┤\n",
      "│ α      │ β      │ γ      │\n",
      "└────────┴────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "smoothie = blend(\"\"\"\n",
    "SELECT * FROM ( VALUES {{LLMQA('What are the first letters of the alphabet?', options='α;β;γ;δ', modifier='{3}')}} )\n",
    "\"\"\")\n",
    "print(smoothie.df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-26T18:07:33.886364Z",
     "start_time": "2024-10-26T18:07:33.433520Z"
    }
   },
   "id": "7ffc171b4f97bf75"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Agent-Based Inference with CTE Expressions\n",
    "The above example opens up the opportunity to rewrite the query as more of an agent-based flow. SQL is a bit odd in that it's executed bottom-up, i.e. to execute the following query:\n",
    "```sql\n",
    "SELECT the_answer FROM final_table WHERE final_table.x IN \n",
    "    (SELECT some_field FROM initial_table)\n",
    "```\n",
    "...We first gather `some_field` from `initial_table`, and *then* go and fetch `the_answer`, despite the author (human or AI) having written the second step, first. This is similar to the point made by [Google in the pipe-syntax paper]](https://research.google/pubs/sql-has-problems-we-can-fix-them-pipe-syntax-in-sql/) about how SQL syntactic clause order doesn't match semantic evaluation order.\n",
    "\n",
    "At the end of the day, we have two agents performing the following tasks - \n",
    "1) Brainstorm some greek letters\n",
    "2) Using the output of the previous task, select only the first 3 \n",
    "\n",
    "With BlendSQL, we can use common table expressions (CTEs) to more closely mimic this order of 'agents'."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e9841576ad74398"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36mExecuting \u001B[96m `{{ LLMQA( 'What is the first letter of the alphabet?', options=(SELECT * FROM letter_agent_output) )}}`...\u001B[39m\n",
      "\u001B[36mExecuting `SELECT * FROM (VALUES ({{LLMQA('List some greek letters')}}))` and setting to `letter_agent_output`\u001B[39m\n",
      "\u001B[36mExecuting \u001B[96m `{{LLMQA('List some greek letters')}}`...\u001B[39m\n",
      "\u001B[92mFinal Query:\n",
      "SELECT * FROM (VALUES ( 'alpha','beta','gamma','delta','epsilon','zeta','eta','theta','iota','kappa','lambda','mu','nu','xi','omicron','pi','rho','sigma','tau','upsilon','phi','chi','psi','omega' ))\u001B[39m\n",
      "\u001B[36mCreated temp table letter_agent_output\u001B[39m\n",
      "\u001B[33mNo BlendSQL ingredients found in query:\u001B[39m\n",
      "\u001B[93mSELECT * FROM letter_agent_output\u001B[39m\n",
      "\u001B[33mExecuting as vanilla SQL...\u001B[39m\n",
      "\u001B[90mUsing options '{'mu', 'alpha', 'theta', 'zeta', 'epsilon', 'xi', 'sigma', 'upsilon', 'pi', 'tau', 'phi', 'gamma', 'omega', 'kappa', 'iota', 'delta', 'lambda', 'eta', 'rho', 'chi', 'beta', 'omicron', 'nu', 'psi'}'\u001B[39m\n",
      "\u001B[92mFinal Query:\n",
      "SELECT  'alpha' \u001B[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────────┐\n",
      "│ 'alpha'   │\n",
      "├───────────┤\n",
      "│ alpha     │\n",
      "└───────────┘\n"
     ]
    }
   ],
   "source": [
    "smoothie = blend(\"\"\"\n",
    "WITH letter_agent_output AS (\n",
    "    SELECT * FROM (VALUES {{LLMQA('List some greek letters')}})\n",
    ") SELECT {{\n",
    "    LLMQA(\n",
    "        'What is the first letter of the alphabet?', \n",
    "        options=(SELECT * FROM letter_agent_output)\n",
    "    )}}\n",
    "\"\"\")\n",
    "print(smoothie.df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-26T18:08:40.996473Z",
     "start_time": "2024-10-26T18:08:38.614398Z"
    }
   },
   "id": "ef5ffc11ff592e30"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using `output_type` to Influence Generation\n",
    "BlendSQL does its best to infer datatytpes given surrounding syntax. Sometimes, though, the user may want to override those assumptions, or inject new ones that were unable to be inferred.\n",
    "\n",
    "The `output_type` argument takes a Python-style type annotation like `int`, `str`, `bool` or `float`. Below we use that to guide the generation towards one-or-more integer. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "449a7d3d01dea38b"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36mExecuting \u001B[96m `{{LLMQA('Count up, starting from 1', output_type='int', modifier='+')}}`...\u001B[39m\n",
      "\u001B[90mUsing regex '(\\d{1,18})'\u001B[39m\n",
      "\u001B[92mFinal Query:\n",
      "SELECT * FROM (VALUES ( '1','2' ))\u001B[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────┬────────┐\n",
      "│   col0 │   col1 │\n",
      "├────────┼────────┤\n",
      "│      1 │      2 │\n",
      "└────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "smoothie = blend(\"\"\"\n",
    "SELECT * FROM ( VALUES {{LLMQA('Count up, starting from 1', output_type='int', modifier='+')}} )\n",
    "\"\"\")\n",
    "print(smoothie.df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-26T18:11:02.407373Z",
     "start_time": "2024-10-26T18:11:01.958618Z"
    }
   },
   "id": "658ce9487a5b4485"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RAG for Unstructured Reasoning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75a215007dbff91b"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36mExecuting \u001B[96m `{{ LLMQA( 'Give me a 5-word summary about this person', context=(SELECT Name FROM People WHERE Name = {{LLMQA('Who has a musical by Lin-Manuel Miranda written about them?', options='People::Name')}}) ) }}`...\u001B[39m\n",
      "\u001B[36mExecuting \u001B[96m `{{LLMQA ( 'Who has a musical by Lin-Manuel Miranda written about them?' , options= 'People::Name' ) }}`...\u001B[39m\n",
      "When inferring `options` in infer_gen_kwargs, encountered a column node with no table specified!\n",
      "Should probably mark `schema_qualify` arg as True\n",
      "\u001B[90mUsing options '{'Thomas Jefferson', 'Charli XCX', 'James Madison', 'Sabrina Carpenter', 'Michelle Obama', 'John Quincy Adams', 'James Monroe', 'George Washington', 'Elvis Presley', 'Elon Musk', 'Alexander Hamilton'}'\u001B[39m\n",
      "\u001B[92mFinal Query:\n",
      "SELECT Name AS Name FROM People WHERE Name =  'Alexander Hamilton' \u001B[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: can't backtrack over \"\\n\"; this may confuse the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mFinal Query:\n",
      "SELECT  'Founding Father, Finance Minister |'  AS \"Summary\"\u001B[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────────────────────────────────┐\n",
      "│ Summary                             │\n",
      "├─────────────────────────────────────┤\n",
      "│ Founding Father, Finance Minister | │\n",
      "└─────────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "smoothie = blend(\"\"\"\n",
    "SELECT {{\n",
    "    LLMQA(\n",
    "        'Give me a 5-word summary about this person', \n",
    "        context=(SELECT Name FROM People WHERE Name = {{LLMQA('Who has a musical by Lin-Manuel Miranda written about them?', options='People::Name')}})\n",
    "    )\n",
    "}} AS \"Summary\"\n",
    "\"\"\")\n",
    "print(smoothie.df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-26T18:13:32.235340Z",
     "start_time": "2024-10-26T18:13:31.449936Z"
    }
   },
   "id": "74b6331ba74b95d8"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36mExecuting \u001B[96m `{{LLMQA('Who wrote the song Espresso?')}}`...\u001B[39m\n",
      "\u001B[36mExecuting `SELECT Name AS Name FROM People WHERE {{LLMMap('Is a singer?', 'People::Name')}} = TRUE` and setting to `Musicians`\u001B[39m\n",
      "\u001B[36mExecuting \u001B[96m `{{LLMMap('Is a singer?', 'People::Name')}}`...\u001B[39m\n",
      "When inferring `options` in infer_gen_kwargs, encountered a column node with no table specified!\n",
      "Should probably mark `schema_qualify` arg as True\n",
      "\u001B[90mUsing regex '(t|f)'\u001B[39m\n",
      "Making calls to Model with batch_size 5: |\u001B[36m          \u001B[39m| 3/? [00:01<00:00,  2.29it/s]    \n",
      "\u001B[33mFinished LLMMap with values:\n",
      "{\n",
      "    \"James Madison\": false,\n",
      "    \"Sabrina Carpenter\": true,\n",
      "    \"Elvis Presley\": true,\n",
      "    \"Thomas Jefferson\": false,\n",
      "    \"Charli XCX\": true,\n",
      "    \"Michelle Obama\": false,\n",
      "    \"George Washington\": false,\n",
      "    \"Alexander Hamilton\": false,\n",
      "    \"John Quincy Adams\": false,\n",
      "    \"James Monroe\": false\n",
      "}\u001B[39m\n",
      "\u001B[36mCombining 1 outputs for table `People`\u001B[39m\n",
      "\u001B[36mCreated temp table 79b1_People\u001B[39m\n",
      "\u001B[92mFinal Query:\n",
      "SELECT Name AS Name FROM \"79b1_People\" WHERE  \"79b1_People\".\"Is a singer?\"  = TRUE\u001B[39m\n",
      "\u001B[36mCreated temp table Musicians\u001B[39m\n",
      "\u001B[90mUsing options '{'Elvis Presley', 'Charli XCX', 'Sabrina Carpenter'}'\u001B[39m\n",
      "\u001B[92mFinal Query:\n",
      "SELECT Musicians.Name AS \"Espresso Singer\" FROM Musicians WHERE Musicians.Name =  'Sabrina Carpenter' \u001B[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────────────────┐\n",
      "│ Espresso Singer   │\n",
      "├───────────────────┤\n",
      "│ Sabrina Carpenter │\n",
      "└───────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# A two-step reasoning problem:\n",
    "#   1) Identify who, out of the table, is a singer using `LLMMap`\n",
    "#   2) Where the previous step yields `TRUE`, select the one that wrote the song Espresso.\n",
    "smoothie = blend(\"\"\"\n",
    "WITH Musicians AS \n",
    "(SELECT Name FROM People WHERE {{LLMMap('Is a singer?', 'People::Name')}} = TRUE)\n",
    "SELECT Name AS \"Espresso Singer\" FROM Musicians WHERE Name = {{LLMQA('Who wrote the song Espresso?')}}\n",
    "\"\"\")\n",
    "print(smoothie.df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-26T18:18:09.674511Z",
     "start_time": "2024-10-26T18:18:08.008686Z"
    }
   },
   "id": "1a089867c40ebc41"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Internet-Connected RAG \n",
    "So we know how to use a table subset as a context, by writing subqueries. But what if the knowledge we need to answer a question isn't present in the universe of our table?\n",
    "\n",
    "For this, we have the `RAGQA` ingredient (retrieval-augmented generation question-answering). Currently it only supports Bing via Azure as a source, but the idea is that in the future, it will support more forms of unstructured retrieval. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14c549c0bc8e5563"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's ask a question that requires a bit more world-knowledge to answer."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b18b91327f1a9874"
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36mExecuting \u001B[96m `{{LLMQA(\"Who's birthday is June 28, 1971?\")}}`...\u001B[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: can't backtrack over \"\\n\"; this may confuse the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mFinal Query:\n",
      "SELECT  'Not specified in the context'  AS \"Answer\"\u001B[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────────────────────┐\n",
      "│ Answer                       │\n",
      "├──────────────────────────────┤\n",
      "│ Not specified in the context │\n",
      "└──────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "smoothie = blend(\"\"\"\n",
    "SELECT {{LLMQA(\"Who's birthday is June 28, 1971?\")}} AS \"Answer\"\n",
    "\"\"\")\n",
    "print(smoothie.df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-26T18:22:41.144450Z",
     "start_time": "2024-10-26T18:22:40.678444Z"
    }
   },
   "id": "f1a798ba024c1154"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ok, that's fair.\n",
    "\n",
    "Now let's try again, using constrained decoding via `options` and using the `RAGQA` ingredient to fetch relevant context via a Bing web search first."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b006708b577b4b3"
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36mUnpacked alias `\u001B[96m{{RAGQA(\"Who's birthday is June 28, 1971?\", source='bing', options='People::Name')}}\u001B[36m` to `\u001B[96m\n",
      "{{\n",
      "    LLMQA(\n",
      "        \"Who's birthday is June 28, 1971?\", \n",
      "        (\n",
      "            SELECT {{\n",
      "                BingWebSearch(\"Who's birthday is June 28, 1971?\")\n",
      "            }} AS \"Search Results\"\n",
      "        ), options='People::Name'\n",
      "    )\n",
      "}}\n",
      "`\u001B[39m\n",
      "\u001B[36mExecuting \u001B[96m `{{RAGQA(\"Who's birthday is June 28, 1971?\", source='bing', options='People::Name')}}`...\u001B[39m\n",
      "When inferring `options` in infer_gen_kwargs, encountered a column node with no table specified!\n",
      "Should probably mark `schema_qualify` arg as True\n",
      "\u001B[36mExecuting \u001B[96m `{{ BingWebSearch ( \"Who's birthday is June 28, 1971?\" ) }}`...\u001B[39m\n",
      "\u001B[92mFinal Query:\n",
      "SELECT  '## DOCUMENT 1\n",
      "\n",
      "Elon Reeve Musk was born on June 28, 1971, in Pretoria, South Africa''s administrative capital. [7] [8] He is of British and Pennsylvania Dutch ancestry.[9] [10] His mother, Maye (née Haldeman), is a model and dietitian born in Saskatchewan, Canada, and raised in South Africa.[11] [12] [13] His father, Errol Musk, is a South African electromechanical engineer, pilot, sailor, consultant ...\n",
      "\n",
      "## DOCUMENT 2\n",
      "\n",
      "Weekday: June 28th, 1971 was a Monday. People born on June 28th, 1971 turned 53 this year (2024). Birthdays of famous people, actors, celebrities and stars on June 28th. With 365 days 1971 is a normal year and no leap year.'  AS \"Search Results\"\u001B[39m\n",
      "\u001B[90mUsing options '{'Thomas Jefferson', 'Charli XCX', 'James Madison', 'Sabrina Carpenter', 'Michelle Obama', 'John Quincy Adams', 'James Monroe', 'George Washington', 'Elvis Presley', 'Elon Musk', 'Alexander Hamilton'}'\u001B[39m\n",
      "\u001B[92mFinal Query:\n",
      "SELECT * FROM People WHERE Name =  'Elon Musk' \u001B[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────────┬──────────────────────────────────────┐\n",
      "│ Name      │ Known_For                            │\n",
      "├───────────┼──────────────────────────────────────┤\n",
      "│ Elon Musk │ Tesla, SpaceX, Twitter/X acquisition │\n",
      "└───────────┴──────────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "smoothie = blend(\"\"\"\n",
    "SELECT * FROM People WHERE Name = {{RAGQA(\"Who's birthday is June 28, 1971?\", source='bing', options='People::Name')}}\n",
    "\"\"\")\n",
    "print(smoothie.df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-26T18:23:15.641730Z",
     "start_time": "2024-10-26T18:23:14.521040Z"
    }
   },
   "id": "882c37cb31e10085"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nice! Elon Musk was indeed born on June 28th, 1971. You can check out the BlendSQL logs above to validate this given the web context."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7eb6f2202332c596"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a98dc2315cbd7cd4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
