{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Teaching BlendSQL via In-Context Learning\n",
    "\n",
    "As described in [our paper](https://arxiv.org/pdf/2402.17882.pdf), the real power of BlendSQL comes when it is used as an intermediate representation for tasks requiring complex reasoning across many different forms of data.\n",
    "\n",
    "In this notebook, we show an example of how we can 'teach' an instruction-finetuned language model how to write with this new dialect of SQL. Our pipeline can be summarized as:\n",
    "\n",
    "1) Define few-shot examples, using our dataset\n",
    "2) Design a prompt for our Parser LLM, which explains the task we want it to achieve\n",
    "3) Call our Parser with our prompt + a question to get a BlendSQL query\n",
    "4) Execute the BlendSQL query with `blend()` to retrieve the final answer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from textwrap import dedent\n",
    "import outlines\n",
    "\n",
    "from blendsql import blend\n",
    "from blendsql.ingredients import LLMMap, LLMJoin, LLMQA\n",
    "from blendsql.models import OpenaiLLM\n",
    "from blendsql.models._model import Model\n",
    "from blendsql._program import Program\n",
    "from blendsql.db import SQLite\n",
    "from blendsql.utils import fetch_from_hub"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T17:40:52.667300Z",
     "start_time": "2024-05-24T17:40:52.666775Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# 1) Define our few-shot examples\n",
    "examples = [\n",
    "   {\n",
    "        \"serialized_db\": 'CREATE TABLE \"w\" (\\n\"index\" INTEGER,\\n  \"name\" TEXT,\\n  \"province\" TEXT,\\n  \"city\" TEXT,\\n  \"year\" TEXT,\\n  \"remarks\" TEXT\\n)\\n/*\\n3 example rows:\\nSELECT * FROM w LIMIT 3\\n index                      name          province     city year                                                         remarks\\n     0       abdul rahman mosque    kabul province    kabul 2009                                   largest mosque in afghanistan\\n     1 friday mosque of kandahar kandahar province kandahar 1750                houses the cloak of the islamic prophet muhammad\\n     2     omar al-farooq mosque kandahar province kandahar 2014 built on the site that was a popular cinema of kandahar . [ 1 ]\\n*/\\n\\nCREATE VIRTUAL TABLE \"documents\" USING fts5(title, content, tokenize = \\'trigram\\')',\n",
    "        \"question\": \"Who were the builders of the mosque in Herat with fire temples ?\",\n",
    "        \"blendsql\": \"\"\"\n",
    "        {{\n",
    "            LLMQA(\n",
    "                'Who were the builders of the mosque?',\n",
    "                (\n",
    "                    SELECT documents.title AS 'Building', documents.content FROM documents\n",
    "                    JOIN {{\n",
    "                        LLMJoin(\n",
    "                            left_on='w::name',\n",
    "                            right_on='documents::title'\n",
    "                        )\n",
    "                    }}\n",
    "                    WHERE w.city = 'herat' AND w.remarks LIKE '%fire temple%'\n",
    "                )\n",
    "            )\n",
    "        }}\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"serialized_db\": 'CREATE TABLE \"w\" (\\n\"index\" INTEGER,\\n  \"no\" INTEGER,\\n  \"rider\" TEXT,\\n  \"team\" TEXT,\\n  \"motorcycle\" TEXT\\n)\\n/*\\n3 example rows:\\nSELECT * FROM w LIMIT 3\\n index  no          rider                 team      motorcycle\\n     0   1   carl fogarty   ducati performance      ducati 996\\n     1   4 akira yanagawa kawasaki racing team kawasaki zx-7rr\\n     2   5  colin edwards        castrol honda      honda rc45\\n*/\\n\\nCREATE VIRTUAL TABLE \"documents\" USING fts5(title, content, tokenize = \\'trigram\\')',\n",
    "        \"question\": \"After what season did the number 7 competitor retire ?\",\n",
    "        \"blendsql\": \"\"\"\n",
    "        {{\n",
    "            LLMQA(\n",
    "                'When did the competitor retire?',\n",
    "                (\n",
    "                    SELECT documents.title AS 'Competitor', documents.content FROM documents\n",
    "                    JOIN {{\n",
    "                        LLMJoin(\n",
    "                            left_on='w::rider',\n",
    "                            right_on='documents::title'\n",
    "                        )\n",
    "                    }}\n",
    "                    WHERE w.no = 7\n",
    "                )\n",
    "            )\n",
    "        }}\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"serialized_db\": 'CREATE TABLE \"w\" (\\n\"index\" INTEGER,\\n  \"year\" TEXT,\\n  \"winner\" TEXT,\\n  \"position\" TEXT,\\n  \"school\" TEXT\\n)\\n/*\\n3 example rows:\\nSELECT * FROM w LIMIT 3\\n index    year         winner   position     school\\n     0 1961-62       ron ryan right wing      colby\\n     1 1962-63 bob brinkworth     center rensselaer\\n     2 1963-64 bob brinkworth     center rensselaer\\n*/\\n\\nCREATE VIRTUAL TABLE \"documents\" USING fts5(title, content, tokenize = \\'trigram\\')',\n",
    "        \"question\": \"What year was the 1971-72 ECAC Hockey Player of the Year born ?\",\n",
    "        \"blendsql\": \"\"\"\n",
    "        {{\n",
    "            LLMQA(\n",
    "                'What year was the player born?',\n",
    "                (\n",
    "                    SELECT documents.title AS 'Player', documents.content FROM documents\n",
    "                    JOIN {{\n",
    "                        LLMJoin(\n",
    "                            left_on = 'w::winner',\n",
    "                            right_on = 'documents::title'\n",
    "                        )\n",
    "                    }}\n",
    "                    WHERE w.year = '1971-72'\n",
    "                )\n",
    "            )\n",
    "        }}\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"serialized_db\": 'CREATE TABLE \"w\" (\\n\"index\" INTEGER,\\n  \"date\" TEXT,\\n  \"language\" TEXT,\\n  \"language family\" TEXT,\\n  \"region\" TEXT\\n)\\n/*\\n3 example rows:\\nSELECT * FROM w LIMIT 3\\n index                     date language language family      region\\n     0 early 2nd millennium bce sumerian         isolate mesopotamia\\n     1       2nd millennium bce  eblaite         semitic       syria\\n     2            ca . 1100 bce  hittite       anatolian    anatolia\\n*/\\n\\nCREATE VIRTUAL TABLE \"documents\" USING fts5(title, content, tokenize = \\'trigram\\')',\n",
    "        \"question\": \"What was the language family that was used in Hattusa , as well as parts of the northern Levant and Upper Mesopotamia ?\",\n",
    "        \"blendsql\": \"\"\"\n",
    "        SELECT \"language family\" FROM w\n",
    "        WHERE language = {{\n",
    "            LLMQA(\n",
    "                'Which language was used in Hattusa, as well as parts of the northern Levant and Upper Mesopotamia ?',\n",
    "                (SELECT title, content FROM documents WHERE documents MATCH 'hattusa'),\n",
    "                options='w::language'\n",
    "            )\n",
    "        }}\n",
    "       \"\"\",\n",
    "    },\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T17:40:53.870231Z",
     "start_time": "2024-05-24T17:40:53.861273Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# 2) Define our prompt to the Parser LLM\n",
    "class ParserProgram(Program):\n",
    "    def __call__(self, model: Model, examples: List[dict], serialized_db: str, question: str, **kwargs):\n",
    "        prompt = \"\"\n",
    "        prompt += dedent(\"\"\"\n",
    "        Generate BlendSQL given the question, table, and passages to answer the question correctly.\n",
    "        BlendSQL is a superset of SQLite, which adds external function calls for information not found within native SQLite.\n",
    "        These external functions should be wrapped in double curly brackets.\n",
    "\n",
    "        If question-relevant column(s) contents are not suitable for SQL comparisons or calculations, map it to a new column with clean content by a new grammar:\n",
    "            `LLMMap('question', '{table}::{column}')`\n",
    "\n",
    "        If mapping to a new column still cannot answer the question with valid SQL, turn to an end-to-end solution using a new grammar:\n",
    "            `LLMQA('{question}', ({blendsql}))`\n",
    "\n",
    "        If we need to do a `join` operation where there is imperfect alignment between table values, use the new grammar:\n",
    "            `LLMJoin(({blendsql}), options='{table}::{column}')`\n",
    "\n",
    "        ONLY use these BlendSQL ingredients if necessary.\n",
    "        Answer parts of the question in vanilla SQL, if possible.\n",
    "\n",
    "        Examples:\\n\n",
    "        \"\"\")\n",
    "        for example in examples:\n",
    "            prompt += f\"{example['serialized_db']}\\n\\n\"\n",
    "            prompt += f\"Question: {example['question']}\\n\"\n",
    "            prompt += f\"BlendSQL: {example['blendsql']}\\n\"\n",
    "        prompt += f\"{serialized_db}\\n\\n\"\n",
    "        prompt += f\"Question: {question}\\n\"\n",
    "        prompt += f\"BlendSQL: \"\n",
    "        generator = outlines.generate.text(model.model_obj)\n",
    "        result = generator(prompt)\n",
    "        return (result, prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T17:40:57.706352Z",
     "start_time": "2024-05-24T17:40:57.703862Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def few_shot_blendsql(question: str, db: SQLite, parser: Model, blender: Model):\n",
    "    # 3) Call the parser with our prompt\n",
    "    predicted_query = parser.predict(\n",
    "        program=ParserProgram,\n",
    "        serialized_db=db.to_serialized(),\n",
    "        question=question,\n",
    "        examples=examples\n",
    "    )\n",
    "    # 4) Execute the BlendSQL query to get the final answer\n",
    "    smoothie = blend(\n",
    "        query=predicted_query,\n",
    "        db=db,\n",
    "        ingredients={LLMMap, LLMQA, LLMJoin},\n",
    "        verbose=False,\n",
    "        default_model=blender\n",
    "    )\n",
    "    return (predicted_query, smoothie)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T17:40:57.876261Z",
     "start_time": "2024-05-24T17:40:57.871184Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "blendsql, smoothie = few_shot_blendsql(\n",
    "    question=\"What team did New Zealand play in the city featuring the Mount Panorama racetrack ?\",\n",
    "    db=SQLite(fetch_from_hub(\"1884_New_Zealand_rugby_union_tour_of_New_South_Wales_1.db\")),\n",
    "    default_model=OpenaiLLM(\"gpt-3.5-turbo\"),\n",
    "    parser=OpenaiLLM(\"gpt-3.5-turbo\")\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T17:40:58.391861Z",
     "start_time": "2024-05-24T17:40:58.251979Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT rival \n",
      "FROM w \n",
      "WHERE city = {{\n",
      "    LLMQA(\n",
      "        'What city features the Mount Panorama racetrack?',\n",
      "        (SELECT title, content FROM documents WHERE documents MATCH 'mount panorama racetrack'),\n",
      "        options='w::city'\n",
      "    )\n",
      "}}\n"
     ]
    }
   ],
   "source": [
    "print(blendsql)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T17:40:59.005129Z",
     "start_time": "2024-05-24T17:40:58.999060Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "               rival\n0  western districts",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rival</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>western districts</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoothie.df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T17:40:59.518010Z",
     "start_time": "2024-05-24T17:40:59.502008Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "blendsql",
   "language": "python",
   "display_name": "blendsql"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
