{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-23T18:59:01.820042Z",
     "start_time": "2024-07-23T18:59:01.817735Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HTTP_PROXY\"] = \"http://http.proxy.fmr.com:8000\"\n",
    "os.environ[\"HTTPS_PROXY\"] = \"http://http.proxy.fmr.com:8000\"\n",
    "os.environ[\"https_proxy\"] = \"http://http.proxy.fmr.com:8000\"\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "import datasets\n",
    "from textwrap import dedent\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "from utils.normalizer import prepare_df_for_neuraldb_from_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "def preprocess_hybridqa_table(table: dict) -> dict:\n",
    "    \"\"\"Preprocesses wikitq headers to make them easier to parse in text-to-SQL task.\n",
    "    TODO: This is causing some encoding issues\n",
    "    \"\"\"\n",
    "    preprocessed_table = {\"header\": [], \"rows\": []}\n",
    "    for v in table[\"header\"]:\n",
    "        preprocessed_table[\"header\"].append(re.sub(r\"(\\'|\\\")\", \"\", v))\n",
    "    for v in table[\"rows\"]:\n",
    "        preprocessed_table[\"rows\"].append([re.sub(r\"(\\'|\\\")\", \"\", item) for item in v])\n",
    "    return preprocessed_table\n",
    "\n",
    "def load_formatted_dataset(dataset_split) -> List[str]:\n",
    "    formatted_dataset = []\n",
    "    for item in tqdm(dataset_split):\n",
    "        document_context = item['passages']['rows']\n",
    "        table_context = prepare_df_for_neuraldb_from_table(\n",
    "            preprocess_hybridqa_table(item['table']), add_row_id=False\n",
    "        )\n",
    "        question_context = item['question']\n",
    "        intro = dedent(\"\"\"This is a hybrid question answering task. The goal of this task is to answer the question given a table (`w`) and corresponding passages (`documents`).\n",
    "        Be as succinct as possible in answering the given question, do not include explanation.\n",
    "        \"\"\")\n",
    "        formatted_dataset.append(\n",
    "            {\n",
    "                \"intro\": intro,\n",
    "                \"documents\": document_context,\n",
    "                \"table\": table_context,\n",
    "                \"question\": question_context\n",
    "            }\n",
    "        )\n",
    "    return formatted_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T18:09:51.951479Z",
     "start_time": "2024-07-23T18:09:51.949581Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a720504/miniconda3/envs/blendsql/lib/python3.9/site-packages/datasets/load.py:929: FutureWarning: The repository for hybridqa contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at ../datasets/hybridqa/hybridqa.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.load.load_dataset(\n",
    "    path=\"../datasets/hybridqa\",\n",
    ")\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T18:09:52.293871Z",
     "start_time": "2024-07-23T18:09:52.189106Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/3466 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9849191ecc6148429813ddd14cf56d5c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not Path(\"hybridqa-validation-formatted.pkl\").is_file():\n",
    "    formatted_dataset = load_formatted_dataset(dataset['validation'])\n",
    "    with open(\"hybridqa-validation-formatted.pkl\", \"wb\") as f:\n",
    "        pickle.dump(formatted_dataset, f)\n",
    "else:\n",
    "    with open(\"hybridqa-validation-joined.pkl\", \"r\") as f:\n",
    "        formatted_dataset = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T18:43:18.975262Z",
     "start_time": "2024-07-23T18:09:52.573177Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/3466 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b7a0e12e63c946da8090b0a1fc981aef"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7510.8770917484135 average, no truncation\n"
     ]
    }
   ],
   "source": [
    "num_tokens = 0\n",
    "for item in tqdm(formatted_dataset):\n",
    "    document_df = pd.DataFrame(item['documents'], columns=[\"title\", \"content\"])\n",
    "    num_tokens += len(\n",
    "        encoding.encode(\n",
    "            f\"\"\"\n",
    "            {item['intro']}\n",
    "\n",
    "            Context:\\n{item['table'].to_string()}\\n{document_df.to_string()}\\n\n",
    "            Question: {item['question']}\n",
    "            Answer:\\n\n",
    "            \"\"\"\n",
    "        )\n",
    "    )\n",
    "print(f\"{num_tokens / len(dataset['validation'])} average, no truncation\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T19:05:25.531055Z",
     "start_time": "2024-07-23T19:02:50.472185Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/3466 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "02c41dad6f904c40b76b15328372cb35"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3691.7642815926138 average, 400 character document truncation\n"
     ]
    }
   ],
   "source": [
    "num_tokens = 0\n",
    "for item in tqdm(formatted_dataset):\n",
    "    documents = [(i[0], i[1][:400]) for i in item['documents']]\n",
    "    document_df = pd.DataFrame(documents, columns=[\"title\", \"content\"])\n",
    "    num_tokens += len(\n",
    "        encoding.encode(\n",
    "            f\"\"\"\n",
    "            {item['intro']}\n",
    "\n",
    "            Context:\\n{item['table'].to_string()}\\n{document_df.to_string()}\\n\n",
    "            Question: {item['question']}\n",
    "            Answer:\\n\n",
    "            \"\"\"\n",
    "        )\n",
    "    )\n",
    "print(f\"{num_tokens / len(dataset['validation'])} average, 400 character document truncation\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T19:11:33.942965Z",
     "start_time": "2024-07-23T19:11:13.013906Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
