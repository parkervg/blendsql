{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"<pre><code>SELECT {{\n    LLMQA(\n        'Describe BlendSQL in 50 words.',\n        context=(\n            SELECT content[0:5000] AS \"README\"\n            FROM read_text('https://raw.githubusercontent.com/parkervg/blendsql/main/README.md')\n        )\n    )\n}} AS answer\n</code></pre>  SQL \ud83e\udd1d LLMs  Join our Discord server for more discussion! <p>Paper  GitHub </p> <p></p>"},{"location":"#installation","title":"\ud83d\udcbb Installation\u2b50 Quickstart","text":"<pre><code>pip install uv &amp;&amp; uv pip install blendsql\n</code></pre> <pre><code>import pandas as pd\n\nfrom blendsql import BlendSQL\nfrom blendsql.models import VLLM\n\n# Define model \nmodel = VLLM(\"RedHatAI/gemma-3-12b-it-quantized.w4a16\", base_url=\"http://localhost:8000/v1/\")\n\n# Prepare our BlendSQL connection\nbsql = BlendSQL(\n    {\n        \"People\": pd.DataFrame(\n            {\n                \"Name\": [\n                    \"George Washington\",\n                    \"John Adams\",\n                    \"Thomas Jefferson\",\n                    \"James Madison\",\n                    \"James Monroe\",\n                    \"Alexander Hamilton\",\n                    \"Sabrina Carpenter\",\n                    \"Charli XCX\",\n                    \"Elon Musk\",\n                    \"Michelle Obama\",\n                    \"Elvis Presley\",\n                ],\n                \"Known_For\": [\n                    \"Established federal government, First U.S. President\",\n                    \"XYZ Affair, Alien and Sedition Acts\",\n                    \"Louisiana Purchase, Declaration of Independence\",\n                    \"War of 1812, Constitution\",\n                    \"Monroe Doctrine, Missouri Compromise\",\n                    \"Created national bank, Federalist Papers\",\n                    \"Nonsense, Emails I Cant Send, Mean Girls musical\",\n                    \"Crash, How Im Feeling Now, Boom Clap\",\n                    \"Tesla, SpaceX, Twitter/X acquisition\",\n                    \"Lets Move campaign, Becoming memoir\",\n                    \"14 Grammys, King of Rock n Roll\",\n                ],\n            }\n        ),\n        \"Eras\": pd.DataFrame({\"Years\": [\"1700-1800\", \"1800-1900\", \"1900-2000\", \"2000-Now\"]}),\n    },\n    model=model,\n    verbose=True,\n)\n\nsmoothie = bsql.execute(\n    \"\"\"\n    SELECT * FROM People P\n    WHERE P.Name IN {{\n        LLMQA('First 3 presidents of the U.S?', quantifier='{3}')\n    }}\n    \"\"\",\n    infer_gen_constraints=True, # Is `True` by default\n)\n\nsmoothie.print_summary()\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 Name              \u2502 Known_For                                             \u2502\n# \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n# \u2502 George Washington \u2502 Established federal government, First U.S. Preside... \u2502\n# \u2502 John Adams        \u2502 XYZ Affair, Alien and Sedition Acts                   \u2502\n# \u2502 Thomas Jefferson  \u2502 Louisiana Purchase, Declaration of Independence       \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502   Time (s) \u2502   # Generation Calls \u2502   Prompt Tokens \u2502   Completion Tokens \u2502\n# \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n# \u2502    1.25158 \u2502                    1 \u2502             296 \u2502                  16 \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\nsmoothie = bsql.execute(\n    \"\"\"\n    SELECT GROUP_CONCAT(Name, ', ') AS 'Names',\n    {{\n        LLMMap(\n            'In which time period was this person born?',\n            p.Name,\n            options=Eras.Years\n        )\n    }} AS Born\n    FROM People p\n    GROUP BY Born\n    \"\"\",\n)\n\nsmoothie.print_summary()\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 Names                                                 \u2502 Born      \u2502\n# \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n# \u2502 George Washington, John Adams, Thomas Jefferson, J... \u2502 1700-1800 \u2502\n# \u2502 Sabrina Carpenter, Charli XCX, Elon Musk, Michelle... \u2502 2000-Now  \u2502\n# \u2502 Elvis Presley                                         \u2502 1900-2000 \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502   Time (s) \u2502   # Generation Calls \u2502   Prompt Tokens \u2502   Completion Tokens \u2502\n# \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n# \u2502    1.03858 \u2502                    2 \u2502             544 \u2502                  75 \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nsmoothie = bsql.execute(\"\"\"\n    SELECT {{\n        LLMQA(\n            'Describe BlendSQL in 50 words.',\n            context=(\n                SELECT content[0:5000] AS \"README\"\n                FROM read_text('https://raw.githubusercontent.com/parkervg/blendsql/main/README.md')\n            )\n        )\n    }} AS answer\n\"\"\")\n\nsmoothie.print_summary()\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 answer                                              \u2502\n# \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n# \u2502 BlendSQL is a Python library that combines SQL a... \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502   Time (s) \u2502   # Generation Calls \u2502   Prompt Tokens \u2502   Completion Tokens \u2502\n# \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n# \u2502    4.07617 \u2502                    1 \u2502            1921 \u2502                  50 \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"#summary","title":"Summary","text":"<p>BlendSQL is a superset of SQL for problem decomposition and hybrid question-answering with LLMs.</p> <p>As a result, we can Blend together...</p> <ul> <li>\ud83e\udd64 ...operations over heterogeneous data sources (e.g. tables, text, images)</li> <li>\ud83e\udd64 ...the structured &amp; interpretable reasoning of SQL with the generalizable reasoning of LLMs</li> </ul>"},{"location":"#core-design-principle-be-lazy","title":"Core Design Principle: Be Lazy \ud83d\ude34","text":"<p>This is embodied in a few different ways - early exit LLM functions when <code>LIMIT</code> clauses are used, don't eagerly materialize CTEs unless we need to, only load language models into memory if we use them, etc.</p> <p>But, at a higher level: Existing DBMS (database management systems) are already highly optimized, and many very smart people get paid a lot of money to keep them at the cutting-edge. Rather than reinvent the wheel, we can leverage their optimizations and only pull the subset of data into memory that is logically required to pass to the language model functions. We then prep the database state via temporary tables, and finally sync back to the native SQL dialect and execute. In this way, BlendSQL 'compiles to SQL'.</p> <p>For more info on query execution in BlendSQL, see Section 2.4 here. </p>"},{"location":"#news","title":"\ud83d\udcf0 News","text":"<ul> <li>(2/4/26) Optimized VLLM integration, particularly for <code>LLMMap</code><ul> <li>Define max concurrent async calls via <code>blendsql.config.set_async_limit(32)</code></li> </ul> </li> <li>(11/7/25) \ud83d\udcddNew paper: Play by the Type Rules: Inferring Constraints for LLM Functions in Declarative Programs</li> <li>(5/30/25) Created a Discord server</li> <li>(5/6/25): New blog post: Language Models, SQL, and Types, Oh My!</li> <li>(5/1/15): Single-page function documentation</li> <li>(10/26/24) New tutorial! blendsql-by-example.ipynb</li> </ul>"},{"location":"#features","title":"Features","text":"<ul> <li>Supports many DBMS \ud83d\udcbe<ul> <li>SQLite, PostgreSQL, DuckDB, Pandas (aka duckdb in a trenchcoat)</li> </ul> </li> <li>Optimized async-based parallelism with vLLM \u2728</li> <li>Write your normal queries - smart parsing optimizes what is passed to external functions \ud83e\udde0<ul> <li>Traverses abstract syntax tree with sqlglot to minimize LLM function calls \ud83c\udf33</li> </ul> </li> <li>Constrained decoding with guidance \ud83d\ude80<ul> <li>We only generate syntactically valid outputs according to query syntax + database contents</li> </ul> </li> <li>LLM function caching, built on diskcache \ud83d\udd11</li> </ul>"},{"location":"#benchmarks","title":"Benchmarks","text":"<p>On a dataset of complex questions converted to executable declarative programs (e.g. How many test takers are there at the school/s in a county with population over 2 million?), BlendSQL is 53% faster than the pandas-based LOTUS. See Section 4 of Play by the Type Rules: Inferring Constraints for LLM Functions in Declarative Programs for more details. </p> <p></p>"},{"location":"#but-why-not-just-define-udfs","title":"But - why not just define UDFs?","text":"<p>Many DBMS allow for the creation of Python user-defined functions (UDFs), like DuckDB. So why not just use those to embed language model functions instead of BlendSQL? The below plot adds the DuckDB UDF approach to the same benchmark we did above - where DuckDB UDFs come in with at average of 133.2 seconds per query.  </p> <p></p> <p>The reason for this? DuckDB uses a generalized query optimizer, very good at many different optimizations. But when we introduce a UDF with an unknown cost, many values get passed to the highly expensive language model functions that could have been filtered out via vanilla SQL expressions first (<code>JOIN</code>, <code>WHERE</code>, <code>LIMIT</code>, etc.).</p> <p>This highlights an important point about the value-add of BlendSQL. While you can just import the individual language model functions and call them on data (see here) - if you know the larger query context where the function output will be used, you should use the BlendSQL query optimizer (<code>bsql.execute()</code>), built specifically for language model functions. As demonstrated above, it makes a huge difference for large database contexts, and out-of-the-box UDFs without the ability to assign cost don't cut it.</p> <p>[!TIP] How do we know the BlendSQL optimizer is passing the minimal required data to the language model functions? Check out our extensive test suite for examples.</p>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>Simple Row-Wise Classification</li> <li>Search-then-Map <ul> <li>Specifying <code>return_type</code></li> </ul> </li> <li>Search-then-Reduce </li> <li>Few-Shot Prompting</li> </ul> <p>The below examples can use this model initialization logic to define the variable <code>model</code>:</p> <pre><code>from blendsql.models import VLLM \n\nmodel = VLLM(\"RedHatAI/gemma-3-12b-it-quantized.w4a16\", base_url=\"http://localhost:8000/v1/\")\n</code></pre> <p>For all the below examples, use <code>smoothie.print_summary()</code> to get an overview of the inputs and outputs.</p> <p></p>"},{"location":"#simple-row-wise-classification","title":"Simple Row-Wise Classification","text":"<pre><code>import pandas as pd\nfrom blendsql import BlendSQL\n\nif __name__ == \"__main__\":\n    bsql = BlendSQL(\n        {\n            \"posts\": pd.DataFrame(\n                {\"content\": [\"I hate this product\", \"I love this product\"]}\n            )\n        },\n        model=model,\n        verbose=True,\n    )\n\n    smoothie = bsql.execute(\n        \"\"\"\n        SELECT {{\n            LLMMap(\n                'What is the sentiment of this text?',\n                content,\n                options=('positive', 'negative', 'neutral')\n            )      \n        }} AS classification FROM posts\n        \"\"\"\n    )\n    print(smoothie.df)\n</code></pre>"},{"location":"#search-then-map","title":"Search-then-Map","text":"<p>Some question answering tasks require hybrid reasoning - some information is present in a given table, but some information exists only in external free text documents. </p> <pre><code>import pandas as pd \n\nfrom blendsql import BlendSQL\n\nbsql = BlendSQL(\n    {\n        \"world_aquatic_championships\": pd.DataFrame(\n            [\n                {\n                    \"Medal\": \"Silver\",\n                    \"Name\": \"Dana Vollmer\",\n                    \"Sport\": \"Swimming\",\n                    \"Event\": \"Women's 100 m butterfly\",\n                    \"Time/Score\": \"56.87\",\n                    \"Date\": \"July 25\",\n                },\n                {\n                    \"Medal\": \"Gold\",\n                    \"Name\": \"Ryan Lochte\",\n                    \"Sport\": \"Swimming\",\n                    \"Event\": \"Men's 200 m freestyle\",\n                    \"Time/Score\": \"1:44.44\",\n                },\n                {\n                    \"Medal\": \"Gold\",\n                    \"Name\": \"Rebecca Soni\",\n                    \"Sport\": \"Swimming\",\n                    \"Event\": \"Women's 100 m breaststroke\",\n                    \"Time/Score\": \"1:05.05\",\n                    \"Date\": \"July 26\",\n                },\n                {\n                    \"Medal\": \"Gold\",\n                    \"Name\": \"Elizabeth Beisel\",\n                    \"Sport\": \"Swimming\",\n                    \"Event\": \"Women's 400 m individual medley\",\n                    \"Time/Score\": \"4:31.78\",\n                    \"Date\": \"July 31\",\n                },\n            ]\n        )\n    },\n    model=model,\n    verbose=True, # Set `verbose=True` to see the query plan as it executes\n)\n\n_ = bsql.model.model_obj # Models are lazy loaded by default. Use this line if you want to pre-load models before execution.\n</code></pre> <p>We can now create a custom function that will:    1) Fill in our f-string templatized question with values in the database   2) Batch-retrieve top <code>k</code> relevant documents for each unrolled question    3) Batch-apply the provied language model to generate a type constrained output given the document contexts </p> <pre><code>from blendsql.search import TavilySearch, FaissVectorStore\nfrom blendsql.ingredients import LLMMap\n\nUSE_TAVILY = True # This requires a `.env` file with a `TAVILY_API_KEY` variable defined\nif USE_TAVILY:\n  context_searcher = TavilySearch(k=3)\nelse:\n  # We can also define a local FAISS vector store\n  context_searcher = FaissVectorStore(\n    model_name_or_path=\"sentence-transformers/all-mpnet-base-v2\",\n    documents=[\n      \"Ryan Steven Lochte (/\u02c8l\u0252kti/ LOK-tee; born August 3, 1984) is an American former[2] competition swimmer and 12-time Olympic medalist.\",\n      \"Rebecca Soni (born March 18, 1987) is an American former competition swimmer and breaststroke specialist.\",\n      \"Elizabeth Lyon Beisel (/\u02c8ba\u026az\u0259l/; born August 18, 1992) is an American competition swimmer who specializes in backstroke and individual medley events.\"\n    ],\n    k=3\n  )\n\nDocumentSearchMap = LLMMap.from_args(\n  context_searcher=context_searcher\n)\n\n# This line registers our new function in our `BlendSQL` connection context\n# Replacement scans allow us to now reference the function by the variable name we initialized it to (`DocumentSearchMap`)\nbsql.ingredients = {DocumentSearchMap} \n\n# Define a blendsql program to answer: 'What is the name of the oldest person who won gold?'\nsmoothie = bsql.execute(\n    \"\"\"\n    SELECT Name FROM world_aquatic_championships w\n    WHERE Medal = 'Gold'\n    /* By default, blendsql infers type constraints given expression context. */ \n    /* So below, the return_type will be constrained to an integer (`\\d+`) */ \n    ORDER BY {{DocumentSearchMap('What year was {} born?', w.Name)}} ASC LIMIT 1\n    \"\"\"\n)\n\nprint(smoothie.df)\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 Name        \u2502\n# \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n# \u2502 Ryan Lochte \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>To analyze the prompts we sent to the model, we can access <code>GLOBAL_HISTORY</code>. </p> <pre><code>from blendsql import GLOBAL_HISTORY\n\n# This is a list\nprint(GLOBAL_HISTORY)\n</code></pre>"},{"location":"#specifying-return_type","title":"Specifying <code>return_type</code>","text":"<p>Notice in the above example - what if two athletes were born in the same year, but different days? </p> <p>In this case, simply fetching the year of birth isn't enough for the ordering we need to do. For cases when the required datatype is unable to be inferred via expression context, you can override the inferred default via passing <code>return_type</code>. The following are valid. All below can be wrapped in a <code>List[...]</code> type.</p> <code>return_type</code> Argument Regex DB Mapping Logic <code>any</code> N.A. N.A. The DB implicitly casts the type, if type affinity is supported (e.g. SQLite does this). <code>str</code> N.A. N.A. Same behavior as <code>any</code>, but the language model is prompted with the cue that the return type should look like a string. <code>int</code> <code>r\"-?(\\d+)\"</code> <code>float</code> <code>r\"-?(\\d+(\\.\\d+)?)\"</code> <code>bool</code> <code>r\"(t\\|f\\|true\\|false\\|True\\|False)\"</code> <code>substring</code> (*Only valid for LLMMap) complicated - see https://github.com/guidance-ai/guidance/blob/main/guidance/library/_substring.py#L11 <code>date</code> <code>r\"\\d{4}-\\d{2}-\\d{2}\"</code> The ISO8601 is inserted into the query as a date type. This differs for different DBMS - in DuckDB, it would be <code>'1992-09-20'::DATE</code> <pre><code>smoothie = bsql.execute(\n    \"\"\"\n    SELECT Name FROM world_aquatic_championships w\n    WHERE Medal = 'Gold'\n    /* Defining `return_type = 'date'` will constrain generation to a date format, and handle type conversion to the respective database context for you. */  \n    /* For example, DuckDB and SQLite stores dates as a ISO8601 string */\n    ORDER BY {{DocumentSearchMap('When was {} born?', w.Name, return_type='date')}} ASC LIMIT 1\n    \"\"\"\n)\n</code></pre>"},{"location":"#search-then-reduce","title":"Search-then-Reduce","text":"<p>Below we use the scalar <code>LLMQA</code> function to do a search over our documents with the question formatted with a value from the structured <code>european_countries</code> table.</p> <pre><code>import pandas as pd \n\nfrom blendsql import BlendSQL\nfrom blendsql.search import FaissVectorStore\nfrom blendsql.ingredients import LLMQA\n\nbsql = BlendSQL(\n    {\n        \"documents\": pd.DataFrame(\n            [\n                {\n                    \"title\": \"Steve Nash\",\n                    \"content\": \"Steve Nash played college basketball at Santa Clara University\",\n                },\n                {\n                    \"title\": \"E.F. Codd\",\n                    \"content\": 'Edgar Frank \"Ted\" Codd (19 August 1923 \u2013 18 April 2003) was a British computer scientist who, while working for IBM, invented the relational model for database management, the theoretical basis for relational databases and relational database management systems.',\n                },\n                {\n                    \"title\": \"George Washington (February 22, 1732 \u2013 December 14, 1799) was a Founding Father and the first president of the United States, serving from 1789 to 1797.\"\n                },\n                {\n                    \"title\": \"Thomas Jefferson\",\n                    \"content\": \"Thomas Jefferson (April 13, 1743 \u2013 July 4, 1826) was an American Founding Father and the third president of the United States from 1801 to 1809.\",\n                },\n                {\n                    \"title\": \"John Adams\",\n                    \"content\": \"John Adams (October 30, 1735 \u2013 July 4, 1826) was an American Founding Father who was the second president of the United States from 1797 to 1801.\",\n                },\n            ]\n        ),\n        \"european_countries\": pd.DataFrame(\n            [\n                {\n                    \"Country\": \"Portugal\",\n                    \"Area (km\u00b2)\": 91568,\n                    \"Population (As of 2011)\": 10555853,\n                    \"Population density (per km\u00b2)\": 115.2,\n                    \"Capital\": \"Lisbon\",\n                },\n                {\n                    \"Country\": \"Sweden\",\n                    \"Area (km\u00b2)\": 449964,\n                    \"Population (As of 2011)\": 9088728,\n                    \"Population density (per km\u00b2)\": 20.1,\n                    \"Capital\": \"Stockholm\",\n                },\n                {\n                    \"Country\": \"United Kingdom\",\n                    \"Area (km\u00b2)\": 244820,\n                    \"Population (As of 2011)\": 62300000,\n                    \"Population density (per km\u00b2)\": 254.4,\n                    \"Capital\": \"London\",\n                },\n            ]\n        ),\n    },\n    model=model,\n    verbose=True,\n)\n\nUSE_SEARCH = True \nif USE_SEARCH:\n  LLMQA = LLMQA.from_args(\n    context_searcher=FaissVectorStore(\n      model_name_or_path=\"sentence-transformers/all-mpnet-base-v2\",\n      documents=bsql.db.execute_to_list(\"SELECT DISTINCT title || content FROM documents\"),\n      k=3\n    )\n  )\n  bsql.ingredients = {LLMQA}\n\nsmoothie = bsql.execute(\n\"\"\"\nSELECT {{\n    LLMQA(\n      'Who is from {}?', \n      /* The below subquery gets executed, and the result is inserted into the below `{}`. */\n      (\n        SELECT Country FROM european_countries c\n        WHERE Capital = 'London'\n      )\n    )\n}} AS answer\n\"\"\"\n)\nprint(smoothie.df)\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 answer     \u2502\n# \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n# \u2502 E.F. Codd  \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"#few-shot-prompting","title":"Few-Shot Prompting","text":"<p>For the LLM-based ingredients in BlendSQL, few-shot prompting can be vital. In <code>LLMMap</code>, <code>LLMQA</code> and <code>LLMJoin</code>, we provide an interface to pass custom few-shot examples.</p>"},{"location":"#llmmap","title":"<code>LLMMap</code>","text":"<ul> <li>Default examples</li> <li>All possible fields</li> </ul> <pre><code>from blendsql import BlendSQL\nfrom blendsql.ingredients.builtin import LLMMap, DEFAULT_MAP_FEW_SHOT\n\ningredients = {\n  LLMMap.from_args(\n    few_shot_examples=[\n      *DEFAULT_MAP_FEW_SHOT,\n      {\n        \"question\": \"Is this a sport?\",\n        \"mapping\": {\n          \"Soccer\": True,\n          \"Chair\": False,\n          \"Banana\": False,\n          \"Golf\": True\n        },\n        # Below are optional\n        \"column_name\": \"Items\",\n        \"table_name\": \"Table\",\n        \"return_type\": \"boolean\"\n      }\n    ],\n    # How many inference values to pass to model at once\n    batch_size=5,\n  )\n}\n\nbsql = BlendSQL(db, ingredients=ingredients)\n</code></pre>"},{"location":"#llmqa","title":"<code>LLMQA</code>","text":"<ul> <li>Default examples</li> <li>All possible fields</li> </ul> <pre><code>from blendsql import BlendSQL\nfrom blendsql.ingredients.builtin import LLMQA, DEFAULT_QA_FEW_SHOT\n\ningredients = {\n    LLMQA.from_args(\n        few_shot_examples=[\n            *DEFAULT_QA_FEW_SHOT,\n            {\n                \"question\": \"Which weighs the most?\",\n                \"context\": {\n                    {\n                        \"Animal\": [\"Dog\", \"Gorilla\", \"Hamster\"],\n                        \"Weight\": [\"20 pounds\", \"350 lbs\", \"100 grams\"]\n                    }\n                },\n                \"answer\": \"Gorilla\",\n                # Below are optional\n                \"options\": [\"Dog\", \"Gorilla\", \"Hamster\"]\n            }\n        ],\n        # Lambda to turn the pd.DataFrame to a serialized string\n        context_formatter=lambda df: df.to_markdown(\n            index=False\n        )\n    )\n}\n\nbsql = BlendSQL(db, ingredients=ingredients)\n</code></pre>"},{"location":"#llmjoin","title":"<code>LLMJoin</code>","text":"<ul> <li>Default examples</li> <li>All possible fields</li> </ul> <pre><code>from blendsql import BlendSQL\nfrom blendsql.ingredients.builtin import LLMJoin, DEFAULT_JOIN_FEW_SHOT\n\ningredients = {\n  LLMJoin.from_args(\n    few_shot_examples=[\n      *DEFAULT_JOIN_FEW_SHOT,\n      {\n        \"join_criteria\": \"Join the state to its capital.\",\n        \"left_values\": [\"California\", \"Massachusetts\", \"North Carolina\"],\n        \"right_values\": [\"Sacramento\", \"Boston\", \"Chicago\"],\n        \"mapping\": {\n          \"California\": \"Sacramento\",\n          \"Massachusetts\": \"Boston\",\n          \"North Carolina\": \"-\"\n        }\n      }\n    ],\n  )\n}\n\nbsql = BlendSQL(db, ingredients=ingredients)\n</code></pre>"},{"location":"#citation","title":"Citation","text":"<pre><code>@inproceedings{glenn2025play,\n  title={Play by the Type Rules: Inferring Constraints for Small Language Models in Declarative Programs},\n  author={Glenn, Parker and Samuel, Alfy and Liu, Daben},\n  booktitle={EurIPS 2025 Workshop: AI for Tabular Data}\n}\n\n@article{glenn2024blendsql,\n  title={BlendSQL: A Scalable Dialect for Unifying Hybrid Question Answering in Relational Algebra},\n  author={Parker Glenn and Parag Pravin Dakle and Liang Wang and Preethi Raghavan},\n  year={2024},\n  eprint={2402.17882},\n  archivePrefix={arXiv},\n  primaryClass={cs.CL}\n}\n</code></pre>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>Special thanks to those below for inspiring this project. Definitely recommend checking out the linked work below, and citing when applicable!</p> <ul> <li>The authors of Binding Language Models in Symbolic Languages<ul> <li>This paper was the primary inspiration for BlendSQL.</li> </ul> </li> <li>The authors of EHRXQA: A Multi-Modal Question Answering Dataset for Electronic Health Records with Chest X-ray Images<ul> <li>As far as I can tell, the first publication to propose unifying model calls within SQL</li> <li>Served as the inspiration for the vqa-ingredient.ipynb example</li> </ul> </li> <li>The authors of Grammar Prompting for Domain-Specific Language Generation with Large Language Models</li> <li>The maintainers of the Guidance library for powering the constrained decoding capabilities of BlendSQL</li> </ul>"},{"location":"by-example/","title":"Some Cool Things by Example","text":""},{"location":"by-example/#inferring-regular-expression-constraints","title":"Inferring Regular Expression Constraints","text":"<p><pre><code>SELECT \"Name\" FROM parks\nWHERE \"Location\" = 'Alaska'\nORDER BY {{\n    LLMMap(\n        'Size in km2?',\n        Area\n    )\n}} DESC LIMIT 1\n</code></pre> By virtue of the <code>ORDER BY</code> clause, we assume that the output of the <code>{{LLMMap}</code> ingredient should be a numeric. BlendSQL constrains the generation of the language model, then, to the regular expression corresponding to a integer (or floating point) <code>(\\d+(\\.\\d+)?){n}</code>, where <code>n</code> is the number of values in the <code>Area</code> column, and <code>-</code> represents a null value.</p>"},{"location":"by-example/#automatic-options-injection","title":"Automatic <code>options</code> Injection","text":"<p><pre><code>SELECT \"Location\", \"Name\" AS \"Park Protecting Ash Flow\" FROM parks\n    WHERE \"Name\" = {{\n      LLMQA(\n        'Which park protects an ash flow?',\n        (SELECT \"Name\", \"Description\" FROM parks)\n      )\n  }}\n</code></pre> We can omit the <code>options</code> argument, and BlendSQL will automatically infer the <code>options=\"parks::Name\"</code> argument.</p>"},{"location":"by-example/#referencing-cte-passing-in-enumerated-options","title":"Referencing CTE, Passing in Enumerated Options","text":"<p><pre><code>WITH w AS (\n    SELECT *\n    FROM account_history\n    WHERE Symbol IS NOT NULL\n) SELECT Symbol, {{\n    LLMMap(\n        'Sells cell phones?',\n        Description,\n        ('t', 'f')\n    )\n}} FROM w\n</code></pre> The <code>context</code> arg can reference a table created from a CTE, and our <code>options</code> value can be a semi-colon seperated list of strings.</p>"},{"location":"by-example/#conditional-materializing-of-cte-statements","title":"Conditional Materializing of CTE Statements","text":"<p><pre><code>WITH a AS (\n    SELECT * FROM portfolio WHERE Quantity &gt; 200\n), b AS\n(\n    SELECT Symbol FROM portfolio AS w WHERE w.Symbol LIKE \"A%\"\n),\nSELECT * FROM a WHERE {{test_starts_with('F', a.Symbol)}} = TRUE\nJOIN b ON a.Symbol = b.Symbol\n</code></pre> We only eagerly materialize a table from a CTE if it's used within an ingredient. Above, BlendSQL will materialize the <code>a</code> table, but not <code>b</code>.</p>"},{"location":"faq/","title":"FAQ","text":""},{"location":"faq/#how-does-blendsql-execute-a-query","title":"How does BlendSQL execute a query?","text":"<p>BlendSQL handles traversal of the SQL AST and creation of temporary tables to execute a given query.  This allows BlendSQL to be DBMS-agnostic, and extendable into both SQLite, PostgreSQL, and other DBMS.</p>"},{"location":"faq/#why-not-just-implement-blendsql-as-a-user-defined-function-in-sqlite","title":"Why not just implement BlendSQL as a user-defined function in SQLite?","text":"<p>LLMs are expensive, both in terms of $ cost and compute time. When applying them to SQLite databases, we want to take special care in ensuring we're not applying them to contexts where they're not required.  This is not easily achievable with UDFs, even when marked as a deterministic function.</p> <p>BlendSQL is specifically designed to enforce an order-of-operations that 1) prioritizes vanilla SQL operations first, and 2) caches results from LLM ingredients so they don't need to be recomputed. For example: <pre><code>SELECT {{LLMMap('What state is this NBA team from?', 'w::team')} FROM w \n   WHERE num_championships &gt; 3 \n   ORDER BY {{LLMMap('What state is this NBA team from?', 'w::team')}\n</code></pre> BlendSQL makes sure to only pass those <code>team</code> values from rows which satisfy the condition <code>num_championship &gt; 3</code> to the LLM. Additionally, since we assume the function is deterministic, we make a single LLM call and cache the results, despite the ingredient function being used twice.</p>"},{"location":"faq/#so-i-get-how-to-write-blendsql-queries-but-why-would-i-use-this-over-vanilla-sqlite","title":"So I get how to write BlendSQL queries. But why would I use this over vanilla SQLite?","text":"<p>Certain ingredients, like LLMJoin, will likely give seasoned SQL experts a headache at first. However, BlendSQL's real strength comes from it's use as an intermediate representation for reasoning over structured + unstructured with LLMs. Some examples of this can be found here.</p>"},{"location":"installation/","title":"Installation","text":"<pre><code>pip install blendsql\n</code></pre>"},{"location":"quickstart/","title":"Quickstart","text":"<pre><code>import pandas as pd\n\nfrom blendsql import BlendSQL\nfrom blendsql.models import VLLM\n\nmodel = VLLM(\"RedHatAI/gemma-3-12b-it-quantized.w4a16\", base_url=\"http://localhost:8000/v1/\")\n\n# Prepare our BlendSQL connection\nbsql = BlendSQL(\n    {\n        \"People\": pd.DataFrame(\n            {\n                \"Name\": [\n                    \"George Washington\",\n                    \"John Adams\",\n                    \"Thomas Jefferson\",\n                    \"James Madison\",\n                    \"James Monroe\",\n                    \"Alexander Hamilton\",\n                    \"Sabrina Carpenter\",\n                    \"Charli XCX\",\n                    \"Elon Musk\",\n                    \"Michelle Obama\",\n                    \"Elvis Presley\",\n                ],\n                \"Known_For\": [\n                    \"Established federal government, First U.S. President\",\n                    \"XYZ Affair, Alien and Sedition Acts\",\n                    \"Louisiana Purchase, Declaration of Independence\",\n                    \"War of 1812, Constitution\",\n                    \"Monroe Doctrine, Missouri Compromise\",\n                    \"Created national bank, Federalist Papers\",\n                    \"Nonsense, Emails I Cant Send, Mean Girls musical\",\n                    \"Crash, How Im Feeling Now, Boom Clap\",\n                    \"Tesla, SpaceX, Twitter/X acquisition\",\n                    \"Lets Move campaign, Becoming memoir\",\n                    \"14 Grammys, King of Rock n Roll\",\n                ],\n            }\n        ),\n        \"Eras\": pd.DataFrame({\"Years\": [\"1700-1800\", \"1800-1900\", \"1900-2000\", \"2000-Now\"]}),\n    },\n    model=model,\n    verbose=True,\n)\n\nsmoothie = bsql.execute(\n    \"\"\"\n    SELECT * FROM People P\n    WHERE P.Name IN {{\n        LLMQA('First 3 presidents of the U.S?', quantifier='{3}')\n    }}\n    \"\"\",\n    infer_gen_constraints=True, # Is `True` by default\n)\n\nsmoothie.print_summary()\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 Name              \u2502 Known_For                                             \u2502\n# \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n# \u2502 George Washington \u2502 Established federal government, First U.S. Preside... \u2502\n# \u2502 John Adams        \u2502 XYZ Affair, Alien and Sedition Acts                   \u2502\n# \u2502 Thomas Jefferson  \u2502 Louisiana Purchase, Declaration of Independence       \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502   Time (s) \u2502   # Generation Calls \u2502   Prompt Tokens \u2502   Completion Tokens \u2502\n# \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n# \u2502    1.25158 \u2502                    1 \u2502             296 \u2502                  16 \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\nsmoothie = bsql.execute(\n    \"\"\"\n    SELECT GROUP_CONCAT(Name, ', ') AS 'Names',\n    {{\n        LLMMap(\n            'In which time period was this person born?',\n            p.Name,\n            options=Eras.Years\n        )\n    }} AS Born\n    FROM People p\n    GROUP BY Born\n    \"\"\",\n)\n\nsmoothie.print_summary()\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 Names                                                 \u2502 Born      \u2502\n# \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n# \u2502 George Washington, John Adams, Thomas Jefferson, J... \u2502 1700-1800 \u2502\n# \u2502 Sabrina Carpenter, Charli XCX, Elon Musk, Michelle... \u2502 2000-Now  \u2502\n# \u2502 Elvis Presley                                         \u2502 1900-2000 \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502   Time (s) \u2502   # Generation Calls \u2502   Prompt Tokens \u2502   Completion Tokens \u2502\n# \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n# \u2502    1.03858 \u2502                    2 \u2502             544 \u2502                  75 \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nsmoothie = bsql.execute(\"\"\"\n    SELECT {{\n        LLMQA(\n            'Describe BlendSQL in 50 words.',\n            context=(\n                SELECT content[0:5000] AS \"README\"\n                FROM read_text('https://raw.githubusercontent.com/parkervg/blendsql/main/README.md')\n            )\n        )\n    }} AS answer\n\"\"\")\n\nsmoothie.print_summary()\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 answer                                              \u2502\n# \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n# \u2502 BlendSQL is a Python library that combines SQL a... \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502   Time (s) \u2502   # Generation Calls \u2502   Prompt Tokens \u2502   Completion Tokens \u2502\n# \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n# \u2502    4.07617 \u2502                    1 \u2502            1921 \u2502                  50 \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"examples/feverous/","title":"FEVEROUS","text":"<p>Here, we deal not with questions, but truth claims given a context of unstructured and structured data.</p> <p>These claims should be judged as \"SUPPORTS\" or \"REFUTES\". Using BlendSQL, we can formulate this determination of truth as a function over facts. </p> <p>Oyedaea is part of the family Asteraceae in the order Asterales. <pre><code>SELECT EXISTS (\n    SELECT * FROM w0 WHERE \"family:\" = 'asteraceae' AND \"order:\" = 'asterales'\n) \n</code></pre></p> <p>Sixty two year old Welsh journalist Jan Moir worked for a couple other papers before working at Daily Mail as an opinion columnist and has won several awards for her writing. <pre><code>SELECT (\n    SELECT {{LLMMap('What age?', 'w0::born')}} = 62 FROM w0\n) AND (\n    {{\n        LLMValidate(\n            'Did Jan Moir work at a couple other papers before working at Daily Mail as an opinion columnist?',\n            (SELECT * FROM documents)\n        ) \n    }}\n) AND (\n    {{\n        LLMValidate(\n            'Has Jan Moir won several awards for her writing?',\n            (SELECT * FROM documents)\n        ) \n    }}\n)\n</code></pre></p> <p>Saunders College of Business, which is accredited by the Association to Advance Collegiate Schools of Business International, is one of the colleges of Rochester Institute of Technology established in 1910 and is currently under the supervision of Dean Jacqueline R. Mozrall. <pre><code>SELECT EXISTS(\n    SELECT * FROM w0 \n    WHERE \"parent institution\" = 'rochester institute of technology'\n    AND \"established\" = '1910'\n    AND \"dean\" = 'jacqueline r. mozrall'\n) AND (\n    {{\n        LLMValidate(\n            'Is Saunders College of Business (SCB) accredited by the Association to Advance Collegiate Schools of Business International (AACSB)?',\n            (SELECT * FROM documents)\n        )\n    }}\n)\n</code></pre></p>"},{"location":"examples/hybridqa/","title":"HybridQA","text":"<p>For this setting, our database contains 2 tables: a table from Wikipedia <code>w</code>, and a collection of unstructured Wikipedia articles in the table <code>documents</code>.</p> <p>What is the state flower of the smallest state by area ? <pre><code>SELECT \"common name\" AS 'State Flower' FROM w \nWHERE state = {{\n    LLMQA(\n        'Which is the smallest state by area?',\n        (SELECT title, content FROM documents),\n        options='w::state'\n    )\n}}\n</code></pre></p> <p>Who were the builders of the mosque in Herat with fire temples ? <pre><code>{{\n    LLMQA(\n        'Who were the builders of the mosque?',\n        (\n            SELECT documents.title AS 'Building', documents.content FROM documents\n            JOIN {{\n                LLMJoin(\n                    left_on='w::name',\n                    right_on='documents::title'\n                )\n            }}\n            WHERE w.city = 'herat' AND w.remarks LIKE '%fire temple%'\n        )\n    )\n}}\n</code></pre></p> <p>What is the capacity of the venue that was named in honor of Juan Antonio Samaranch in 2010 after his death ? <pre><code>SELECT capacity FROM w WHERE venue = {{\n    LLMQA(\n        'Which venue is named in honor of Juan Antonio Samaranch?',\n        (SELECT title AS 'Venue', content FROM documents),\n        options='w::venue'\n    )\n}}\n</code></pre></p>"},{"location":"examples/ottqa/","title":"OTT-QA","text":"<p>Unlike HybridQA, these questions are open-domain, where we don't know in advance where the answer of a given open question appears in a passage or a table.</p> <p>As a result, we need to play the role of both the retriever (to select relevant context) and reader (to read from relevant contexts and return the given answer).</p> <p>As the underlying database consists of 400K tables and 5M documents, it's important to set <code>LIMIT</code> clauses appropriately to ensure reasonable execution times.</p> <p>The examples below also demonstrate how BlendSQL unpacks CTE statements to ensure we only pass necessary data into the BlendSQL ingredient calls. </p> <p>When was the third highest paid Rangers F.C . player born ? <pre><code>{{\n    LLMQA(\n        'When was the Rangers Player born?',\n        (\n            WITH t AS (\n                SELECT player FROM (\n                    SELECT * FROM \"./List of Rangers F.C. records and statistics (0)\"\n                    UNION ALL SELECT * FROM \"./List of Rangers F.C. records and statistics (1)\"\n                ) ORDER BY trim(fee, '\u00a3') DESC LIMIT 1 OFFSET 2\n            ), d AS (\n                SELECT * FROM documents JOIN t WHERE documents MATCH t.player || ' OR rangers OR fc' ORDER BY rank LIMIT 5\n            ) SELECT d.content, t.player AS 'Rangers Player' FROM d JOIN t\n        )\n    )\n}}\n</code></pre></p> <p>In which Track Cycling World Championships event was the person born in Matanzas , Cuba ranked highest ? <pre><code>{{\n    LLMQA(\n        'In what event was the cyclist ranked highest?',\n        (\n            SELECT * FROM (\n                SELECT * FROM \"./Cuba at the UCI Track Cycling World Championships (2)\"\n            ) as w WHERE w.name = {{\n                LLMQA(\n                    \"Which cyclist was born in Matanzas, Cuba?\",\n                    (\n                        SELECT * FROM documents \n                            WHERE documents MATCH 'matanzas AND (cycling OR track OR born)' \n                            ORDER BY rank LIMIT 3\n                    ),\n                    options=\"w::name\"\n                )\n            }}\n        ),\n        options='w::event'\n    )\n}}\n</code></pre></p> <p>Who is the director the Togolese film that was a 30 minute film that was shot in 16mm ? <pre><code>SELECT director FROM \"./List of African films (4)\" as w\nWHERE title = {{\n    LLMQA(\n        'What is the name of the Togolese film that was 30 minutes and shot in 16mm?',\n        (SELECT * FROM documents WHERE documents MATCH 'togolese OR 30 OR 16mm OR film' ORDER BY rank LIMIT 5),\n        options='w::title'\n    )\n}}\n</code></pre></p>"},{"location":"reference/execute-blendsql/","title":"Execute a BlendSQL Query","text":""},{"location":"reference/execute-blendsql/#blendsql-class","title":"BlendSQL Class","text":"<p>Core <code>BlendSQL</code> class that provides high level interface for executing BlendSQL queries.</p> <p>Parameters:</p> Name Type Description Default <code>db</code> <code>Union[DataFrame, dict, str, Database]</code> <p>Database to connect to. Can be:</p> <ul> <li> <p>pandas DataFrame or dict of DataFrames</p> </li> <li> <p>Path to SQLite database file</p> </li> <li> <p>PostgreSQL connection string</p> </li> <li> <p><code>Database</code> object</p> </li> </ul> <code>None</code> <code>model</code> <code>Optional[ModelBase]</code> <p>Model instance to use for LLM operations. Can also be provided during query execution.</p> <code>None</code> <code>ingredients</code> <code>Optional[Collection[Type[Ingredient]]]</code> <p>Collection of ingredients to make available for queries. Can also be     provided during query execution.</p> <code>list()</code> <code>verbose</code> <code>bool</code> <p>Whether to output debug logging information. Defaults to False.</p> <code>False</code> <code>infer_gen_constraints</code> <code>bool</code> <p>Whether to automatically infer constraints for LLM generation based on query context. Defaults to True.</p> <code>True</code> <code>table_to_title</code> <code>Optional[Dict[str, str]]</code> <p>Optional mapping from table names to descriptive titles, useful for datasets where table titles contain metadata.</p> <code>None</code> Source code in <code>blendsql/blendsql.py</code> <pre><code>@dataclass\nclass BlendSQL:\n    \"\"\"Core `BlendSQL` class that provides high level interface for executing BlendSQL queries.\n\n    Args:\n        db (Union[pd.DataFrame, dict, str, Database]): Database to connect to. Can be:\n\n            - pandas DataFrame or dict of DataFrames\n\n            - Path to SQLite database file\n\n            - PostgreSQL connection string\n\n            - `Database` object\n        model (Optional[ModelBase]): Model instance to use for LLM operations. Can also be\n            provided during query execution.\n        ingredients (Optional[Collection[Type[Ingredient]]]): Collection of ingredients to\n            make available for queries. Can also be\n                provided during query execution.\n        verbose (bool): Whether to output debug logging information. Defaults to False.\n        infer_gen_constraints (bool): Whether to automatically infer constraints for\n            LLM generation based on query context. Defaults to True.\n        table_to_title (Optional[Dict[str, str]]): Optional mapping from table names to\n            descriptive titles, useful for datasets where table titles contain metadata.\n    \"\"\"\n\n    db: pd.DataFrame | dict | str | Path | Database = field(default=None)\n    model: ModelBase | None = field(default=None)\n    ingredients: Collection[Type[Ingredient]] | None = field(default_factory=list)\n\n    verbose: bool = field(default=False)\n\n    infer_gen_constraints: bool = field(default=True)\n    enable_constrained_decoding: bool = field(default=True)\n    enable_cascade_filter: bool = field(default=True)\n    enable_early_exit: bool = field(default=True)\n\n    table_to_title: dict[str, str] | None = field(default=None)\n\n    def __post_init__(self):\n        if not isinstance(self.db, Database):\n            self.db = self._infer_db_type(self.db)\n        if self.db is None:\n            raise ValueError(\"df_or_db_path must be provided\")\n        self.ingredients = self._merge_default_ingredients(self.ingredients)\n        self._toggle_verbosity(self.verbose)\n\n    @staticmethod\n    def _toggle_verbosity(verbose_in_use: bool):\n        if verbose_in_use:\n            logger.setLevel(logging.DEBUG)\n        else:\n            logger.setLevel(logging.ERROR)\n\n    @staticmethod\n    def _merge_default_ingredients(\n        ingredients: Collection[Type[Ingredient]] | None,\n    ) -&gt; set[Type[Ingredient]]:\n        from blendsql.ingredients import LLMQA, LLMMap, LLMJoin\n\n        DEFAULT_INGREDIENTS = {LLMQA, LLMMap, LLMJoin}\n        try:\n            _ingredient_names = [i.__name__.upper() for i in ingredients]\n        except AttributeError as e:\n            raise LMFunctionException(\n                \"All arguments passed to `ingredients` should be `Ingredient` classes!\"\n            ) from e\n        ingredient_names = set(_ingredient_names)\n        if len(ingredient_names) != len(_ingredient_names):\n            raise LMFunctionException(\n                f\"Duplicate ingredient names passed! These are case insensitive, be careful.\\n{_ingredient_names=}\"\n            )\n        ingredients = set(ingredients)\n        for default_ingredient in DEFAULT_INGREDIENTS:\n            if default_ingredient.__name__.upper() not in ingredient_names:\n                ingredients.add(default_ingredient)\n        return ingredients\n\n    @staticmethod\n    def _infer_db_type(df_or_db_path: pd.DataFrame | dict | str | Path) -&gt; Database:\n        if df_or_db_path is None:\n            from .db.pandas import Pandas\n\n            return Pandas({})  # Load an empty DuckDB connection\n\n        elif isinstance(df_or_db_path, (pd.DataFrame, dict)):\n            from .db.pandas import Pandas\n\n            if isinstance(df_or_db_path, dict):\n                if not isinstance(next(iter(df_or_db_path.values())), pd.DataFrame):\n                    logger.debug(\n                        Color.update(\"Converting dict values to pd.DataFrames...\")\n                    )\n                    df_or_db_path = {\n                        k: pd.DataFrame(v) for k, v in df_or_db_path.items()\n                    }\n            return Pandas(df_or_db_path)\n\n        elif isinstance(df_or_db_path, (str, Path)):\n            if Path(df_or_db_path).exists():\n                if Path(df_or_db_path).suffix == \".duckdb\":\n                    from .db.duckdb import DuckDB\n\n                    return DuckDB.from_file(df_or_db_path)\n                else:\n                    from .db.sqlite import SQLite\n\n                    return SQLite(df_or_db_path)\n            elif \"://\" in df_or_db_path:\n                from .db.postgresql import PostgreSQL\n\n                return PostgreSQL(df_or_db_path)\n        else:\n            raise ValueError(\n                f\"Could not resolve '{df_or_db_path}' to a valid database type!\"\n            )\n\n    def visualize(self, query: str, output_path: str | None = None, format=\"pdf\"):\n        \"\"\"Visualize query as a DAG with graphviz.\"\"\"\n        from .visualize import SQLGlotASTVisualizer\n\n        visualizer = SQLGlotASTVisualizer()\n\n        dialect: sqlglot.Dialect = get_dialect(self.db.__class__.__name__)\n\n        # Generate visualization\n        dot = visualizer.visualize(\n            _parse_one(query, dialect=dialect, schema=self.db.sqlglot_schema)\n        )\n\n        if output_path is not None:\n            # Save as PDF\n            dot.render(output_path, format=format, cleanup=True)\n        return dot\n\n    def _warmup(self, model: ModelBase | None = None):\n        _ = self.execute(\n            \"\"\"\n            SELECT {{LLMQA('What color is the sky?')}} AS answer\n            \"\"\",\n            model=model,\n        )\n        _ = self.execute(\n            \"\"\"\n            WITH subset AS (\n                SELECT 'This product is absolutely wonderful and I love it!' AS reviewText\n                UNION ALL\n                SELECT 'Terrible quality, broke after one day.'\n            )\n            SELECT {{LLMMap('Is this positive?', reviewText, return_type='bool')}}\n            FROM subset\n            \"\"\",\n            model=model,\n        )\n\n    def execute(\n        self,\n        query: str,\n        ingredients: Collection[Type[Ingredient]] | None = None,\n        model: ModelBase | None = None,\n        infer_gen_constraints: bool | None = None,\n        enable_cascade_filter: bool | None = None,\n        enable_early_exit: bool | None = None,\n        enable_constrained_decoding: bool | None = None,\n        verbose: bool | None = None,\n    ) -&gt; Smoothie:\n        '''The `execute()` function is used to execute a BlendSQL query against a database and\n        return the final result, in addition to the intermediate reasoning steps taken.\n        Execution is done on a database given an ingredient context.\n\n        Args:\n            query: The BlendSQL query to execute\n            ingredients: Collection of ingredient objects, to use in interpreting BlendSQL query.\n                {LLMQA, LLMMap, LLMJoin} are supplied by default.\n            verbose: Boolean defining whether to run with logger in debug mode\n            default_model: Which BlendSQL model to use in performing ingredient tasks in the current query\n            infer_gen_constraints: Optionally infer the output format of an `IngredientMap` call, given the predicate context\n                For example, in `{{LLMMap('convert to date', 'w::listing date')}} &lt;= '1960-12-31'`\n                We can infer the output format should look like '1960-12-31' and both:\n                    1) Put this string in the `example_outputs` kwarg\n                    2) If we have a LocalModel, pass the date regex pattern to guidance\n            enable_cascade_filter: Enable cascade filtering optimization.\n            enable_early_exit: Enable early exit optimization.\n            enable_constrained_decoding: Enable constrained decoding for local models.\n\n        Returns:\n            smoothie: `Smoothie` dataclass containing pd.DataFrame output and execution metadata\n\n        Examples:\n            ```python\n            import psutil\n            import pandas as pd\n\n            from blendsql import BlendSQL\n            from blendsql.models import LlamaCpp\n\n            # Prepare our BlendSQL connection\n            bsql = BlendSQL(\n                {\n                    \"People\": pd.DataFrame(\n                        {\n                            \"Name\": [\n                                \"George Washington\",\n                                \"John Quincy Adams\",\n                                \"Thomas Jefferson\",\n                                \"James Madison\",\n                                \"James Monroe\",\n                                \"Alexander Hamilton\",\n                                \"Sabrina Carpenter\",\n                                \"Charli XCX\",\n                                \"Elon Musk\",\n                                \"Michelle Obama\",\n                                \"Elvis Presley\",\n                            ],\n                            \"Known_For\": [\n                                \"Established federal government, First U.S. President\",\n                                \"XYZ Affair, Alien and Sedition Acts\",\n                                \"Louisiana Purchase, Declaration of Independence\",\n                                \"War of 1812, Constitution\",\n                                \"Monroe Doctrine, Missouri Compromise\",\n                                \"Created national bank, Federalist Papers\",\n                                \"Nonsense, Emails I Cant Send, Mean Girls musical\",\n                                \"Crash, How Im Feeling Now, Boom Clap\",\n                                \"Tesla, SpaceX, Twitter/X acquisition\",\n                                \"Lets Move campaign, Becoming memoir\",\n                                \"14 Grammys, King of Rock n Roll\",\n                            ],\n                        }\n                    ),\n                    \"Eras\": pd.DataFrame({\"Years\": [\"1800-1900\", \"1900-2000\", \"2000-Now\"]}),\n                },\n                model = LlamaCpp(\n                    model_name_or_path=\"unsloth/gemma-3-4b-it-GGUF\",\n                    filename=\"gemma-3-4b-it-Q4_K_M.gguf\",\n                    config={\n                        \"n_gpu_layers\": -1,\n                        \"n_ctx\": 1028,\n                        \"seed\": 100,\n                        \"n_threads\": psutil.cpu_count(logical=False),\n                    }\n                )\n            )\n\n            smoothie = bsql.execute(\n                \"\"\"\n                SELECT * FROM People P\n                WHERE P.Name IN {{\n                    LLMQA('First 3 presidents of the U.S?', quantifier='{3}')\n                }}\n                \"\"\"\n            )\n\n            print(smoothie.df)\n            # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            # \u2502 Name              \u2502 Known_For                                             \u2502\n            # \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n            # \u2502 George Washington \u2502 Established federal government, First U.S. Preside... \u2502\n            # \u2502 John Quincy Adams \u2502 XYZ Affair, Alien and Sedition Acts                   \u2502\n            # \u2502 Thomas Jefferson  \u2502 Louisiana Purchase, Declaration of Independence       \u2502\n            # \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            smoothie.print_summary()\n            # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            # \u2502   Time (s) \u2502   # Generation Calls \u2502   Prompt Tokens \u2502   Completion Tokens \u2502\n            # \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n            # \u2502    1.25158 \u2502                    1 \u2502             296 \u2502                  16 \u2502\n            # \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            ```\n        '''\n        self._toggle_verbosity(verbose if verbose is not None else self.verbose)\n        logger.debug(Color.horizontal_line())\n        start = time.time()\n        model_in_use = model or self.model\n        try:\n            smoothie = _blend(\n                query=query,\n                db=self.db,\n                default_model=model_in_use,\n                ingredients=self._merge_default_ingredients(\n                    ingredients or self.ingredients\n                ),\n                infer_gen_constraints=infer_gen_constraints\n                if infer_gen_constraints is not None\n                else self.infer_gen_constraints,\n                enable_constrained_decoding=enable_constrained_decoding\n                if enable_constrained_decoding is not None\n                else self.enable_constrained_decoding,\n                enable_cascade_filter=enable_cascade_filter\n                if enable_cascade_filter is not None\n                else self.enable_cascade_filter,\n                enable_early_exit=enable_early_exit\n                if enable_early_exit is not None\n                else self.enable_early_exit,\n                table_to_title=self.table_to_title,\n            )\n        except Exception as error:\n            raise error\n        finally:\n            # In the case of a recursive `_blend()` call,\n            #   this logic allows temp tables to persist until\n            #   the final base case is fulfilled.\n            self.db._reset_connection()\n            # Reset model stats, so future executions don't add here\n            if model_in_use is not None:\n                model_in_use.reset_stats()\n        smoothie.meta.process_time_seconds = time.time() - start\n        logger.debug(Color.horizontal_line())\n        return smoothie\n</code></pre>"},{"location":"reference/execute-blendsql/#blendsql.BlendSQL.execute","title":"<code>execute(query, ingredients=None, model=None, infer_gen_constraints=None, enable_cascade_filter=None, enable_early_exit=None, enable_constrained_decoding=None, verbose=None)</code>","text":"<p>The <code>execute()</code> function is used to execute a BlendSQL query against a database and return the final result, in addition to the intermediate reasoning steps taken. Execution is done on a database given an ingredient context.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The BlendSQL query to execute</p> required <code>ingredients</code> <code>Collection[Type[Ingredient]] | None</code> <p>Collection of ingredient objects, to use in interpreting BlendSQL query. {LLMQA, LLMMap, LLMJoin} are supplied by default.</p> <code>None</code> <code>verbose</code> <code>bool | None</code> <p>Boolean defining whether to run with logger in debug mode</p> <code>None</code> <code>default_model</code> <p>Which BlendSQL model to use in performing ingredient tasks in the current query</p> required <code>infer_gen_constraints</code> <code>bool | None</code> <p>Optionally infer the output format of an <code>IngredientMap</code> call, given the predicate context For example, in <code>{{LLMMap('convert to date', 'w::listing date')}} &lt;= '1960-12-31'</code> We can infer the output format should look like '1960-12-31' and both:     1) Put this string in the <code>example_outputs</code> kwarg     2) If we have a LocalModel, pass the date regex pattern to guidance</p> <code>None</code> <code>enable_cascade_filter</code> <code>bool | None</code> <p>Enable cascade filtering optimization.</p> <code>None</code> <code>enable_early_exit</code> <code>bool | None</code> <p>Enable early exit optimization.</p> <code>None</code> <code>enable_constrained_decoding</code> <code>bool | None</code> <p>Enable constrained decoding for local models.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>smoothie</code> <code>Smoothie</code> <p><code>Smoothie</code> dataclass containing pd.DataFrame output and execution metadata</p> <p>Examples:</p> <pre><code>import psutil\nimport pandas as pd\n\nfrom blendsql import BlendSQL\nfrom blendsql.models import LlamaCpp\n\n# Prepare our BlendSQL connection\nbsql = BlendSQL(\n    {\n        \"People\": pd.DataFrame(\n            {\n                \"Name\": [\n                    \"George Washington\",\n                    \"John Quincy Adams\",\n                    \"Thomas Jefferson\",\n                    \"James Madison\",\n                    \"James Monroe\",\n                    \"Alexander Hamilton\",\n                    \"Sabrina Carpenter\",\n                    \"Charli XCX\",\n                    \"Elon Musk\",\n                    \"Michelle Obama\",\n                    \"Elvis Presley\",\n                ],\n                \"Known_For\": [\n                    \"Established federal government, First U.S. President\",\n                    \"XYZ Affair, Alien and Sedition Acts\",\n                    \"Louisiana Purchase, Declaration of Independence\",\n                    \"War of 1812, Constitution\",\n                    \"Monroe Doctrine, Missouri Compromise\",\n                    \"Created national bank, Federalist Papers\",\n                    \"Nonsense, Emails I Cant Send, Mean Girls musical\",\n                    \"Crash, How Im Feeling Now, Boom Clap\",\n                    \"Tesla, SpaceX, Twitter/X acquisition\",\n                    \"Lets Move campaign, Becoming memoir\",\n                    \"14 Grammys, King of Rock n Roll\",\n                ],\n            }\n        ),\n        \"Eras\": pd.DataFrame({\"Years\": [\"1800-1900\", \"1900-2000\", \"2000-Now\"]}),\n    },\n    model = LlamaCpp(\n        model_name_or_path=\"unsloth/gemma-3-4b-it-GGUF\",\n        filename=\"gemma-3-4b-it-Q4_K_M.gguf\",\n        config={\n            \"n_gpu_layers\": -1,\n            \"n_ctx\": 1028,\n            \"seed\": 100,\n            \"n_threads\": psutil.cpu_count(logical=False),\n        }\n    )\n)\n\nsmoothie = bsql.execute(\n    \"\"\"\n    SELECT * FROM People P\n    WHERE P.Name IN {{\n        LLMQA('First 3 presidents of the U.S?', quantifier='{3}')\n    }}\n    \"\"\"\n)\n\nprint(smoothie.df)\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 Name              \u2502 Known_For                                             \u2502\n# \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n# \u2502 George Washington \u2502 Established federal government, First U.S. Preside... \u2502\n# \u2502 John Quincy Adams \u2502 XYZ Affair, Alien and Sedition Acts                   \u2502\n# \u2502 Thomas Jefferson  \u2502 Louisiana Purchase, Declaration of Independence       \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nsmoothie.print_summary()\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502   Time (s) \u2502   # Generation Calls \u2502   Prompt Tokens \u2502   Completion Tokens \u2502\n# \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n# \u2502    1.25158 \u2502                    1 \u2502             296 \u2502                  16 \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Source code in <code>blendsql/blendsql.py</code> <pre><code>def execute(\n    self,\n    query: str,\n    ingredients: Collection[Type[Ingredient]] | None = None,\n    model: ModelBase | None = None,\n    infer_gen_constraints: bool | None = None,\n    enable_cascade_filter: bool | None = None,\n    enable_early_exit: bool | None = None,\n    enable_constrained_decoding: bool | None = None,\n    verbose: bool | None = None,\n) -&gt; Smoothie:\n    '''The `execute()` function is used to execute a BlendSQL query against a database and\n    return the final result, in addition to the intermediate reasoning steps taken.\n    Execution is done on a database given an ingredient context.\n\n    Args:\n        query: The BlendSQL query to execute\n        ingredients: Collection of ingredient objects, to use in interpreting BlendSQL query.\n            {LLMQA, LLMMap, LLMJoin} are supplied by default.\n        verbose: Boolean defining whether to run with logger in debug mode\n        default_model: Which BlendSQL model to use in performing ingredient tasks in the current query\n        infer_gen_constraints: Optionally infer the output format of an `IngredientMap` call, given the predicate context\n            For example, in `{{LLMMap('convert to date', 'w::listing date')}} &lt;= '1960-12-31'`\n            We can infer the output format should look like '1960-12-31' and both:\n                1) Put this string in the `example_outputs` kwarg\n                2) If we have a LocalModel, pass the date regex pattern to guidance\n        enable_cascade_filter: Enable cascade filtering optimization.\n        enable_early_exit: Enable early exit optimization.\n        enable_constrained_decoding: Enable constrained decoding for local models.\n\n    Returns:\n        smoothie: `Smoothie` dataclass containing pd.DataFrame output and execution metadata\n\n    Examples:\n        ```python\n        import psutil\n        import pandas as pd\n\n        from blendsql import BlendSQL\n        from blendsql.models import LlamaCpp\n\n        # Prepare our BlendSQL connection\n        bsql = BlendSQL(\n            {\n                \"People\": pd.DataFrame(\n                    {\n                        \"Name\": [\n                            \"George Washington\",\n                            \"John Quincy Adams\",\n                            \"Thomas Jefferson\",\n                            \"James Madison\",\n                            \"James Monroe\",\n                            \"Alexander Hamilton\",\n                            \"Sabrina Carpenter\",\n                            \"Charli XCX\",\n                            \"Elon Musk\",\n                            \"Michelle Obama\",\n                            \"Elvis Presley\",\n                        ],\n                        \"Known_For\": [\n                            \"Established federal government, First U.S. President\",\n                            \"XYZ Affair, Alien and Sedition Acts\",\n                            \"Louisiana Purchase, Declaration of Independence\",\n                            \"War of 1812, Constitution\",\n                            \"Monroe Doctrine, Missouri Compromise\",\n                            \"Created national bank, Federalist Papers\",\n                            \"Nonsense, Emails I Cant Send, Mean Girls musical\",\n                            \"Crash, How Im Feeling Now, Boom Clap\",\n                            \"Tesla, SpaceX, Twitter/X acquisition\",\n                            \"Lets Move campaign, Becoming memoir\",\n                            \"14 Grammys, King of Rock n Roll\",\n                        ],\n                    }\n                ),\n                \"Eras\": pd.DataFrame({\"Years\": [\"1800-1900\", \"1900-2000\", \"2000-Now\"]}),\n            },\n            model = LlamaCpp(\n                model_name_or_path=\"unsloth/gemma-3-4b-it-GGUF\",\n                filename=\"gemma-3-4b-it-Q4_K_M.gguf\",\n                config={\n                    \"n_gpu_layers\": -1,\n                    \"n_ctx\": 1028,\n                    \"seed\": 100,\n                    \"n_threads\": psutil.cpu_count(logical=False),\n                }\n            )\n        )\n\n        smoothie = bsql.execute(\n            \"\"\"\n            SELECT * FROM People P\n            WHERE P.Name IN {{\n                LLMQA('First 3 presidents of the U.S?', quantifier='{3}')\n            }}\n            \"\"\"\n        )\n\n        print(smoothie.df)\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 Name              \u2502 Known_For                                             \u2502\n        # \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n        # \u2502 George Washington \u2502 Established federal government, First U.S. Preside... \u2502\n        # \u2502 John Quincy Adams \u2502 XYZ Affair, Alien and Sedition Acts                   \u2502\n        # \u2502 Thomas Jefferson  \u2502 Louisiana Purchase, Declaration of Independence       \u2502\n        # \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        smoothie.print_summary()\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502   Time (s) \u2502   # Generation Calls \u2502   Prompt Tokens \u2502   Completion Tokens \u2502\n        # \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n        # \u2502    1.25158 \u2502                    1 \u2502             296 \u2502                  16 \u2502\n        # \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        ```\n    '''\n    self._toggle_verbosity(verbose if verbose is not None else self.verbose)\n    logger.debug(Color.horizontal_line())\n    start = time.time()\n    model_in_use = model or self.model\n    try:\n        smoothie = _blend(\n            query=query,\n            db=self.db,\n            default_model=model_in_use,\n            ingredients=self._merge_default_ingredients(\n                ingredients or self.ingredients\n            ),\n            infer_gen_constraints=infer_gen_constraints\n            if infer_gen_constraints is not None\n            else self.infer_gen_constraints,\n            enable_constrained_decoding=enable_constrained_decoding\n            if enable_constrained_decoding is not None\n            else self.enable_constrained_decoding,\n            enable_cascade_filter=enable_cascade_filter\n            if enable_cascade_filter is not None\n            else self.enable_cascade_filter,\n            enable_early_exit=enable_early_exit\n            if enable_early_exit is not None\n            else self.enable_early_exit,\n            table_to_title=self.table_to_title,\n        )\n    except Exception as error:\n        raise error\n    finally:\n        # In the case of a recursive `_blend()` call,\n        #   this logic allows temp tables to persist until\n        #   the final base case is fulfilled.\n        self.db._reset_connection()\n        # Reset model stats, so future executions don't add here\n        if model_in_use is not None:\n            model_in_use.reset_stats()\n    smoothie.meta.process_time_seconds = time.time() - start\n    logger.debug(Color.horizontal_line())\n    return smoothie\n</code></pre>"},{"location":"reference/execute-blendsql/#blendsql.BlendSQL.visualize","title":"<code>visualize(query, output_path=None, format='pdf')</code>","text":"<p>Visualize query as a DAG with graphviz.</p> Source code in <code>blendsql/blendsql.py</code> <pre><code>def visualize(self, query: str, output_path: str | None = None, format=\"pdf\"):\n    \"\"\"Visualize query as a DAG with graphviz.\"\"\"\n    from .visualize import SQLGlotASTVisualizer\n\n    visualizer = SQLGlotASTVisualizer()\n\n    dialect: sqlglot.Dialect = get_dialect(self.db.__class__.__name__)\n\n    # Generate visualization\n    dot = visualizer.visualize(\n        _parse_one(query, dialect=dialect, schema=self.db.sqlglot_schema)\n    )\n\n    if output_path is not None:\n        # Save as PDF\n        dot.render(output_path, format=format, cleanup=True)\n    return dot\n</code></pre>"},{"location":"reference/functions/","title":"BlendSQL Functions","text":"<p>All BlendSQL LM functions (sometimes referred to as <code>Ingredients</code> in the codebase) are polymorphic, meaning that can return many different types depending on expression context and user arguments.</p>"},{"location":"reference/functions/#general-syntax","title":"General Syntax","text":""},{"location":"reference/functions/#valuearray","title":"<code>ValueArray</code>","text":"<p>A <code>ValueArray</code> is a reference to a list of values. This can be written using:</p> <ul> <li> <p>Standard column <code>{tablename}.{columnname}</code> syntax (<code>tablename</code> can be ommitted, and standard SQL binding logic will apply)</p> </li> <li> <p>SQL tuple (<code>(value1, value2)</code>) syntax</p> </li> <li> <p>A BlendSQL query which returns a 1d array of values (<code>(SELECT value FROM table WHERE ...)</code>)</p> </li> </ul>"},{"location":"reference/functions/#passing-options","title":"Passing <code>options</code>","text":"<p>The functions <code>LLMMap</code> and <code>LLMQA</code> support the passing of an <code>options</code> argument. This will constrain the output of the functions to only values appearing in the passed <code>ValueArray</code>.</p> <pre><code>SELECT {{\n    LLMMap(\n        'What is the sentiment of this text?',\n        content,\n        options=('positive', 'negative')\n    )      \n}}, content AS classification FROM posts LIMIT 10\n</code></pre>"},{"location":"reference/functions/#quantifier","title":"<code>Quantifier</code>","text":"<p>An optional <code>quantifier</code> argument can be passed to <code>LLMQA</code> and <code>LLMMap</code>, which will be used to modify the regular expression pattern powering the constrained decoding. For example:</p> <pre><code>SELECT {{\n    LLMMap(\n        'What are their interests?',\n        context_column,\n        quantifier='+'\n    )\n}} FROM People\n</code></pre> <p>Since we're asking for 'one-or-more' via the quantifier arg and the default <code>return_type</code> (as of v0.0.61) is <code>str</code>, BlendSQL casts the <code>return_type</code> to a <code>List[str]</code>. </p> <p>The following greedy quantifiers are valid:</p> <ul> <li><code>'*'</code>, meaning 'zero-or-more'</li> <li><code>'+</code>', meaning 'one-or-more'</li> <li>Any string matching the pattern <code>{\\d(,\\d)?}</code> (e.g. <code>{1,2}</code>)</li> <li></li> </ul>"},{"location":"reference/functions/#functions","title":"Functions","text":""},{"location":"reference/functions/#llmqa","title":"LLMQA","text":"<p>The <code>LLMQA</code> is an aggregate function which transforms a subset of data into a single-cell output. This output can be a single atomic type (<code>return_type='str'</code>), or a single nested collection (<code>return_type='List[str]'</code>). </p> <pre><code>def LLMQA(\n    question: str,\n    *context: Query,\n    options: Optional[ValueArray] = None,\n    return_type: Optional[ReturnType] = None,\n    regex: Optional[str] = None,\n    quantifier: Optional[Quantifier] = None\n):\n    ...\n</code></pre> <p>Examples: <pre><code>SELECT preferred_foot FROM Player p\nWHERE p.player_name = {{\n    /* With `infer_gen_constraints=True` (which is default),\n    `options` will automatically be inferred, and the below\n    will select from a value in the `p.player_name` column. */\n    LLMQA(\n        \"Which player has the most Ballon d'Or awards?\"\n    )\n}}\n</code></pre></p> <pre><code>SELECT name FROM state_flowers\nWHERE state = {{\n    LLMQA(\n        \"Which state is known as 'The Golden State'?\",\n        /* Pass context via a subquery */\n        (SELECT title, content FROM documents)\n    )\n}}\n</code></pre> <pre><code>/* Generate 3 values in our generated tuple */\nSELECT * FROM VALUES {{LLMQA('What are the first 3 letters of the alphabet?', quantifier='{3}')}}\n</code></pre> <pre><code>SELECT {{\n    LLMQA(\n        /* Use f-string templating to insert the result of subqueries*/\n        'What do {} and {} have in common?',\n        /* Below are examples - any BlendSQL queries are valid here, \n        but they should return a single scalar value.   \n        */\n        (SELECT 'Saturn'),\n        (SELECT 'Jupiter')\n    )    \n}}\n</code></pre>"},{"location":"reference/functions/#also-see","title":"Also See:","text":"<ul> <li>LLMQA with search</li> <li>LLMQA with search + f-string templating</li> </ul>"},{"location":"reference/functions/#llmmap","title":"LLMMap","text":"<p>The <code>LLMMap</code> is a unary scalar function, much like <code>LENGTH</code> or <code>ABS</code> in SQlite. The output of this function is set as a new column in a temporary table, for later use within the wider query.</p> <pre><code>def LLMMap(\n    question: str,\n    values: ColumnRef,\n    *additional_args: ColumnRef,\n    context: Query = None,\n    options: Optional[ValueArray] = None,\n    return_type: Optional[ReturnType] = None,\n    regex: Optional[str] = None\n):\n    ...\n</code></pre> <p>Examples: <pre><code>SELECT COUNT(DISTINCT(s.CDSCode)) FROM schools s\nJOIN satscores sa ON s.CDSCode = sa.cds\nWHERE sa.AvgScrMath &gt; 560\n/* With `infer_gen_constraints=True`, generations below will be restricted to a boolean. */\nAND {{LLMMap('Is this a county in the California Bay Area?', s.County)}} = TRUE\n</code></pre></p> <pre><code>SELECT GROUP_CONCAT(Name, ', ') AS Names,\n{{\n    LLMMap(\n        'In which time period was this person born?',\n        p.Name,\n        /* BlendSQL differs from standard SQL binding logic below, \n        since we can invoke a table (`Eras`) not previously referenced */\n        options=Eras.Years\n    )\n}} AS Born\nFROM People p\nGROUP BY Born\n</code></pre> <pre><code>WITH player_stats AS (\n    SELECT *, {{\n        LLMMap(\n            'How many points and assists did {} have? Respond in the order [points, assists]. If a stat is not present for a player, return -1.', \n            player, \n            Report, /* Pass `Report` in as context for each `player` */\n            return_type='List[int]',\n            quantifier='{2}'\n        )\n    }} AS box_score_values\n    FROM w\n) SELECT \nplayer,\nReport,\nlist_element(box_score_values, 1) AS points,\nlist_element(box_score_values, 2) AS assists\nFROM player_stats\n</code></pre>"},{"location":"reference/functions/#also-see_1","title":"Also See:","text":"<ul> <li>LLMMap with search</li> <li>Mapping with <code>return_type='substring'</code></li> </ul>"},{"location":"reference/functions/#llmjoin","title":"LLMJoin","text":"<p>The <code>LLMJoin</code> function can be used to perform semantic entity linking between columns in tables. It is commonly used in conjunction with a <code>documents</code> table, to fetch articles related to a value in another table.</p> <pre><code>def LLMJoin(\n    left_on: ValueArray,\n    right_on: ValueArray,\n    join_criteria: Optional[str] = \"Join to same topics.\"\n):\n    ...\n</code></pre> <p>Examples: <pre><code>-- Get all articles on players older than 21\nSELECT * FROM Player p\nJOIN documents d ON {{\n    LLMJoin(\n        p.Name,\n        d.title\n    )\n}} WHERE p.age &gt; 21\n</code></pre></p> <pre><code>SELECT f.name, c.name FROM fruits f\nJOIN colors c ON {{\n    LLMJoin(\n        f.name,\n        c.name,\n        /* If we need to, we can pass a join_criteria.\n        Otherwise, the default 'Join by topic' is used. */\n        join_criteria='Align the fruit to its color.'\n    )\n}}\n</code></pre>"},{"location":"reference/query_optimization/","title":"Query optimization","text":""},{"location":"reference/query_optimization/#querycontextmanager","title":"QueryContextManager","text":"Source code in <code>blendsql/parse/parse.py</code> <pre><code>@dataclass\nclass QueryContextManager:\n    dialect: sqlglot.Dialect = field()\n    node: exp.Expression = field(default=None)\n\n    def parse(self, query: str, schema: dict | Schema | None = None):\n        self.node = _parse_one(query, dialect=self.dialect, schema=schema)\n\n    def to_string(self):\n        return self.node.sql(dialect=self.dialect)\n</code></pre>"},{"location":"reference/query_optimization/#subquerycontextmanager","title":"SubqueryContextManager","text":"Source code in <code>blendsql/parse/parse.py</code> <pre><code>@dataclass\nclass SubqueryContextManager:\n    dialect: sqlglot.Dialect = field()\n    node: exp.Select = field()\n    prev_subquery_has_ingredient: bool = field()\n    ingredient_alias_to_parsed_dict: dict = field()\n\n    # Keep a running log of what aliases we've initialized so far, per subquery\n    alias_to_subquery: dict = field(default_factory=dict)\n    alias_to_tablename: dict = field(default_factory=dict)\n    tablename_to_alias: dict = field(default_factory=dict)\n\n    root: sqlglot.optimizer.scope.Scope = field(init=False)\n    stateful_columns_referenced_by_lm_ingredients: dict = field(init=False)\n    function_references: list[exp.Expression] = field(init=False)\n\n    def __post_init__(self):\n        self.alias_to_tablename = dict()\n        self.tablename_to_alias = dict()\n        self.self_join_tablenames = set()\n        # https://github.com/tobymao/sqlglot/blob/v20.9.0/posts/ast_primer.md#scope\n        self.root = build_scope(self.node)\n        self.stateful_columns_referenced_by_lm_ingredients = (\n            self.get_stateful_columns_referenced_by_lm_functions(\n                self.ingredient_alias_to_parsed_dict\n            )\n        )\n        self.function_references = list(self.node.find_all(exp.BlendSQLFunction))\n        self._gather_alias_mappings()\n        self.return_type_inferrer = ReturnTypeInferrer()\n\n    def _reset_root(self):\n        self.root = build_scope(self.node)\n\n    def set_node(self, node):\n        self.node = node\n        self._reset_root()\n\n    def get_stateful_columns_referenced_by_lm_functions(\n        self, ingredient_alias_to_parsed_dict: dict\n    ):\n        stateful_columns_referenced_by_lm_functions = {}\n        ingredient_aliases = [i.name for i in check.get_ingredient_nodes(self.node)]\n\n        def _process_single(arg: ColumnRef):\n            tablename, columnname = get_tablename_colname(arg)\n            if tablename not in stateful_columns_referenced_by_lm_functions:\n                stateful_columns_referenced_by_lm_functions[tablename] = set()\n            stateful_columns_referenced_by_lm_functions[tablename].add(columnname)\n\n        for ingredient_alias in ingredient_aliases:\n            kwargs_dict = ingredient_alias_to_parsed_dict[ingredient_alias][\n                \"kwargs_dict\"\n            ]\n            for raw_arg in {\n                # Below lists all arguments where a table may be referenced\n                # We omit `options`, since this should not take into account the\n                #   state of the filtered database.\n                kwargs_dict.get(\"context\", None),\n                kwargs_dict.get(\"values\", None),\n                kwargs_dict.get(\"additional_args\", None),\n                kwargs_dict.get(\"left_on\", None),\n                kwargs_dict.get(\"right_on\", None),\n            }:\n                args = raw_arg\n                if not isinstance(raw_arg, (tuple, list)):\n                    args = [raw_arg]\n                for arg in args:\n                    if arg is None:\n                        continue\n                    if isinstance(arg, StringConcatenation):\n                        for column in arg:\n                            _process_single(column)\n                    elif isinstance(arg, ColumnRef):\n                        _process_single(arg)\n                    # If `context` is a subquery, this gets executed on its own later, so we don't handle it here.\n        return stateful_columns_referenced_by_lm_functions\n\n    def abstracted_table_selects(\n        self, db: Database\n    ) -&gt; Generator[tuple[str, str], None, None]:\n        \"\"\"For each table in a given query, generates a `SELECT *` query where all unneeded predicates\n        are set to `TRUE`.\n        We say `unneeded` in the sense that to minimize the data that gets passed to an ingredient,\n        we don't need to factor in this operation at the moment.\n\n        Args:\n            node: exp.Select node from which to construct abstracted versions of queries for each table.\n\n        Returns:\n            abstracted_queries: Generator with (tablename, abstracted_query_str).\n\n        Examples:\n            ```python\n            scm = SubqueryContextManager(\n                node=_parse_one(\n                    \"SELECT * FROM transactions WHERE {{Model('is this an italian restaurant?', 'transactions::merchant')}} = TRUE AND child_category = 'Restaurants &amp; Dining'\"\n                )\n            )\n            scm.abstracted_table_selects()\n            ```\n            Returns:\n            ```text\n            ('transactions', 'SELECT * FROM transactions WHERE TRUE AND child_category = \\'Restaurants &amp; Dining\\'')\n            ```\n        \"\"\"\n        # If we don't have an ingredient at the top-level, we can safely ignore\n        if len(self.stateful_columns_referenced_by_lm_ingredients) == 0:\n            return\n\n        abstracted_query = self.node.transform(transform.set_ingredient_nodes_to_true)\n\n        # Prepare join metadata if multiple tables are referenced\n        abstracted_join_temp_tablename = None\n        all_tablename_or_aliasnames = []\n        all_columnnames = []\n\n        if len(self.stateful_columns_referenced_by_lm_ingredients) &gt; 1:\n            all_resolved_tablenames = []\n            for (\n                tablename_or_aliasname,\n                columnnames,\n            ) in self.stateful_columns_referenced_by_lm_ingredients.items():\n                tablename = self.alias_to_tablename.get(\n                    tablename_or_aliasname, tablename_or_aliasname\n                )\n                all_resolved_tablenames.append(tablename)\n                columnnames = list(columnnames)\n                all_tablename_or_aliasnames.extend(\n                    [tablename_or_aliasname] * len(columnnames)\n                )\n                all_columnnames.extend(columnnames)\n\n            abstracted_join_temp_tablename = \"_JOIN_\".join(all_resolved_tablenames)\n\n        def prepare_joined_temp_table():\n            abstracted_join_str = set_select_to(\n                node=abstracted_query,\n                tablenames=all_tablename_or_aliasnames,\n                columnnames=all_columnnames,\n                aliasnames=[\n                    f\"{c}_{t}\"\n                    for c, t in zip(all_columnnames, all_tablename_or_aliasnames)\n                ],\n            ).sql(dialect=self.dialect)\n            logger.debug(\n                Color.update(\"Executing \")\n                + Color.sql(abstracted_join_str, ignore_prefix=True)\n                + Color.update(\n                    f\" and setting to `{abstracted_join_temp_tablename}`...\",\n                    ignore_prefix=True,\n                )\n            )\n            abstracted_join_df = db.execute_to_df(abstracted_join_str)\n            db.to_temp_table(\n                df=abstracted_join_df, tablename=abstracted_join_temp_tablename\n            )\n\n        def _result(abstracted_query, tablename_or_aliasname, columnnames):\n            resolved_tablename = self.alias_to_tablename.get(\n                tablename_or_aliasname, tablename_or_aliasname\n            )\n            if abstracted_join_temp_tablename is not None:\n                query = set_select_to(\n                    exp.Select(\n                        expressions=[exp.Star()],\n                        from_=exp.From(\n                            this=exp.Table(\n                                this=exp.Identifier(this=abstracted_join_temp_tablename)\n                            )\n                        ),\n                    ),\n                    tablenames=[abstracted_join_temp_tablename] * len(columnnames),\n                    columnnames=[f\"{c}_{tablename_or_aliasname}\" for c in columnnames],\n                    aliasnames=list(columnnames),\n                )\n            else:\n                query = set_select_to(\n                    abstracted_query,\n                    [tablename_or_aliasname] * len(columnnames),\n                    list(columnnames),\n                )\n            return (resolved_tablename, has_join, query.sql(dialect=self.dialect))\n\n        has_join = self.node.find(exp.Join) is not None\n\n        # Special condition: If we *only* have an ingredient in the top-level `SELECT` clause,\n        #   then we can be more aggressive and execute the ENTIRE rest of SQL first and assign to temporary session table.\n        # Example: \"\"\"SELECT w.title, w.\"designer ( s )\", {{LLMMap('How many animals are in this image?', 'images::title')}}\n        #    FROM images JOIN w ON w.title = images.title\n        #    WHERE \"designer ( s )\" = 'georgia gerber'\"\"\"\n        # Below, we also need `self.node.find(exp.Table)` in case we get a QAIngredient on its own\n        #   E.g. `SELECT A() AS _col_0` cases should be ignored\n        if (\n            self.node.find(exp.Table)\n            and check.ingredients_only_in_top_select(self.node)\n            and not check.ingredient_alias_in_query_body(self.node)\n        ):\n            if abstracted_join_temp_tablename is not None:\n                prepare_joined_temp_table()\n            for (\n                tablename_or_aliasname,\n                columnnames,\n            ) in self.stateful_columns_referenced_by_lm_ingredients.items():\n                yield _result(abstracted_query, tablename_or_aliasname, columnnames)\n            return\n\n        # Base case is below\n        abstracted_query = abstracted_query.transform(\n            transform.remove_nodetype,\n            (exp.Order, exp.Limit, exp.Group, exp.Offset, exp.Having),\n        )\n        # If our previous subquery has an ingredient, we can't optimize with subquery condition\n        # So, remove this subquery constraint and run\n        if self.prev_subquery_has_ingredient:\n            abstracted_query = abstracted_query.transform(\n                transform.maybe_set_subqueries_to_true\n            )\n        # Happens with {{LLMQA()}} cases, where we get 'SELECT *'\n        if abstracted_query.find(exp.Table) is None:\n            return\n        # Check here to see if we have no other predicates other than 'WHERE TRUE'\n        # There's no point in creating a temporary table in this situation\n        where_node = abstracted_query.find(exp.Where)\n        join_node = abstracted_query.find(exp.Join)\n        # If we have a join_node that's a cross join ('JOIN \"colors\" ON TRUE'),\n        #   this was likely created by a LLMJoin ingredient.\n        #   We don't need to create temp tables for these.\n        # TODO: This cross join is inefficient, make it a union\n        is_cross_join = lambda node: node.args.get(\"on\", None) == exp.true()\n        ignore_join = bool(not join_node or is_cross_join(join_node))\n\n        if ignore_join and where_node:\n            where_this = where_node.args[\"this\"]\n            if (\n                where_this == exp.true()\n                or isinstance(where_this, exp.Column)\n                or check.all_terminals_are_true(where_node)\n            ):\n                return\n        elif not ignore_join and where_node is None:\n            return\n\n        if abstracted_join_temp_tablename is not None:\n            prepare_joined_temp_table()\n\n        for (\n            tablename_or_aliasname,\n            columnnames,\n        ) in self.stateful_columns_referenced_by_lm_ingredients.items():\n            yield _result(abstracted_query, tablename_or_aliasname, columnnames)\n        return\n\n    def _gather_alias_mappings(\n        self,\n    ) -&gt; Generator[tuple[str, exp.Select], None, None]:\n        \"\"\"For each table in the select query, generates a new query\n            selecting all columns with the given predicates (Relationships like x = y, x &gt; 1, x &gt;= y).\n\n        Args:\n            node: The exp.Select node containing the query to extract table_star queries for\n\n        Returns:\n            table_star_queries: Generator with (tablename, exp.Select). The exp.Select is the table_star query\n\n        Examples:\n            ```sql\n            SELECT \"Run Date\", Account, Action, ROUND(\"Amount ($)\", 2) AS 'Total Dividend Payout ($$)', Name\n                FROM account_history\n                LEFT JOIN constituents ON account_history.Symbol = constituents.Symbol\n                WHERE constituents.Sector = 'Information Technology'\n                AND lower(Action) like \"%dividend%\"\n            ```\n        \"\"\"\n        # Use `scope` to get all unique tablenodes in ast\n        tablenodes = set(\n            list(\n                get_scope_nodes(nodetype=exp.Table, root=self.root, restrict_scope=True)\n            )\n        )\n        # aliasnodes catch instances where we do something like\n        #   `SELECT (SELECT * FROM x) AS w`\n        curr_alias_to_tablename = {}\n        curr_alias_to_subquery = {}\n        subquery_node = self.node.find(exp.Subquery)\n        if subquery_node is not None:\n            # Make a note here: we need to create a new table with the name of the alias,\n            #   and set to results of this subquery\n            alias = None\n            if \"alias\" in subquery_node.args:\n                alias = subquery_node.args[\"alias\"]\n            if alias is None:\n                # Try to get from parent\n                parent_node = subquery_node.parent\n                if parent_node is not None:\n                    if \"alias\" in parent_node.args:\n                        alias = parent_node.args[\"alias\"]\n            if alias is not None:\n                if not any(x.name == alias.name for x in tablenodes):\n                    tablenodes.add(exp.Table(this=exp.Identifier(this=alias.name)))\n                curr_alias_to_subquery = {alias.name: subquery_node.args[\"this\"]}\n        for tablenode in tablenodes:\n            # Check to be sure this is in the top-level `SELECT`\n            if check.in_subquery(tablenode):\n                continue\n            # Check to see if we have a table alias\n            # e.g. `SELECT a FROM table AS w`\n            table_alias_node = tablenode.find(exp.TableAlias)\n            if table_alias_node is not None:\n                curr_alias_to_tablename = {table_alias_node.name: tablenode.name}\n            self.alias_to_tablename |= curr_alias_to_tablename\n            self.tablename_to_alias |= {\n                v: k for k, v in curr_alias_to_tablename.items()\n            }\n\n            self.alias_to_subquery |= curr_alias_to_subquery\n        self.self_join_tablenames.update(\n            [\n                table\n                for table, count in Counter(self.alias_to_tablename.values()).items()\n                if count &gt; 1\n            ]\n        )\n\n    def maybe_resolve_aliased_function(\n        self, function_node: exp.Expression\n    ) -&gt; exp.Expression:\n        \"\"\"More specifically, this function takes an exp.BlendSQLFunction, and returns an exp.BlendSQLFunction.\"\"\"\n        # is this function_node an alias in a `SELECT` statement?\n        if isinstance(function_node.parent, exp.Alias):\n            for _node in self.function_references:\n                if (\n                    isinstance(_node.parent, exp.Binary)\n                    and _node.this == function_node.this\n                ):\n                    return _node\n                    # TODO: this can be made more robust by finding ALL references of this function,\n                    #   and seeing if we can combine them into a single exit_condition.\n        return function_node\n\n    def get_exit_condition(\n        self, function_node: exp.Expression\n    ) -&gt; tuple[Callable, int] | tuple[None, None]:\n        limit_node = self.node.find(exp.Limit)\n        if limit_node is None:\n            return (None, None)\n\n        def _has_unsafe_or(node):\n            \"\"\"\n            An OR is unsafe if it's not contained within parentheses\n            at the WHERE clause level.\n            \"\"\"\n            for or_node in node.find_all(exp.Or):\n                # Check if this OR has a Paren as an ancestor before hitting WHERE/AND\n                parent = or_node.parent\n                while parent and parent != node:\n                    if isinstance(parent, exp.Paren):\n                        break\n                    if isinstance(parent, (exp.Where, exp.And)):\n                        return True\n                    parent = parent.parent\n            return False\n\n        # First, check for expressions that always invalidate early exit\n        if (\n            self.node.find(exp.Group)\n            or self.node.find(exp.Order)\n            or self.node.find(exp.Distinct)\n        ):\n            return (None, None)\n\n        # For `OR`, we need to check if it appears at the \"top level\"\n        # vs being contained within a subexpression\n        # `... {{A()}} AND (x OR y) LIMIT 5` should still be eligible for an exit condition\n        where_clause = self.node.find(exp.Where)\n        if where_clause and _has_unsafe_or(where_clause):\n            return (None, None)\n\n        function_node = self.maybe_resolve_aliased_function(function_node)\n\n        if isinstance(function_node.parent, (exp.Binary, exp.In)):\n            # We can apply some exit_condition function\n            limit_arg: int = limit_node.expression.to_py()\n            offset_node = self.node.find(exp.Offset)\n            offset_arg = 0\n            if offset_node:\n                offset_arg: int = offset_node.expression.to_py()\n\n            parent_node = function_node.parent\n            arg = parent_node.expression.to_py()\n            num_required_values = limit_arg + offset_arg\n\n            if arg == function_node:\n                return (None, None)\n            if isinstance(parent_node, exp.EQ):\n                return (lambda v: v == arg, num_required_values)\n            elif isinstance(parent_node, exp.GT):\n                return (lambda v: v &gt; arg, num_required_values)\n            elif isinstance(parent_node, exp.GTE):\n                return (lambda v: v &gt;= arg, num_required_values)\n            elif isinstance(parent_node, exp.LT):\n                return (lambda v: v &lt; arg, num_required_values)\n            elif isinstance(parent_node, exp.LTE):\n                return (lambda v: v &lt;= arg, num_required_values)\n            elif isinstance(parent_node, exp.Like):\n                # First we need to convert SQL pattern to regex\n                re_pattern = re.escape(arg).replace(r\"\\%\", \".*\")\n                return (lambda v: re.search(re_pattern, v), num_required_values)\n            elif isinstance(parent_node, exp.Is):\n                return (lambda v: v is arg, num_required_values)\n            elif isinstance(parent_node, exp.Not):\n                return (lambda v: not v, num_required_values)\n            elif isinstance(parent_node, exp.In):\n                print()\n            # TODO: add more\n        return (None, None)\n\n    def is_eligible_for_cascade_filter(self) -&gt; bool:\n        \"\"\"\n        A query is eligible for cascade filtering if:\n        1. It's a single-table query\n        2. It has 2+ BlendSQL functions in the WHERE clause\n        3. Those functions are not separated by OR operators\n        4. There are no BlendSQL functions outside the WHERE clause (not yet supported)\n        \"\"\"\n\n        where_node = self.node.find(exp.Where)\n        if where_node is None:\n            return False\n\n        # Count BlendSQL functions in WHERE clause\n        blendsql_functions_in_where = [\n            n for n in where_node.walk() if isinstance(n, exp.BlendSQLFunction)\n        ]\n\n        # Need at least 2 functions to cascade\n        if len(blendsql_functions_in_where) &lt; 2:\n            return False\n\n        select_node = self.node.find(exp.Select)\n        if select_node is None:\n            return False\n\n        # Count BlendSQL functions in WHERE clause\n        blendsql_functions_in_select = [\n            n for n in select_node.walk() if isinstance(n, exp.BlendSQLFunction)\n        ]\n\n        def has_or_with_blendsql(node):\n            \"\"\"Check if node is/contains OR with BlendSQL functions in different branches\"\"\"\n            if node is None:\n                return False\n            if isinstance(node, exp.Or):\n                # Check if both sides of OR contain BlendSQL functions\n                left_has_blendsql = any(\n                    isinstance(n, exp.BlendSQLFunction) for n in node.left.walk()\n                )\n                right_has_blendsql = any(\n                    isinstance(n, exp.BlendSQLFunction) for n in node.right.walk()\n                )\n\n                # If BlendSQL functions exist in the OR, cascading is unsafe\n                if left_has_blendsql or right_has_blendsql:\n                    return True\n\n            # Recursively check children\n            for child in node.iter_expressions():\n                if has_or_with_blendsql(child):\n                    return True\n            return False\n\n        # Check if there's an OR that makes cascading unsafe\n        if has_or_with_blendsql(where_node):\n            return False\n\n        # Check for BlendSQL functions outside WHERE clause\n        all_blendsql_functions = [\n            n for n in self.node.walk() if isinstance(n, exp.BlendSQLFunction)\n        ]\n\n        if len(all_blendsql_functions) &gt; (\n            len(blendsql_functions_in_where) + len(blendsql_functions_in_select)\n        ):\n            logger.debug(\n                Color.error(\n                    \"Cascade filtering optimization is not yet supported for queries with \"\n                    \"BlendSQL functions outside the WHERE or SELECT clause (e.g., in ORDER BY, HAVING, etc.)\"\n                )\n            )\n            return False\n\n        return True\n\n    def infer_gen_constraints(\n        self,\n        function_node: exp.Expression,\n        schema: dict,\n        alias_to_tablename: dict,\n        has_user_regex: bool,\n    ) -&gt; dict:\n        \"\"\"\n        Convenience function matching the original method signature.\n\n        Args:\n            function_node: The expression node containing the BlendSQL function\n            schema: Database schema mapping table names to column types\n            alias_to_tablename: Mapping of table aliases to actual table names\n            has_user_regex: Whether the user has provided a custom regex\n\n        Returns:\n            Dict with inferred generation constraints\n        \"\"\"\n        return self.return_type_inferrer(\n            function_node=self.maybe_resolve_aliased_function(function_node),\n            schema=schema,\n            alias_to_tablename=alias_to_tablename,\n            has_user_regex=has_user_regex,\n        )\n\n    def sql(self):\n        return self.node.sql(dialect=self.dialect)\n</code></pre>"},{"location":"reference/query_optimization/#blendsql.parse.parse.SubqueryContextManager.abstracted_table_selects","title":"<code>abstracted_table_selects(db)</code>","text":"<p>For each table in a given query, generates a <code>SELECT *</code> query where all unneeded predicates are set to <code>TRUE</code>. We say <code>unneeded</code> in the sense that to minimize the data that gets passed to an ingredient, we don't need to factor in this operation at the moment.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <p>exp.Select node from which to construct abstracted versions of queries for each table.</p> required <p>Returns:</p> Name Type Description <code>abstracted_queries</code> <code>None</code> <p>Generator with (tablename, abstracted_query_str).</p> <p>Examples:</p> <p><pre><code>scm = SubqueryContextManager(\n    node=_parse_one(\n        \"SELECT * FROM transactions WHERE {{Model('is this an italian restaurant?', 'transactions::merchant')}} = TRUE AND child_category = 'Restaurants &amp; Dining'\"\n    )\n)\nscm.abstracted_table_selects()\n</code></pre> Returns: <pre><code>('transactions', 'SELECT * FROM transactions WHERE TRUE AND child_category = 'Restaurants &amp; Dining'')\n</code></pre></p> Source code in <code>blendsql/parse/parse.py</code> <pre><code>def abstracted_table_selects(\n    self, db: Database\n) -&gt; Generator[tuple[str, str], None, None]:\n    \"\"\"For each table in a given query, generates a `SELECT *` query where all unneeded predicates\n    are set to `TRUE`.\n    We say `unneeded` in the sense that to minimize the data that gets passed to an ingredient,\n    we don't need to factor in this operation at the moment.\n\n    Args:\n        node: exp.Select node from which to construct abstracted versions of queries for each table.\n\n    Returns:\n        abstracted_queries: Generator with (tablename, abstracted_query_str).\n\n    Examples:\n        ```python\n        scm = SubqueryContextManager(\n            node=_parse_one(\n                \"SELECT * FROM transactions WHERE {{Model('is this an italian restaurant?', 'transactions::merchant')}} = TRUE AND child_category = 'Restaurants &amp; Dining'\"\n            )\n        )\n        scm.abstracted_table_selects()\n        ```\n        Returns:\n        ```text\n        ('transactions', 'SELECT * FROM transactions WHERE TRUE AND child_category = \\'Restaurants &amp; Dining\\'')\n        ```\n    \"\"\"\n    # If we don't have an ingredient at the top-level, we can safely ignore\n    if len(self.stateful_columns_referenced_by_lm_ingredients) == 0:\n        return\n\n    abstracted_query = self.node.transform(transform.set_ingredient_nodes_to_true)\n\n    # Prepare join metadata if multiple tables are referenced\n    abstracted_join_temp_tablename = None\n    all_tablename_or_aliasnames = []\n    all_columnnames = []\n\n    if len(self.stateful_columns_referenced_by_lm_ingredients) &gt; 1:\n        all_resolved_tablenames = []\n        for (\n            tablename_or_aliasname,\n            columnnames,\n        ) in self.stateful_columns_referenced_by_lm_ingredients.items():\n            tablename = self.alias_to_tablename.get(\n                tablename_or_aliasname, tablename_or_aliasname\n            )\n            all_resolved_tablenames.append(tablename)\n            columnnames = list(columnnames)\n            all_tablename_or_aliasnames.extend(\n                [tablename_or_aliasname] * len(columnnames)\n            )\n            all_columnnames.extend(columnnames)\n\n        abstracted_join_temp_tablename = \"_JOIN_\".join(all_resolved_tablenames)\n\n    def prepare_joined_temp_table():\n        abstracted_join_str = set_select_to(\n            node=abstracted_query,\n            tablenames=all_tablename_or_aliasnames,\n            columnnames=all_columnnames,\n            aliasnames=[\n                f\"{c}_{t}\"\n                for c, t in zip(all_columnnames, all_tablename_or_aliasnames)\n            ],\n        ).sql(dialect=self.dialect)\n        logger.debug(\n            Color.update(\"Executing \")\n            + Color.sql(abstracted_join_str, ignore_prefix=True)\n            + Color.update(\n                f\" and setting to `{abstracted_join_temp_tablename}`...\",\n                ignore_prefix=True,\n            )\n        )\n        abstracted_join_df = db.execute_to_df(abstracted_join_str)\n        db.to_temp_table(\n            df=abstracted_join_df, tablename=abstracted_join_temp_tablename\n        )\n\n    def _result(abstracted_query, tablename_or_aliasname, columnnames):\n        resolved_tablename = self.alias_to_tablename.get(\n            tablename_or_aliasname, tablename_or_aliasname\n        )\n        if abstracted_join_temp_tablename is not None:\n            query = set_select_to(\n                exp.Select(\n                    expressions=[exp.Star()],\n                    from_=exp.From(\n                        this=exp.Table(\n                            this=exp.Identifier(this=abstracted_join_temp_tablename)\n                        )\n                    ),\n                ),\n                tablenames=[abstracted_join_temp_tablename] * len(columnnames),\n                columnnames=[f\"{c}_{tablename_or_aliasname}\" for c in columnnames],\n                aliasnames=list(columnnames),\n            )\n        else:\n            query = set_select_to(\n                abstracted_query,\n                [tablename_or_aliasname] * len(columnnames),\n                list(columnnames),\n            )\n        return (resolved_tablename, has_join, query.sql(dialect=self.dialect))\n\n    has_join = self.node.find(exp.Join) is not None\n\n    # Special condition: If we *only* have an ingredient in the top-level `SELECT` clause,\n    #   then we can be more aggressive and execute the ENTIRE rest of SQL first and assign to temporary session table.\n    # Example: \"\"\"SELECT w.title, w.\"designer ( s )\", {{LLMMap('How many animals are in this image?', 'images::title')}}\n    #    FROM images JOIN w ON w.title = images.title\n    #    WHERE \"designer ( s )\" = 'georgia gerber'\"\"\"\n    # Below, we also need `self.node.find(exp.Table)` in case we get a QAIngredient on its own\n    #   E.g. `SELECT A() AS _col_0` cases should be ignored\n    if (\n        self.node.find(exp.Table)\n        and check.ingredients_only_in_top_select(self.node)\n        and not check.ingredient_alias_in_query_body(self.node)\n    ):\n        if abstracted_join_temp_tablename is not None:\n            prepare_joined_temp_table()\n        for (\n            tablename_or_aliasname,\n            columnnames,\n        ) in self.stateful_columns_referenced_by_lm_ingredients.items():\n            yield _result(abstracted_query, tablename_or_aliasname, columnnames)\n        return\n\n    # Base case is below\n    abstracted_query = abstracted_query.transform(\n        transform.remove_nodetype,\n        (exp.Order, exp.Limit, exp.Group, exp.Offset, exp.Having),\n    )\n    # If our previous subquery has an ingredient, we can't optimize with subquery condition\n    # So, remove this subquery constraint and run\n    if self.prev_subquery_has_ingredient:\n        abstracted_query = abstracted_query.transform(\n            transform.maybe_set_subqueries_to_true\n        )\n    # Happens with {{LLMQA()}} cases, where we get 'SELECT *'\n    if abstracted_query.find(exp.Table) is None:\n        return\n    # Check here to see if we have no other predicates other than 'WHERE TRUE'\n    # There's no point in creating a temporary table in this situation\n    where_node = abstracted_query.find(exp.Where)\n    join_node = abstracted_query.find(exp.Join)\n    # If we have a join_node that's a cross join ('JOIN \"colors\" ON TRUE'),\n    #   this was likely created by a LLMJoin ingredient.\n    #   We don't need to create temp tables for these.\n    # TODO: This cross join is inefficient, make it a union\n    is_cross_join = lambda node: node.args.get(\"on\", None) == exp.true()\n    ignore_join = bool(not join_node or is_cross_join(join_node))\n\n    if ignore_join and where_node:\n        where_this = where_node.args[\"this\"]\n        if (\n            where_this == exp.true()\n            or isinstance(where_this, exp.Column)\n            or check.all_terminals_are_true(where_node)\n        ):\n            return\n    elif not ignore_join and where_node is None:\n        return\n\n    if abstracted_join_temp_tablename is not None:\n        prepare_joined_temp_table()\n\n    for (\n        tablename_or_aliasname,\n        columnnames,\n    ) in self.stateful_columns_referenced_by_lm_ingredients.items():\n        yield _result(abstracted_query, tablename_or_aliasname, columnnames)\n    return\n</code></pre>"},{"location":"reference/query_optimization/#blendsql.parse.parse.SubqueryContextManager.infer_gen_constraints","title":"<code>infer_gen_constraints(function_node, schema, alias_to_tablename, has_user_regex)</code>","text":"<p>Convenience function matching the original method signature.</p> <p>Parameters:</p> Name Type Description Default <code>function_node</code> <code>Expression</code> <p>The expression node containing the BlendSQL function</p> required <code>schema</code> <code>dict</code> <p>Database schema mapping table names to column types</p> required <code>alias_to_tablename</code> <code>dict</code> <p>Mapping of table aliases to actual table names</p> required <code>has_user_regex</code> <code>bool</code> <p>Whether the user has provided a custom regex</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dict with inferred generation constraints</p> Source code in <code>blendsql/parse/parse.py</code> <pre><code>def infer_gen_constraints(\n    self,\n    function_node: exp.Expression,\n    schema: dict,\n    alias_to_tablename: dict,\n    has_user_regex: bool,\n) -&gt; dict:\n    \"\"\"\n    Convenience function matching the original method signature.\n\n    Args:\n        function_node: The expression node containing the BlendSQL function\n        schema: Database schema mapping table names to column types\n        alias_to_tablename: Mapping of table aliases to actual table names\n        has_user_regex: Whether the user has provided a custom regex\n\n    Returns:\n        Dict with inferred generation constraints\n    \"\"\"\n    return self.return_type_inferrer(\n        function_node=self.maybe_resolve_aliased_function(function_node),\n        schema=schema,\n        alias_to_tablename=alias_to_tablename,\n        has_user_regex=has_user_regex,\n    )\n</code></pre>"},{"location":"reference/smoothie/","title":"Smoothie","text":""},{"location":"reference/smoothie/#smoothie","title":"Smoothie","text":"<p>The <code>Smoothie</code> object defines the output of an executed BlendSQL script.</p> Source code in <code>blendsql/smoothie.py</code> <pre><code>@dataclass\nclass Smoothie:\n    _df: pl.DataFrame = field()\n    meta: SmoothieMeta = field()\n\n    def __post_init__(self):\n        if isinstance(self._df, pl.LazyFrame):\n            self._df = self._df.collect()\n\n    @cached_property\n    def df(self):\n        return self._df.to_pandas()\n\n    @cached_property\n    def pl(self):\n        return self._df\n\n    def print_summary(self):\n        from rich.console import Console, Group\n        from rich.align import Align\n        from rich.panel import Panel\n        from rich.syntax import Syntax\n        from rich.table import Table\n        from rich.columns import Columns\n        from rich.box import ROUNDED\n        from blendsql.parse.dialect import get_dialect\n        import sqlglot\n\n        console = Console(force_terminal=True)\n\n        # Create SQL syntax highlighted query\n        formatted_query = sqlglot.transpile(\n            self.meta.query, read=get_dialect(self.meta.db_type), pretty=True\n        )[0]\n        query_syntax = Syntax(\n            formatted_query, \"sql\", theme=\"default\", dedent=True, word_wrap=True\n        )\n\n        # Create summary table\n        table = Table(show_header=True, header_style=\"bold\")\n        table.add_column(\"Time (s)\")\n        table.add_column(\"# Generation Calls\")\n        table.add_column(\"Prompt Tokens\")\n        table.add_column(\"Completion Tokens\")\n        table.add_column(\"Cached Tokens\")\n\n        time_value = (\n            str(self.meta.process_time_seconds)\n            if hasattr(self.meta, \"process_time_seconds\")\n            else \"N.A.\"\n        )\n\n        table.add_row(\n            time_value,\n            str(f\"{self.meta.num_generation_calls:,}\"),\n            str(f\"{self.meta.prompt_tokens:,}\"),\n            str(f\"{self.meta.completion_tokens:,}\"),\n            str(\n                f\"{self.meta.cached_tokens:,} ({round(self.meta.cached_tokens / self.meta.prompt_tokens, 2) * 100 if self.meta.prompt_tokens else 0}%)\"\n            ),\n        )\n\n        # Create side-by-side panels for query and result\n        query_panel = Panel(query_syntax, title=\"Query\", border_style=\"blue\")\n\n        def df_to_table(df: pl.DataFrame, title: str = \"\") -&gt; Table:\n            table = Table(title=title, show_header=True, show_lines=True)\n\n            # Add columns\n            for col in df.columns:\n                table.add_column(str(col))\n\n            # Add rows\n            for row in df.iter_rows():\n                table.add_row(*[str(v) for v in row])\n\n            return table\n\n        total_rows = len(self.pl)\n        num_row_limit = 5\n        if total_rows &gt; num_row_limit:\n            df_to_display = self.pl.head(num_row_limit)\n            result_title = f\"Result ({num_row_limit} out of {total_rows} Rows)\"\n        else:\n            df_to_display = self.pl\n            result_title = f\"Result\"\n        result_panel = Panel(\n            df_to_table(df_to_display),\n            title=result_title,\n            border_style=\"blue\",\n        )\n\n        content = Group(Columns([query_panel, result_panel], equal=True), table)\n        boxed = Panel(\n            content,\n            box=ROUNDED,  # box style: ROUNDED, DOUBLE, HEAVY, SIMPLE, etc.\n            padding=(1, 2),  # (vertical, horizontal) padding inside\n        )\n        console.print(Align.center(boxed))\n\n    def __str__(self):\n        self.print_summary()\n</code></pre> Source code in <code>blendsql/smoothie.py</code> <pre><code>@dataclass\nclass SmoothieMeta:\n    # Number of values passed to a Map/Join/QA ingredient\n    num_values_passed: int = field()\n    num_generation_calls: int = field()  # Number of generation calls made to the model\n    prompt_tokens: int = field()\n    completion_tokens: int = field()\n    cached_tokens: int = field()\n    ingredients: Iterable[Type[Ingredient]] = field()\n    query: str = field()\n    db_url: str = field()\n    db_type: str = field()\n    contains_ingredient: bool = field(default=True)\n    process_time_seconds: float = field(default=\"N.A.\")\n</code></pre>"},{"location":"reference/string-ingredient/","title":"StringIngredient","text":"<p>This is the simplest type of ingredient. This will output a string to be placed directly into the SQL query.</p> <p>We have the <code>DT</code> function as a builtin StringIngredient.</p> <pre><code>SELECT merchant FROM transactions\n    WHERE {{DT('transactions::date', start='q2')}}\n</code></pre> <p>This will call a Python function that uses <code>datetime</code> to interpret the absolute dates which the relative phrase \"q2\" most likely refers to.</p> <p>We do not create any new tables or perform any joins with a StringIngredient; instead, we simply get the following SQL query.</p> <p>[!NOTE] The below SQL interpretation of the <code>DT</code> function assumes we're calling it in December, 2022. The phrase 'q2' will be interpreted differently in, say, March 1998.</p> <pre><code>SELECT merchant FROM transactions\n    WHERE date &gt; '2022-09-30' AND date &lt; '2022-12-01'\n</code></pre>"},{"location":"reference/technical_walkthrough/","title":"Technical walkthrough","text":"<p>All the below logic can be found in the <code>blend()</code> function from <code>blendsql/blendsql.py</code>.</p>"},{"location":"reference/technical_walkthrough/#example","title":"Example","text":"<p>We can take the following query as an example.</p> <pre><code>--- 'Show me dividends from tech companies that manufacture cell phones'\nSELECT \"Run Date\", Account, Action, ROUND(\"Amount ($)\", 2) AS 'Total Dividend Payout ($$)', Name\n    FROM account_history\n    LEFT JOIN constituents ON account_history.Symbol = constituents.Symbol\n    WHERE constituents.Sector = 'Information Technology'\n    AND {{\n           LLM(\n               'does this company manufacture cell phones?',\n               'constituents::Name',\n            )\n    }} = 1\n    AND lower(account_history.Action) like \"%dividend%\"\n</code></pre>"},{"location":"reference/technical_walkthrough/#1-generate-a-session-uuid","title":"1) Generate a Session UUID","text":"<p>This uuid allows us to create new temporary tables containing the output of our BlendSQL functions rather than overwriting the original, underlying SQL tables.</p> <pre><code>import uuid \n\nsession_uuid = str(uuid.uuid4())[:5]\n</code></pre>"},{"location":"reference/technical_walkthrough/#2-identify-all-subqueries","title":"2) Identify All Subqueries","text":"<p>Here, we define subqueries as any select statement from a single table. These may or may not have their own <code>SELECT</code> clause.</p> <p>In our example, we only have a single query.</p>"},{"location":"reference/technical_walkthrough/#3-for-each-table-generate-select-statements","title":"3) For Each Table, Generate Select Statements","text":"<p>Iterating through our subqueries, we now need to write each table reference as its own <code>SELECT</code> statement.</p> <p>To do this, we iterate through each table and get the following queries.</p> <p>Notice how in the <code>account_history</code> query, we change the specific columns to the <code>*</code>, so we get everything.</p> <pre><code>SELECT * FROM account_history\n    WHERE lower(account_history.Action) like \"%dividend%\"\n</code></pre> <pre><code>SELECT * FROM constituents\n    WHERE constituents.Sector = 'Information Technology'\n    AND {{\n           LLM(\n               'does this company manufacture cell phones?',\n               'constituents::Name',\n            )\n    }} = 1\n</code></pre>"},{"location":"reference/technical_walkthrough/#4-abstract-away-selects","title":"4) Abstract Away Selects","text":"<p>In our <code>constituents</code> subquery, we have an expensive LLM operation.</p> <p>In order to make sure we pass minimal required data to our BlendSQL ingredients while still honoring the SQL logic, we abstract away external functions to <code>True</code> to calculate the theoretical upper bound of data that might get returned.</p> <pre><code>-- Abstracted query\nSELECT * FROM constituents\n    WHERE constituents.Sector = 'Information Technology'\n    AND TRUE\n</code></pre> <p>We execute each of these queries and assign them to new temporary tables, <code>f\"{session_uuid}_{tablename}_{subquery_idx}\"</code>.</p>"},{"location":"reference/technical_walkthrough/#4-execute-blendsql-ingredients-on-our-new-tables","title":"4) Execute BlendSQL Ingredients on our New Tables","text":"<p>Now we can execute some external functions.</p> <p>For example, if we have a session_id of '1234': <pre><code>SELECT Symbol FROM \"1234_constituents_0\" \n    WHERE sector = 'Information Technology' \n    AND {{\n            LLM(\n                'does this company manufacture cell phones?', \n                'constituents::Name'\n            )\n        }} = 1\n</code></pre></p> <p>The table \"1234_constituents_0\" now only has those entries where <code>sector = 'Information Technology'</code>. This minimizes the data that the <code>{{LLM()}}</code> call actually needs to process.</p> <p>Once we've executed our functions, we now have a table with a new column, <code>'does this company manufacture cell phones?'</code>.</p> <p>We do a left join with the original <code>constituents</code> table to create the new session table \"1234_constituents\". </p> <p>Then, we can move to the next subquery. In this case, there is no BlendSQL ingredient, so we're done with our processing.</p>"},{"location":"reference/technical_walkthrough/#5-execute-our-final-sql-query","title":"5) Execute our Final SQL Query","text":"<p>At the end of our processing, we have the underlying SQL tables and query in a state that we can execute it like any other SQLite script. </p> <pre><code>SELECT \"Run Date\", Account, Action, ROUND(\"Amount ($)\", 2) AS 'Total Dividend Payout ($$)', Name\n    FROM account_history\n    LEFT JOIN '1c0b_constituents' ON account_history.Symbol = '1c0b_constituents'.Symbol\n    WHERE '1c0b_constituents'.Sector = 'Information Technology'\n    AND {{\n           LLM(\n               'does this company manufacture cell phones?',\n               'constituents::Name',\n            )\n    }} = 1\n    AND lower(account_history.Action) like \"%dividend%\"\n</code></pre> <p>Notice how <code>account_history</code> was not modified by a session_id, but <code>constituents</code> was. This is because the logic of filtering by <code>LIKE %dividend%</code> can just be done using raw SQL on the original table, we don't need any complicated BlendSQL processing.</p>"},{"location":"reference/databases/databases/","title":"Databases","text":"<p>Since BlendSQL relies on the package sqlglot for query optimization (which supports a wide variety of SQL dialects) and the notion of temporary tables, it can easily integrate with many different SQL DBMS. </p> <p>Currently, the following are supported.</p> <ul> <li>SQLite</li> <li>PostgreSQL</li> <li>DuckDB</li> <li>Pandas</li> </ul> <p>               Bases: <code>ABC</code></p> Source code in <code>blendsql/db/database.py</code> <pre><code>class Database(ABC):\n    db_url: URL | str = field()\n    lazy_tables: LazyTables = LazyTables()\n\n    def __str__(self):\n        return f\"{self.__class__} @ {self.db_url}\"\n\n    def __repr__(self):\n        return f\"{self.__class__} @ {self.db_url}\"\n\n    @abstractmethod\n    def _reset_connection(self) -&gt; None:\n        \"\"\"Reset connection, so that temp tables are cleared.\"\"\"\n        ...\n\n    @abstractmethod\n    def has_temp_table(self, tablename: str) -&gt; bool:\n        \"\"\"Temp tables are stored in different locations, depending on\n        the DBMS. For example, sqlite puts them in `sqlite_temp_master`,\n        and postgres goes in the main `information_schema.tables` with a\n        'pg_temp' prefix.\n        \"\"\"\n        ...\n\n    @property\n    @abstractmethod\n    def sqlglot_schema(self) -&gt; dict:\n        \"\"\"Returns database schema as a dictionary, in the format that\n        sqlglot.optimizer expects.\n\n        Examples:\n            ```python\n            db.sqlglot_schema\n            &gt; {\"x\": {\"A\": \"INT\", \"B\": \"INT\", \"C\": \"INT\", \"D\": \"INT\", \"Z\": \"STRING\"}}\n            ```\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def tables(self) -&gt; list[str]:\n        \"\"\"Get all table names associated with a database.\"\"\"\n        ...\n\n    @abstractmethod\n    def iter_columns(self, tablename: str) -&gt; Generator[str, None, None]:\n        \"\"\"Yield all column names associated with a tablename.\"\"\"\n        ...\n\n    @abstractmethod\n    def schema_string(self, use_tables: Collection[str] | None = None) -&gt; str:\n        \"\"\"Converts the database to a series of 'CREATE TABLE' statements.\"\"\"\n\n    @abstractmethod\n    def to_temp_table(self, df: pl.DataFrame, tablename: str):\n        \"\"\"Write the given pandas dataframe as a temp table 'tablename'.\"\"\"\n        ...\n\n    @abstractmethod\n    def execute_to_df(\n        self, query: str, lazy: bool, **kwargs\n    ) -&gt; pl.DataFrame | pl.LazyFrame:\n        \"\"\"\n        Execute the given query and return results as dataframe.\n\n        Args:\n            query: The SQL query to execute. Can use `named` paramstyle from PEP 249\n                https://peps.python.org/pep-0249/#paramstyle\n            lazy: Whether to return a pl.LazyFrame.\n            params: Dict containing mapping from name to value.\n\n        Returns:\n            pd.DataFrame\n\n        Examples:\n            ```python\n            from blendsql.db import SQLite\n            db = SQLite(\"./path/to/database.db\")\n            db.execute_query(\"SELECT * FROM t WHERE c = :v\", {\"v\": \"value\"})\n            ```\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def execute_to_list(self, query: str, to_type: Callable = lambda x: x) -&gt; list:\n        \"\"\"A lower-level execute method that doesn't use the pandas processing logic.\n        Returns results as a list.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"reference/databases/duckdb/","title":"DuckDB","text":"<p>Installation</p> <p>You need to install the <code>duckdb</code> library to use this in blendsql.</p> <p>               Bases: <code>Database</code></p> <p>An in-memory DuckDB database connection. Can be initialized via any of the available class methods.</p> <p>Examples:</p> <pre><code>from blendsql.db import DuckDB\ndb = DuckDB.from_pandas(\n    pd.DataFrame(\n        {\n            \"name\": [\"John\", \"Parker\"],\n            \"age\": [12, 26]\n        },\n    )\n)\n# Or, load multiple dataframes\ndb = DuckDB.from_pandas(\n    {\n        \"students\": pd.DataFrame(\n            {\n                \"name\": [\"John\", \"Parker\"],\n                \"age\": [12, 26]\n            },\n        ),\n        \"classes\": pd.DataFrame(\n            {\n                \"class\": [\"Physics 101\", \"Chemistry\"],\n                \"size\": [50, 32]\n            },\n        ),\n    }\n)\n</code></pre> Source code in <code>blendsql/db/duckdb.py</code> <pre><code>@dataclass\nclass DuckDB(Database):\n    \"\"\"An in-memory DuckDB database connection.\n    Can be initialized via any of the available class methods.\n\n    Examples:\n        ```python\n        from blendsql.db import DuckDB\n        db = DuckDB.from_pandas(\n            pd.DataFrame(\n                {\n                    \"name\": [\"John\", \"Parker\"],\n                    \"age\": [12, 26]\n                },\n            )\n        )\n        # Or, load multiple dataframes\n        db = DuckDB.from_pandas(\n            {\n                \"students\": pd.DataFrame(\n                    {\n                        \"name\": [\"John\", \"Parker\"],\n                        \"age\": [12, 26]\n                    },\n                ),\n                \"classes\": pd.DataFrame(\n                    {\n                        \"class\": [\"Physics 101\", \"Chemistry\"],\n                        \"size\": [50, 32]\n                    },\n                ),\n            }\n        )\n        ```\n    \"\"\"\n\n    # Can be either a dict from name -&gt; pd.DataFrame\n    # or, a single pd.DataFrame object\n    con: \"DuckDBPyConnection\" = field()\n    db_url: str = field(default=None)\n\n    # We use below to track which tables we should drop on '_reset_connection'\n    temp_tables: set[str] = field(default_factory=set)\n\n    @classmethod\n    def from_pandas(\n        cls,\n        data: dict[str, pd.DataFrame] | pd.DataFrame,\n        tablename: str = \"w\",\n    ):\n        import duckdb\n\n        con = duckdb.connect(database=\":memory:\")\n        if isinstance(data, pd.DataFrame):\n            db_url = \"Local pandas table\"\n            # I don't really understand the scope of duckdb's replacement scan here\n            # I assign the underlying data to _df, since passing self.data doesn't work\n            # in the self.con.sql call.\n            _df = data\n            con.sql(\n                f'CREATE TABLE \"{double_quote_escape(tablename)}\" AS SELECT * FROM _df'\n            )\n\n        elif isinstance(data, dict):\n            db_url = f\"Local pandas tables {', '.join(data.keys())}\"\n            for tablename, _df in data.items():\n                # Note: duckdb.sql connects to the default in-memory database connection\n                con.sql(\n                    f'CREATE TABLE \"{double_quote_escape(tablename)}\" AS SELECT * FROM _df'\n                )\n        else:\n            raise ValueError(\n                \"Unknown datatype passed to `Pandas`!\\nWe expect either a single dataframe, or a dictionary mapping many tables from {tablename: df}\"\n            )\n        return cls(con=con, db_url=db_url)\n\n    @classmethod\n    def from_sqlite(cls, filepath: str, additional_cmds: list[str] | None = None):\n        import duckdb\n\n        con = duckdb.connect(database=\":memory:\")\n        db_url = str(Path(filepath).resolve())\n        con.sql(\"INSTALL sqlite;\")\n        con.sql(\"LOAD sqlite;\")\n        if additional_cmds is not None:\n            for cmd in additional_cmds:\n                con.sql(cmd)\n        con.sql(f\"ATTACH '{db_url}' AS sqlite_db (TYPE sqlite);\")\n        con.sql(\"USE sqlite_db\")\n        return cls(con=con, db_url=db_url)\n\n    @classmethod\n    def from_file(cls, filepath: str):\n        import duckdb\n\n        con = duckdb.connect(filepath)\n        db_url = str(Path(filepath).resolve())\n        return cls(con=con, db_url=db_url)\n\n    def _reset_connection(self):\n        \"\"\"Reset connection, so that temp tables are cleared.\"\"\"\n        for tablename in self.temp_tables:\n            self.con.sql(f'DROP TABLE IF EXISTS \"{tablename}\"')\n        self.temp_tables = set()\n\n    def has_temp_table(self, tablename: str) -&gt; bool:\n        return tablename in self.execute_to_list(\"SHOW TABLES\")\n\n    @cached_property\n    def sqlglot_schema(self) -&gt; dict:\n        \"\"\"Returns database schema as a dictionary, in the format that\n        sqlglot.optimizer expects.\n\n        Examples:\n            ```python\n            db.sqlglot_schema\n            &gt; {\"x\": {\"A\": \"INT\", \"B\": \"INT\", \"C\": \"INT\", \"D\": \"INT\", \"Z\": \"STRING\"}}\n            ```\n        \"\"\"\n        schema: dict[str, dict] = {}\n        for tablename in self.tables():\n            schema[tablename] = {}\n            for column_name, column_type in self.con.sql(\n                f'SELECT column_name, column_type FROM (DESCRIBE \"{double_quote_escape(tablename)}\")'\n            ).fetchall():\n                schema[tablename][column_name] = column_type\n        return schema\n\n    def tables(self) -&gt; list[str]:\n        return self.execute_to_list(\"SHOW TABLES;\")\n\n    def iter_columns(self, tablename: str) -&gt; Generator[str, None, None]:\n        for row in self.con.sql(\n            f'SELECT column_name FROM (DESCRIBE \"{double_quote_escape(tablename)}\")'\n        ).fetchall():\n            yield row[0]\n\n    def schema_string(self, use_tables: Collection[str] | None = None) -&gt; str:\n        \"\"\"Converts the database to a series of 'CREATE TABLE' statements.\"\"\"\n        # TODO\n        return None\n\n    def to_temp_table(self, df: pd.DataFrame, tablename: str):\n        \"\"\"Technically, when duckdb is run in-memory (as is the default),\n        all created tables are temporary tables (since they expire at the\n        end of the session). So, we don't really need to insert 'TEMP' keyword here?\n        \"\"\"\n        # DuckDB has this cool 'CREATE OR REPLACE' syntax\n        # https://duckdb.org/docs/sql/statements/create_table.html#create-or-replace\n        create_table_stmt = (\n            f'CREATE OR REPLACE TEMP TABLE \"{tablename}\" AS SELECT * FROM df'\n        )\n        logger.debug(Color.quiet_sql(create_table_stmt))\n        self.con.sql(create_table_stmt)\n        self.temp_tables.add(tablename)\n        logger.debug(Color.update(f\"Created temp table {tablename}\"))\n\n    def execute_to_df(\n        self, query: str, lazy=True, close_conn=True, **_\n    ) -&gt; pl.LazyFrame:\n        \"\"\"On params with duckdb: https://github.com/duckdb/duckdb/issues/9853#issuecomment-1832732933\n\n        If `close_conn==True` and `lazy=True`, we can't call `self.con.sql(query).pl(lazy=True)`,\n            since this leaves an open connection that blocks future queries.\n            Instead, we create a pl.DataFrame and call `.lazy()` on it.\n        \"\"\"\n        if close_conn:\n            res = self.con.sql(query).pl()\n            return res.lazy() if lazy else res\n        else:\n            return self.con.sql(query).pl(lazy=lazy)\n\n    def execute_to_list(\n        self, query: str, to_type: Callable | None = lambda x: x\n    ) -&gt; list:\n        result = self.con.sql(query).fetchall()\n        return [to_type(row[0]) for row in result]\n</code></pre>"},{"location":"reference/databases/duckdb/#blendsql.db.duckdb.DuckDB.from_pandas","title":"<code>from_pandas(data, tablename='w')</code>  <code>classmethod</code>","text":"Source code in <code>blendsql/db/duckdb.py</code> <pre><code>@classmethod\ndef from_pandas(\n    cls,\n    data: dict[str, pd.DataFrame] | pd.DataFrame,\n    tablename: str = \"w\",\n):\n    import duckdb\n\n    con = duckdb.connect(database=\":memory:\")\n    if isinstance(data, pd.DataFrame):\n        db_url = \"Local pandas table\"\n        # I don't really understand the scope of duckdb's replacement scan here\n        # I assign the underlying data to _df, since passing self.data doesn't work\n        # in the self.con.sql call.\n        _df = data\n        con.sql(\n            f'CREATE TABLE \"{double_quote_escape(tablename)}\" AS SELECT * FROM _df'\n        )\n\n    elif isinstance(data, dict):\n        db_url = f\"Local pandas tables {', '.join(data.keys())}\"\n        for tablename, _df in data.items():\n            # Note: duckdb.sql connects to the default in-memory database connection\n            con.sql(\n                f'CREATE TABLE \"{double_quote_escape(tablename)}\" AS SELECT * FROM _df'\n            )\n    else:\n        raise ValueError(\n            \"Unknown datatype passed to `Pandas`!\\nWe expect either a single dataframe, or a dictionary mapping many tables from {tablename: df}\"\n        )\n    return cls(con=con, db_url=db_url)\n</code></pre>"},{"location":"reference/databases/duckdb/#blendsql.db.duckdb.DuckDB.from_sqlite","title":"<code>from_sqlite(filepath, additional_cmds=None)</code>  <code>classmethod</code>","text":"Source code in <code>blendsql/db/duckdb.py</code> <pre><code>@classmethod\ndef from_sqlite(cls, filepath: str, additional_cmds: list[str] | None = None):\n    import duckdb\n\n    con = duckdb.connect(database=\":memory:\")\n    db_url = str(Path(filepath).resolve())\n    con.sql(\"INSTALL sqlite;\")\n    con.sql(\"LOAD sqlite;\")\n    if additional_cmds is not None:\n        for cmd in additional_cmds:\n            con.sql(cmd)\n    con.sql(f\"ATTACH '{db_url}' AS sqlite_db (TYPE sqlite);\")\n    con.sql(\"USE sqlite_db\")\n    return cls(con=con, db_url=db_url)\n</code></pre>"},{"location":"reference/databases/pandas/","title":"Pandas","text":"<p>This is just a wrapper over the <code>DuckDB.from_pandas</code> class method. Makes it more intuitive to do a <code>from blendsql.db import Pandas</code>, for those developers who might not know DuckDB supports pandas dataframes.</p> <p>Examples:</p> <pre><code>from blendsql.db import Pandas\ndb = Pandas(\n    pd.DataFrame(\n        {\n            \"name\": [\"John\", \"Parker\"],\n            \"age\": [12, 26]\n        },\n    )\n)\n# Or, load multiple dataframes\ndb = Pandas(\n    {\n        \"students\": pd.DataFrame(\n            {\n                \"name\": [\"John\", \"Parker\"],\n                \"age\": [12, 26]\n            },\n        ),\n        \"classes\": pd.DataFrame(\n            {\n                \"class\": [\"Physics 101\", \"Chemistry\"],\n                \"size\": [50, 32]\n            },\n        ),\n    }\n)\n</code></pre> Source code in <code>blendsql/db/pandas.py</code> <pre><code>def Pandas(\n    data: dict[str, pd.DataFrame] | pd.DataFrame, tablename: str = \"w\"\n) -&gt; DuckDB:\n    \"\"\"This is just a wrapper over the `DuckDB.from_pandas` class method.\n    Makes it more intuitive to do a `from blendsql.db import Pandas`, for those\n    developers who might not know DuckDB supports pandas dataframes.\n\n    Examples:\n        ```python\n        from blendsql.db import Pandas\n        db = Pandas(\n            pd.DataFrame(\n                {\n                    \"name\": [\"John\", \"Parker\"],\n                    \"age\": [12, 26]\n                },\n            )\n        )\n        # Or, load multiple dataframes\n        db = Pandas(\n            {\n                \"students\": pd.DataFrame(\n                    {\n                        \"name\": [\"John\", \"Parker\"],\n                        \"age\": [12, 26]\n                    },\n                ),\n                \"classes\": pd.DataFrame(\n                    {\n                        \"class\": [\"Physics 101\", \"Chemistry\"],\n                        \"size\": [50, 32]\n                    },\n                ),\n            }\n        )\n        ```\n    \"\"\"\n    return DuckDB.from_pandas(data, tablename)\n</code></pre>"},{"location":"reference/databases/postgresql/","title":"PostreSQL","text":"<p>Installation</p> <p>You need to install the <code>psycopg2-binary</code> library to use this in blendsql.</p> <p>               Bases: <code>SQLAlchemyDatabase</code></p> <p>A PostgreSQL database connection. Can be initialized via the SQLAlchemy input string. https://docs.sqlalchemy.org/en/20/core/engines.html#postgresql</p> <p>Examples:</p> <pre><code>from blendsql.db import PostgreSQL\ndb = PostgreSQL(\"user:password@localhost/mydatabase\")\n</code></pre> Source code in <code>blendsql/db/postgresql.py</code> <pre><code>class PostgreSQL(SQLAlchemyDatabase):\n    \"\"\"A PostgreSQL database connection.\n    Can be initialized via the SQLAlchemy input string.\n    https://docs.sqlalchemy.org/en/20/core/engines.html#postgresql\n\n    Examples:\n        ```python\n        from blendsql.db import PostgreSQL\n        db = PostgreSQL(\"user:password@localhost/mydatabase\")\n        ```\n    \"\"\"\n\n    def __init__(self, db_path: str):\n        if not _has_psycopg2:\n            raise ImportError(\n                \"Please install psycopg2 with `pip install psycopg2-binary`!\"\n            ) from None\n        db_url: URL = make_url(f\"postgresql+psycopg2://{db_path}\")\n        if db_url.username is None:\n            logging.warning(\n                Color.error(\n                    \"Connecting to postgreSQL database without specifying user!\\nIt is strongly encouraged to create a `blendsql` user with read-only permissions and temp table creation privileges.\"\n                )\n            )\n        super().__init__(db_url=db_url)\n\n    def has_temp_table(self, tablename: str) -&gt; bool:\n        return tablename in self.execute_to_list(\n            \"SELECT table_name FROM information_schema.tables WHERE table_schema LIKE 'pg_temp_%'\"\n        )\n\n    @cached_property\n    def sqlglot_schema(self) -&gt; dict:\n        schema: dict[str, dict] = {}\n        for tablename in self.tables():\n            schema[tablename] = {}\n            for _, row in self.execute_to_df(\n                \"\"\"\n                    SELECT column_name as name, data_type as type \n                    FROM information_schema.columns \n                    WHERE table_name = :t\n                    AND table_schema = 'public'\n                    \"\"\",\n                {\"t\": tablename},\n            ).iterrows():\n                schema[tablename][row[\"name\"]] = row[\"type\"]\n        return schema\n</code></pre>"},{"location":"reference/databases/postgresql/#creating-a-blendsql-user","title":"Creating a <code>blendsql</code> User","text":"<p>When executing a BlendSQL query, there are internal checks to ensure prior to execution that a given query does not contain any 'modify' actions.</p> <p>However, it is still best practice when using PostgreSQL to create a dedicated 'blendsql' user with only the permissions needed. </p> <p>You can create a user with the required permissions with the script below (after invoking postgres via <code>psql</code>)</p> <pre><code>CREATE USER blendsql;\nGRANT pg_read_all_data TO blendsql;\nGRANT TEMP ON DATABASE mydb TO blendsql;\n</code></pre> <p>Now, we can initialize a PostgreSQL database with our new user.</p> <pre><code>from blendsql.db import PostgreSQL\ndb = PostgreSQL(\"blendsql@localhost:5432/mydb\")\n</code></pre>"},{"location":"reference/databases/sqlite/","title":"SQLite","text":"<p>               Bases: <code>SQLAlchemyDatabase</code></p> <p>A SQLite database connection. Can be initialized viae a path to the database file.</p> <p>Examples:</p> <pre><code>from blendsql.db import SQLite\ndb = SQLite(\"./path/to/database.db\")\n</code></pre> Source code in <code>blendsql/db/sqlite.py</code> <pre><code>class SQLite(SQLAlchemyDatabase):\n    \"\"\"A SQLite database connection.\n    Can be initialized viae a path to the database file.\n\n    Examples:\n        ```python\n        from blendsql.db import SQLite\n        db = SQLite(\"./path/to/database.db\")\n        ```\n    \"\"\"\n\n    def __init__(self, db_path: str):\n        db_url: URL = make_url(f\"sqlite:///{Path(db_path).resolve()}\")\n        super().__init__(db_url=db_url)\n\n    def has_temp_table(self, tablename: str) -&gt; bool:\n        return tablename in self.execute_to_list(\n            \"SELECT name FROM sqlite_temp_master WHERE type='table';\"\n        )\n\n    @cached_property\n    def sqlglot_schema(self) -&gt; dict:\n        \"\"\"Returns database schema as a dictionary, in the format that\n        sqlglot.optimizer expects.\n\n        Examples:\n            &gt;&gt;&gt; db.sqlglot_schema\n            {\"x\": {\"A\": \"INT\", \"B\": \"INT\", \"C\": \"INT\", \"D\": \"INT\", \"Z\": \"STRING\"}}\n        \"\"\"\n        schema: dict[str, dict] = {}\n        for tablename in self.tables():\n            schema[tablename] = {}\n            for row in (\n                self.execute_to_df(\n                    f\"\"\"\n                SELECT name, type FROM pragma_table_info(:t)\n                \"\"\",\n                    {\"t\": tablename},\n                )\n                .collect()\n                .iter_rows(named=True)\n            ):\n                schema[tablename][row[\"name\"]] = row[\"type\"]\n        return schema\n</code></pre>"},{"location":"reference/examples/blendsql-by-example/","title":"BlendSQL by Example","text":"In\u00a0[1]: Copied! <pre>import pandas as pd\nimport nest_asyncio\nnest_asyncio.apply()\n\nfrom blendsql.models import LlamaCpp\nfrom blendsql import BlendSQL\nimport blendsql\n</pre> import pandas as pd import nest_asyncio nest_asyncio.apply()  from blendsql.models import LlamaCpp from blendsql import BlendSQL import blendsql In\u00a0[2]: Copied! <pre>model = LlamaCpp(\n    filename=\"google_gemma-3-4b-it-Q6_K.gguf\",\n    model_name_or_path=\"bartowski/google_gemma-3-4b-it-GGUF\",\n    config={\"n_gpu_layers\": -1, \"n_ctx\": 4096, \"seed\": 100, \"n_threads\": 16},\n)\n</pre> model = LlamaCpp(     filename=\"google_gemma-3-4b-it-Q6_K.gguf\",     model_name_or_path=\"bartowski/google_gemma-3-4b-it-GGUF\",     config={\"n_gpu_layers\": -1, \"n_ctx\": 4096, \"seed\": 100, \"n_threads\": 16}, ) <pre>llama_context: n_ctx_per_seq (512) &gt; n_ctx_train (0) -- possible training context overflow\n</pre> <p>By default, loading a connection with BlendSQL will create an empty in-memory DuckDB database. As a result, we can use cool DuckDB functions like read_text.</p> In\u00a0[25]: Copied! <pre>bsql = BlendSQL(\n    model=model,\n)\nsmoothie = bsql.execute(\n    \"\"\"\n    SELECT {{\n        LLMQA(\n            'Describe BlendSQL in 50 words.',\n            context=(\n                SELECT content[0:5000] AS \"README\"\n                FROM read_text('https://raw.githubusercontent.com/parkervg/blendsql/main/README.md')\n            )\n        )\n    }} AS answer\n    \"\"\"\n)\nprint(smoothie.df)\n</pre> bsql = BlendSQL(     model=model, ) smoothie = bsql.execute(     \"\"\"     SELECT {{         LLMQA(             'Describe BlendSQL in 50 words.',             context=(                 SELECT content[0:5000] AS \"README\"                 FROM read_text('https://raw.githubusercontent.com/parkervg/blendsql/main/README.md')             )         )     }} AS answer     \"\"\" ) print(smoothie.df) <pre>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 answer                                                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 BlendSQL is an open-source SQL tool that combines ... \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>We can also set up a local database from a <code>Dict[str, pd.DataFrame]</code> object.</p> In\u00a0[3]: Copied! <pre>bsql = BlendSQL(\n    {\n        \"People\": pd.DataFrame(\n            {\n               'Name': [\n                   'George Washington', \n                   'John Adams',\n                   'President Thomas Jefferson',\n                   'James Madison', \n                   'James Monroe', \n                   'Alexander Hamilton',\n                   'Sabrina Carpenter',\n                   'Charli XCX',\n                   'Elon Musk',\n                   'Michelle Obama',\n                   'Elvis Presley',\n               ],\n               'Known_For': [\n                   'Established federal government, First U.S. President',\n                   'XYZ Affair, Alien and Sedition Acts',\n                   'Louisiana Purchase, Declaration of Independence',\n                   'War of 1812, Constitution',\n                   'Monroe Doctrine, Missouri Compromise',\n                   'Created national bank, Federalist Papers',\n                   'Nonsense, Emails I Cant Send, Mean Girls musical',\n                   'Crash, How Im Feeling Now, Boom Clap',\n                   'Tesla, SpaceX, Twitter/X acquisition',\n                   'Lets Move campaign, Becoming memoir',\n                   '14 Grammys, King of Rock n Roll'\n               ]\n            }\n        ),\n        \"Eras\": pd.DataFrame(\n            {\n                'Years': [\n                    '1800-1900',\n                    '1900-2000',\n                    '2000-Now'\n                ]\n            }\n        )\n    },\n    # This model can be changed, according to what your personal setup is\n    model=model\n)\n\n# Print the tables in our database\nfor tablename in bsql.db.tables():\n    print(tablename)\n    print(blendsql.common.utils.tabulate(bsql.db.execute_to_df(f\"SELECT * FROM {tablename};\")))\n</pre> bsql = BlendSQL(     {         \"People\": pd.DataFrame(             {                'Name': [                    'George Washington',                     'John Adams',                    'President Thomas Jefferson',                    'James Madison',                     'James Monroe',                     'Alexander Hamilton',                    'Sabrina Carpenter',                    'Charli XCX',                    'Elon Musk',                    'Michelle Obama',                    'Elvis Presley',                ],                'Known_For': [                    'Established federal government, First U.S. President',                    'XYZ Affair, Alien and Sedition Acts',                    'Louisiana Purchase, Declaration of Independence',                    'War of 1812, Constitution',                    'Monroe Doctrine, Missouri Compromise',                    'Created national bank, Federalist Papers',                    'Nonsense, Emails I Cant Send, Mean Girls musical',                    'Crash, How Im Feeling Now, Boom Clap',                    'Tesla, SpaceX, Twitter/X acquisition',                    'Lets Move campaign, Becoming memoir',                    '14 Grammys, King of Rock n Roll'                ]             }         ),         \"Eras\": pd.DataFrame(             {                 'Years': [                     '1800-1900',                     '1900-2000',                     '2000-Now'                 ]             }         )     },     # This model can be changed, according to what your personal setup is     model=model )  # Print the tables in our database for tablename in bsql.db.tables():     print(tablename)     print(blendsql.common.utils.tabulate(bsql.db.execute_to_df(f\"SELECT * FROM {tablename};\"))) <pre>Eras\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Years     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1800-1900 \u2502\n\u2502 1900-2000 \u2502\n\u2502 2000-Now  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nPeople\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Name                       \u2502 Known_For                                            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 George Washington          \u2502 Established federal government, First U.S. President \u2502\n\u2502 John Adams                 \u2502 XYZ Affair, Alien and Sedition Acts                  \u2502\n\u2502 President Thomas Jefferson \u2502 Louisiana Purchase, Declaration of Independence      \u2502\n\u2502 James Madison              \u2502 War of 1812, Constitution                            \u2502\n\u2502 James Monroe               \u2502 Monroe Doctrine, Missouri Compromise                 \u2502\n\u2502 Alexander Hamilton         \u2502 Created national bank, Federalist Papers             \u2502\n\u2502 Sabrina Carpenter          \u2502 Nonsense, Emails I Cant Send, Mean Girls musical     \u2502\n\u2502 Charli XCX                 \u2502 Crash, How Im Feeling Now, Boom Clap                 \u2502\n\u2502 Elon Musk                  \u2502 Tesla, SpaceX, Twitter/X acquisition                 \u2502\n\u2502 Michelle Obama             \u2502 Lets Move campaign, Becoming memoir                  \u2502\n\u2502 Elvis Presley              \u2502 14 Grammys, King of Rock n Roll                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[3]: Copied! <pre>db = blendsql.db.SQLite(blendsql.utils.fetch_from_hub(\"california_schools.db\"))\nprint(\"{} total rows in the table\".format(db.execute_to_list(\"SELECT COUNT(*) FROM schools LIMIT 10;\")[0]))\nprint(\"{} total unique values in the 'City' column\".format(db.execute_to_list(\"SELECT COUNT(DISTINCT City) FROM schools LIMIT 10;\")[0]))\n</pre> db = blendsql.db.SQLite(blendsql.utils.fetch_from_hub(\"california_schools.db\")) print(\"{} total rows in the table\".format(db.execute_to_list(\"SELECT COUNT(*) FROM schools LIMIT 10;\")[0])) print(\"{} total unique values in the 'City' column\".format(db.execute_to_list(\"SELECT COUNT(DISTINCT City) FROM schools LIMIT 10;\")[0])) <pre>17686 total rows in the table\n1165 total unique values in the 'City' column\n</pre> In\u00a0[63]: Copied! <pre>smoothie = BlendSQL(\n    db, model=blendsql.models.LiteLLM('openai/gpt-4o-mini', caching=False)\n).execute(\n    \"\"\"\n    SELECT\n        City,\n        {{LLMMap('Is this in the Bay Area?', City, options=('t', 'f'))}} AS 'In Bay Area?'\n    FROM schools;\n    \"\"\",\n)\nprint(f\"Finished in {smoothie.meta.process_time_seconds} seconds\")\nprint(blendsql.utils.tabulate(smoothie.df.head(10)))\n</pre> smoothie = BlendSQL(     db, model=blendsql.models.LiteLLM('openai/gpt-4o-mini', caching=False) ).execute(     \"\"\"     SELECT         City,         {{LLMMap('Is this in the Bay Area?', City, options=('t', 'f'))}} AS 'In Bay Area?'     FROM schools;     \"\"\", ) print(f\"Finished in {smoothie.meta.process_time_seconds} seconds\") print(blendsql.utils.tabulate(smoothie.df.head(10))) <pre>Executing `SELECT * FROM schools` and setting to `32d0_schools_0`...\nCREATE TEMP TABLE \"32d0_schools_0\" (\n\t\"CDSCode\" TEXT, \n\t\"NCESDist\" TEXT, \n\t\"NCESSchool\" TEXT, \n\t\"StatusType\" TEXT, \n\t\"County\" TEXT, \n\t\"District\" TEXT, \n\t\"School\" TEXT, \n\t\"Street\" TEXT, \n\t\"StreetAbr\" TEXT, \n\t\"City\" TEXT, \n\t\"Zip\" TEXT, \n\t\"State\" TEXT, \n\t\"MailStreet\" TEXT, \n\t\"MailStrAbr\" TEXT, \n\t\"MailCity\" TEXT, \n\t\"MailZip\" TEXT, \n\t\"MailState\" TEXT, \n\t\"Phone\" TEXT, \n\t\"Ext\" TEXT, \n\t\"Website\" TEXT, \n\t\"OpenDate\" TEXT, \n\t\"ClosedDate\" TEXT, \n\t\"Charter\" FLOAT, \n\t\"CharterNum\" TEXT, \n\t\"FundingType\" TEXT, \n\t\"DOC\" TEXT, \n\t\"DOCType\" TEXT, \n\t\"SOC\" TEXT, \n\t\"SOCType\" TEXT, \n\t\"EdOpsCode\" TEXT, \n\t\"EdOpsName\" TEXT, \n\t\"EILCode\" TEXT, \n\t\"EILName\" TEXT, \n\t\"GSoffered\" TEXT, \n\t\"GSserved\" TEXT, \n\t\"Virtual\" TEXT, \n\t\"Magnet\" FLOAT, \n\t\"Latitude\" FLOAT, \n\t\"Longitude\" FLOAT, \n\t\"AdmFName1\" TEXT, \n\t\"AdmLName1\" TEXT, \n\t\"AdmEmail1\" TEXT, \n\t\"AdmFName2\" TEXT, \n\t\"AdmLName2\" TEXT, \n\t\"AdmEmail2\" TEXT, \n\t\"AdmFName3\" TEXT, \n\t\"AdmLName3\" TEXT, \n\t\"AdmEmail3\" TEXT, \n\t\"LastUpdate\" TEXT\n)\nExecuting  `{{LLMMap('Is this in the Bay Area?', 'schools::City', options='t;f')}}`...\nUsing options '['t', 'f']'\nMaking calls to Model with batch_size 5: |          | 234/? [00:00&lt;00:00, 30475.61it/s]\nLLMMap with OpenaiLLM(gpt-4o-mini) only returned 1165 out of 1166 values\nFinished LLMMap with values:\n{\n    \"Hayward\": true,\n    \"Newark\": true,\n    \"Oakland\": true,\n    \"Berkeley\": true,\n    \"San Leandro\": true,\n    \"-\": false,\n    \"Dublin\": true,\n    \"Fremont\": false,\n    \"Sacramento\": true,\n    \"Alameda\": null\n}\nCombining 1 outputs for table `schools`\nCREATE TEMP TABLE \"32d0_schools\" (\n\t\"CDSCode\" TEXT, \n\t\"NCESDist\" TEXT, \n\t\"NCESSchool\" TEXT, \n\t\"StatusType\" TEXT, \n\t\"County\" TEXT, \n\t\"District\" TEXT, \n\t\"School\" TEXT, \n\t\"Street\" TEXT, \n\t\"StreetAbr\" TEXT, \n\t\"City\" TEXT, \n\t\"Zip\" TEXT, \n\t\"State\" TEXT, \n\t\"MailStreet\" TEXT, \n\t\"MailStrAbr\" TEXT, \n\t\"MailCity\" TEXT, \n\t\"MailZip\" TEXT, \n\t\"MailState\" TEXT, \n\t\"Phone\" TEXT, \n\t\"Ext\" TEXT, \n\t\"Website\" TEXT, \n\t\"OpenDate\" TEXT, \n\t\"ClosedDate\" TEXT, \n\t\"Charter\" FLOAT, \n\t\"CharterNum\" TEXT, \n\t\"FundingType\" TEXT, \n\t\"DOC\" TEXT, \n\t\"DOCType\" TEXT, \n\t\"SOC\" TEXT, \n\t\"SOCType\" TEXT, \n\t\"EdOpsCode\" TEXT, \n\t\"EdOpsName\" TEXT, \n\t\"EILCode\" TEXT, \n\t\"EILName\" TEXT, \n\t\"GSoffered\" TEXT, \n\t\"GSserved\" TEXT, \n\t\"Virtual\" TEXT, \n\t\"Magnet\" FLOAT, \n\t\"Latitude\" FLOAT, \n\t\"Longitude\" FLOAT, \n\t\"AdmFName1\" TEXT, \n\t\"AdmLName1\" TEXT, \n\t\"AdmEmail1\" TEXT, \n\t\"AdmFName2\" TEXT, \n\t\"AdmLName2\" TEXT, \n\t\"AdmEmail2\" TEXT, \n\t\"AdmFName3\" TEXT, \n\t\"AdmLName3\" TEXT, \n\t\"AdmEmail3\" TEXT, \n\t\"LastUpdate\" TEXT, \n\t\"Is this in the Bay Area?\" BOOLEAN\n)\nFinal Query:\nSELECT \"32d0_schools\".City AS City,  \"32d0_schools\".\"Is this in the Bay Area?\"  AS \"In Bay Area?\" FROM \"32d0_schools\"\n</pre> <pre>Finished in 6.575707912445068 seconds\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 City        \u2502   In Bay Area? \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Hayward     \u2502              1 \u2502\n\u2502 Newark      \u2502              1 \u2502\n\u2502 Oakland     \u2502              1 \u2502\n\u2502 Berkeley    \u2502              1 \u2502\n\u2502 Oakland     \u2502              1 \u2502\n\u2502 Oakland     \u2502              1 \u2502\n\u2502 Oakland     \u2502              1 \u2502\n\u2502 Hayward     \u2502              1 \u2502\n\u2502 San Leandro \u2502              1 \u2502\n\u2502 Hayward     \u2502              1 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[4]: Copied! <pre>smoothie = bsql.execute(\"\"\"\nSELECT GROUP_CONCAT(Name, ', ') AS 'Names',\n{{LLMMap('In which time period did the person live?', Name, options=Eras.Years)}} AS \"Lived During Classification\"\nFROM People p\nGROUP BY \"Lived During Classification\"\n\"\"\")\nprint(smoothie.df)\n</pre> smoothie = bsql.execute(\"\"\" SELECT GROUP_CONCAT(Name, ', ') AS 'Names', {{LLMMap('In which time period did the person live?', Name, options=Eras.Years)}} AS \"Lived During Classification\" FROM People p GROUP BY \"Lived During Classification\" \"\"\") print(smoothie.df) <pre>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Names                                                 \u2502 Lived During Classification   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 George Washington, John Adams, President Thomas Je... \u2502 1800-1900                     \u2502\n\u2502 Sabrina Carpenter, Charli XCX, Elon Musk, Michelle... \u2502 1900-2000                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[6]: Copied! <pre># Setting `infer_gen_constraints=False` - otherwise, this counter-example would work\nsmoothie = bsql.execute(\"\"\"\nSELECT * FROM People\nWHERE People.Name IN {{LLMQA('First 3 presidents of the U.S?', return_type='List[str]')}}\n\"\"\", infer_gen_constraints=False, verbose=True)\n# The final query 'SELECT * FROM People WHERE Name IN  ('George Washington','John Adams','Thomas Jefferson')' only yields 2 rows\nprint(smoothie.df)\n</pre> # Setting `infer_gen_constraints=False` - otherwise, this counter-example would work smoothie = bsql.execute(\"\"\" SELECT * FROM People WHERE People.Name IN {{LLMQA('First 3 presidents of the U.S?', return_type='List[str]')}} \"\"\", infer_gen_constraints=False, verbose=True) # The final query 'SELECT * FROM People WHERE Name IN  ('George Washington','John Adams','Thomas Jefferson')' only yields 2 rows print(smoothie.df) <pre>Executing  `{{LLMQA('First 3 presidents of the U.S?', return_type='List[str]')}}`...\nUsing model cache...\nFinal Query:\nSELECT * FROM People WHERE People.Name IN ('George Washington', 'John Adams', 'Thomas Jefferson')\n</pre> <pre>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Name              \u2502 Known_For                                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 George Washington \u2502 Established federal government, First U.S. Preside... \u2502\n\u2502 John Adams        \u2502 XYZ Affair, Alien and Sedition Acts                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>Constrained decoding comes to our rescue. By specifying <code>infer_gen_constraints=True</code> (which is the default), BlendSQL infers from the surrounding SQL syntax that we expect a value from <code>People.Name</code>, and we force the generation to only select from values present in the <code>Name</code> column - which leads to the expected response.</p> In\u00a0[8]: Copied! <pre>smoothie = bsql.execute(\"\"\"\nSELECT * FROM People P\nWHERE P.Name IN {{LLMQA('First 3 presidents of the U.S?')}}\n\"\"\", infer_gen_constraints=True, verbose=True)\nprint(smoothie.df)\n</pre> smoothie = bsql.execute(\"\"\" SELECT * FROM People P WHERE P.Name IN {{LLMQA('First 3 presidents of the U.S?')}} \"\"\", infer_gen_constraints=True, verbose=True) print(smoothie.df) <pre>Executing  `{{LLMQA('First 3 presidents of the U.S?')}}`...\nUsing options '{'Charli XCX', 'President Thomas Jefferson', 'John Adams', 'George Washington', 'Elon Musk', 'James Madison', 'James Monroe', 'Sabrina Carpenter', 'Elvis Presley', 'Michelle Obama', 'Alexander Hamilton'}...'\nFinal Query:\nSELECT * FROM People AS P WHERE P.Name IN ('George Washington', 'James Madison', 'James Monroe')\n</pre> <pre>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Name              \u2502 Known_For                                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 George Washington \u2502 Established federal government, First U.S. Preside... \u2502\n\u2502 James Madison     \u2502 War of 1812, Constitution                             \u2502\n\u2502 James Monroe      \u2502 Monroe Doctrine, Missouri Compromise                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[9]: Copied! <pre>smoothie = bsql.execute(\"\"\"\nSELECT * FROM ( VALUES {{LLMQA('What are the first few letters of the alphabet?')}} )\n\"\"\")\nprint(smoothie.df)\n</pre> smoothie = bsql.execute(\"\"\" SELECT * FROM ( VALUES {{LLMQA('What are the first few letters of the alphabet?')}} ) \"\"\") print(smoothie.df) <pre>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col0   \u2502 col1   \u2502 col2   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 A      \u2502 B      \u2502 C      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>Ok, so we were able to generate the first letter of the alphabet... what if we want more?</p> <p>Rather than modify the prompt itself (which can be quite finicky), we can leverage the regex-inspired <code>quantifier</code> argument. This will take either the strings <code>'*'</code> (zero-or-more) or <code>'+'</code> (one-or-more), in addition to tighter bounds of <code>'{3}'</code> (exactly 3) or <code>'{1,6}'</code> (between 1 and 6).</p> In\u00a0[10]: Copied! <pre>smoothie = bsql.execute(\"\"\"\nSELECT * FROM ( VALUES {{LLMQA('What are the first letters of the alphabet?', quantifier='{5}')}} )\n\"\"\")\nprint(smoothie.df)\n</pre> smoothie = bsql.execute(\"\"\" SELECT * FROM ( VALUES {{LLMQA('What are the first letters of the alphabet?', quantifier='{5}')}} ) \"\"\") print(smoothie.df) <pre>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col0   \u2502 col1   \u2502 col2   \u2502 col3   \u2502 col4   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 A      \u2502 B      \u2502 C      \u2502 D      \u2502 E      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>What if we want to generate the letters of a different alphabet? We can use the <code>options</code> argument for this, which takes either a reference to another column in the form <code>'tablename.columnname'</code>, or a tuple of strings.</p> In\u00a0[11]: Copied! <pre>smoothie = bsql.execute(\"\"\"\nSELECT * FROM ( VALUES {{LLMQA('What are the first letters of the alphabet?', options=('\u03b1', '\u03b2', '\u03b3', '\u03b4'), quantifier='{3}')}} )\n\"\"\")\nprint(smoothie.df)\n</pre> smoothie = bsql.execute(\"\"\" SELECT * FROM ( VALUES {{LLMQA('What are the first letters of the alphabet?', options=('\u03b1', '\u03b2', '\u03b3', '\u03b4'), quantifier='{3}')}} ) \"\"\") print(smoothie.df) <pre>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col0   \u2502 col1   \u2502 col2   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 \u03b1      \u2502 \u03b2      \u2502 \u03b3      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[12]: Copied! <pre>smoothie = bsql.execute(\"\"\"\nWITH letter_agent_output AS (\n    SELECT * FROM (VALUES {{LLMQA('List some greek letters')}})\n) SELECT {{\n    LLMQA(\n        'What is the first letter of the alphabet?', \n        options=(SELECT * FROM letter_agent_output)\n    )\n}}\n\"\"\")\nprint(smoothie.df)\n</pre> smoothie = bsql.execute(\"\"\" WITH letter_agent_output AS (     SELECT * FROM (VALUES {{LLMQA('List some greek letters')}}) ) SELECT {{     LLMQA(         'What is the first letter of the alphabet?',          options=(SELECT * FROM letter_agent_output)     ) }} \"\"\") print(smoothie.df) <pre>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 _col_0   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 \u03b1        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[13]: Copied! <pre>smoothie = bsql.execute(\"\"\"\nSELECT * FROM ( VALUES {{LLMQA('Count up, starting from 1', return_type='int', quantifier='+')}} )\n\"\"\")\nprint(smoothie.df)\n</pre> smoothie = bsql.execute(\"\"\" SELECT * FROM ( VALUES {{LLMQA('Count up, starting from 1', return_type='int', quantifier='+')}} ) \"\"\") print(smoothie.df) <pre>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   col0 \u2502   col1 \u2502   col2 \u2502   col3 \u2502   col4 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502      1 \u2502      2 \u2502      3 \u2502      4 \u2502      5 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[15]: Copied! <pre># Give a short summary of the person who had a musical by Lin-Manuel Miranda written about them\nsmoothie = bsql.execute(\"\"\"\nSELECT {{\n    LLMQA(\n        'Give me a very short summary of this person', \n        context=(\n            SELECT * FROM People \n            WHERE People.Name = {{\n                LLMQA('Who has a musical by Lin-Manuel Miranda written about them?')\n            }}\n        )\n    )\n}} AS \"Summary\"\n\"\"\", verbose=True)\nprint(smoothie.df)\n</pre> # Give a short summary of the person who had a musical by Lin-Manuel Miranda written about them smoothie = bsql.execute(\"\"\" SELECT {{     LLMQA(         'Give me a very short summary of this person',          context=(             SELECT * FROM People              WHERE People.Name = {{                 LLMQA('Who has a musical by Lin-Manuel Miranda written about them?')             }}         )     ) }} AS \"Summary\" \"\"\", verbose=True) print(smoothie.df) <pre>Executing  `{{LLMQA('Give me a very short summary of this person', context=(SELECT * FROM People WHERE People.Name = {{LLMQA('Who has a musical by Lin-Manuel Miranda written about them?')}}))}}`...\nExecuting  `{{LLMQA('Who has a musical by Lin-Manuel Miranda written about them?')}}`...\nUsing options '{'Charli XCX', 'President Thomas Jefferson', 'John Adams', 'George Washington', 'Elon Musk', 'James Monroe', 'James Madison', 'Sabrina Carpenter', 'Elvis Presley', 'Michelle Obama', 'Alexander Hamilton'}...'\nFinal Query:\nSELECT * FROM People WHERE People.Name = 'Alexander Hamilton'\nUsing model cache...\nFinal Query:\nSELECT 'Founding father and financial leader' AS \"Summary\"\n</pre> <pre>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Summary                              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Founding father and financial leader \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[17]: Copied! <pre># A two-step reasoning problem:\n#   1) Identify who, out of the table, is a singer using `LLMMap`\n#   2) Where the previous step yields `TRUE`, select the one that wrote the song Espresso.\nsmoothie = bsql.execute(\"\"\"\nWITH Musicians AS\n    (\n        SELECT Name FROM People\n        WHERE {{LLMMap('Is a singer?', Name)}} = TRUE\n    )\nSELECT Name AS \"working late cuz they're a singer\" FROM Musicians M\nWHERE M.Name = {{LLMQA('Who wrote the song \"Espresso?\"')}}\n\"\"\", verbose=True)\nprint(smoothie.df)\n</pre> # A two-step reasoning problem: #   1) Identify who, out of the table, is a singer using `LLMMap` #   2) Where the previous step yields `TRUE`, select the one that wrote the song Espresso. smoothie = bsql.execute(\"\"\" WITH Musicians AS     (         SELECT Name FROM People         WHERE {{LLMMap('Is a singer?', Name)}} = TRUE     ) SELECT Name AS \"working late cuz they're a singer\" FROM Musicians M WHERE M.Name = {{LLMQA('Who wrote the song \"Espresso?\"')}} \"\"\", verbose=True) print(smoothie.df) <pre>Executing  `{{LLMQA('Who wrote the song \"Espresso?\"')}}`...\nMaterializing CTE `Musicians`...\nExecuting `SELECT People.Name AS Name FROM People WHERE {{LLMMap('Is a singer?', People.Name)}} = TRUE` and setting to `Musicians`\nExecuting  `{{LLMMap('Is a singer?', People.Name)}}`...\nExtracted predicate literals `[True]`\nUsing regex '(t|f|true|false|True|False)'\nUsing model cache...\nUsing model cache...\nUsing model cache...\nUsing model cache...\nUsing model cache...\nUsing model cache...\nUsing model cache...\nUsing model cache...\nUsing model cache...\nUsing model cache...\nUsing model cache...\n</pre> <pre>LLMMap with batch_size=1: 0it [00:00, ?it/s]</pre> <pre>Finished LLMMap with values:\n{\n    \"Elon Musk\": false,\n    \"George Washington\": false,\n    \"Elvis Presley\": true,\n    \"James Monroe\": false,\n    \"Charli XCX\": true,\n    \"John Adams\": false,\n    \"James Madison\": true,\n    \"Alexander Hamilton\": true,\n    \"Sabrina Carpenter\": true,\n    \"President Thomas Jefferson\": false\n}\nCombining 1 outputs for table `People`\nCREATE OR REPLACE TEMP TABLE \"7f1e_People\" AS SELECT * FROM df\nCreated temp table 7f1e_People\nFinal Query:\nSELECT \"7f1e_People\".Name AS Name FROM \"7f1e_People\" WHERE \"7f1e_People\".\"Is a singer?\" = TRUE\nCREATE OR REPLACE TEMP TABLE \"Musicians\" AS SELECT * FROM df\nCreated temp table Musicians\nUsing options '{'Charli XCX', 'James Madison', 'Sabrina Carpenter', 'Elvis Presley', 'Michelle Obama', 'Alexander Hamilton'}...'\nUsing model cache...\nFinal Query:\nSELECT M.Name AS \"working late cuz they're a singer\" FROM Musicians AS M WHERE M.Name = 'Charli XCX'\n</pre> <pre>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 working late cuz they're a singer   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Charli XCX                          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>Let's ask a question that requires a bit more world-knowledge to answer.</p> In\u00a0[18]: Copied! <pre>smoothie = bsql.execute(\"\"\"\nSELECT * FROM People WHERE Name = {{LLMQA(\"Who's birthday is June 28, 1971?\")}}\"\"\")\nprint(smoothie.df)\n</pre> smoothie = bsql.execute(\"\"\" SELECT * FROM People WHERE Name = {{LLMQA(\"Who's birthday is June 28, 1971?\")}}\"\"\") print(smoothie.df) <pre>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Name          \u2502 Known_For                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Elvis Presley \u2502 14 Grammys, King of Rock n Roll \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>Not right - Elvis was born in 1935.</p> <p>Now let's try again, using constrained decoding via <code>options</code> and using the <code>RAGQA</code> ingredient to fetch relevant context via a Tavily web search first.</p> In\u00a0[28]: Copied! <pre>from blendsql.ingredients import LLMQA\nfrom blendsql.search import TavilySearch\n\nfrom dotenv import load_dotenv\n\nload_dotenv() # Assumes we have a .env file with a `TAVILY_API_KEY` variable set.\n\nRAGQA = LLMQA.from_args(\n    searcher=TavilySearch(\n        k=2,  # Retrieve 2 document on each search\n    ),\n) # Whatever variable name we use here, we can refer to the function as that in our `execute` call\n\nsmoothie = bsql.execute(\"\"\"\nSELECT * FROM People WHERE Name = {{RAGQA(\"Who's birthday is June 28, 1971?\")}}\n\"\"\", ingredients={RAGQA}, verbose=True)\nprint(smoothie.df)\n</pre> from blendsql.ingredients import LLMQA from blendsql.search import TavilySearch  from dotenv import load_dotenv  load_dotenv() # Assumes we have a .env file with a `TAVILY_API_KEY` variable set.  RAGQA = LLMQA.from_args(     searcher=TavilySearch(         k=2,  # Retrieve 2 document on each search     ), ) # Whatever variable name we use here, we can refer to the function as that in our `execute` call  smoothie = bsql.execute(\"\"\" SELECT * FROM People WHERE Name = {{RAGQA(\"Who's birthday is June 28, 1971?\")}} \"\"\", ingredients={RAGQA}, verbose=True) print(smoothie.df) <pre>Executing  `{{RAGQA(\"Who's birthday is June 28, 1971?\")}}`...\nRetrieved contexts '['Famous People Born on June 28, 1971 - BirthdayDBs....', 'June 28th, 1971 (Monday): Birthday, Zodiac &amp; Weekd...']'\nUsing options '{'Charli XCX', 'James Madison', 'John Quincy Adams', 'Michelle Obama', 'Thomas Jefferson', 'George Washington', 'Sabrina Carpenter', 'Alexander Hamilton', 'Elon Musk', 'Elvis Presley', 'James Monroe'}...'\nUsing model cache...\nFinal Query:\nSELECT * FROM People WHERE People.Name = 'Elon Musk'\n</pre> <pre>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Name      \u2502 Known_For                            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Elon Musk \u2502 Tesla, SpaceX, Twitter/X acquisition \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>Nice! Elon Musk was indeed born on June 28th, 1971. You can check out the BlendSQL logs above to validate this given the web context.</p>"},{"location":"reference/examples/blendsql-by-example/#blendsql-by-example","title":"BlendSQL by Example\u00b6","text":"<p>This notebook introduces BlendSQL, and some of the usecases it can support.</p> <p>Importantly, the novelty of BlendSQL isn't from the ability to constrain language models according to some regular expression or context-free grammar. We can credit projects like guidance and outlines for that. Instead, the novelty of BlendSQL is its ability to infer these constraints according to the surrounding SQL syntax and closely align generation to the structure of the database.</p> <p>SQL, as a grammar, has a lot of rules. Just take these SQLite syntax diagrams for example. These rules include things like, <code>IN</code> statement should be followed by a list of items, <code>&lt;</code>, <code>&gt;</code>, should contain numerics, but <code>=</code> could contain any datatype, etc. We can use these to inform language-model functions, which we call 'ingredients', and denote in double curly brackets (<code>{{</code> and <code>}}</code>).</p>"},{"location":"reference/examples/blendsql-by-example/#a-note-on-models","title":"A Note on Models\u00b6","text":"<p>This demo uses LlamaCpp, and assumes access to a GPU.</p> <p>If you don't have the ability to run this model, take a look at any of the other model integrations that BlendSQL supports. Importantly, note that only local models via <code>TransformersLLM</code> and <code>LlamaCpp</code> give the type constraints from the Play by the Type Rules paper.</p>"},{"location":"reference/examples/blendsql-by-example/#the-elephant-in-the-room-arent-llm-functions-in-sql-super-slow","title":"The Elephant in the Room - Aren't LLM Functions in SQL Super Slow?\u00b6","text":"<p>Short answer - compared to nearly all native SQL operations, yes.</p> <p>However, when using remote APIs like OpenAI or Anthropic, we can dramatically speed up processing times by batching async requests. Below demonstrates that, for a table with 17,686 rows and 1,165 unique values in the column we process, it takes only about 6.5 seconds to run our query with gpt-4o-mini (or about 0.005 seconds per value).</p> <p>By default, we allow 10 concurrent async requests. Depending on your own quotas set by the API provider, you may be able to increase this number using:</p> <pre>from blendsql import config \n\n# Set the limit for max async calls at a given time below\nconfig.set_async_limit(20)\n</pre>"},{"location":"reference/examples/blendsql-by-example/#a-note-on-query-optimizations","title":"A Note on Query Optimizations\u00b6","text":"<p>Because LLM functions are relatively slow compared to other SQL functions, when we perform query optimizations behind the scenes, we make sure to execute all native SQL functions before any LLM-based functions. This ensures the language model only receives the smallest set of data it needs to faithfully evaluate a given SQL expression</p>"},{"location":"reference/examples/blendsql-by-example/#classification-with-llmmap-and-group-by-constrained-by-a-columns-values","title":"Classification with 'LLMMap' and GROUP BY', Constrained by a Column's Values\u00b6","text":"<p>Below, we set up a BlendSQL query leveraging the <code>LLMMap</code> ingredient. This is a unary function similar to the <code>LENGTH</code> or <code>ABS</code> functions in standard SQLite. It takes a single argument (a value from a column) and returns a transformed output, which is then assigned to a new column.</p> <p>Below, we set up a language-model function which takes in the values from the <code>Name</code> column of the <code>People</code> table, and outputs a value exclusively selected from the <code>Eras.Years</code> column.</p>"},{"location":"reference/examples/blendsql-by-example/#constrained-decoding-the-presidents-challenge","title":"Constrained Decoding - The Presidents Challenge\u00b6","text":"<p>Why does constrained decoding matter? Imagine we want to select all the information we have in our table about the first 3 presidents of the U.S. In the absence of relevant data stored in our database, we turn to our language model. But one thing thwarts our plans - the language model doesn't know that we've stored the 3rd president's name in our database as <code>'President Thomas Jefferson'</code>, not <code>'Thomas Jefferson'</code>.</p>"},{"location":"reference/examples/blendsql-by-example/#constrained-decoding-the-alphabet-challenge","title":"Constrained Decoding - The Alphabet Challenge\u00b6","text":"<p>In BlendSQL, we can utilize the power of constrained decoding to guide a language model's generation towards the structure we expect. In other words, rather than taking a \"prompt-and-pray\" approach in which we meticulously craft a natural language prompt which (hopefully) generates a list of 3 strings, we can interact with the logit space to ensure this is the case<sup>1</sup>.</p> <p>[!NOTE] These guarantees are only made possible with open models, i.e. where we can access the underlying logits. For closed-models like OpenAI and Anthropic, we rely on prompting (i.e. 'Datatype: List[str]') and make predictions \"optimistically\"</p> <p>To demonstrate this, we can use the <code>LLMQA</code> ingredient. This ingredient optionally takes in a table subset as context, and returns either a scalar value or a list of scalars.</p> <p>Since BlendSQL can infer the shape of a valid generation according to the surrounding SQL syntax, when we use the <code>LLMQA</code> ingredient in a <code>VALUES</code> or <code>IN</code> clause, it will generate a list by default.</p>"},{"location":"reference/examples/blendsql-by-example/#agent-based-inference-with-cte-expressions","title":"Agent-Based Inference with CTE Expressions\u00b6","text":"<p>The above example opens up the opportunity to rewrite the query as more of an agent-based flow. SQL is a bit odd in that it's executed bottom-up, i.e. to execute the following query:</p> <pre>SELECT the_answer FROM final_table WHERE final_table.x IN \n    (SELECT some_field FROM initial_table)\n</pre> <p>...We first gather <code>some_field</code> from <code>initial_table</code>, and then go and fetch <code>the_answer</code>, despite the author (human or AI) having written the second step, first. This is similar to the point made by Google in the pipe-syntax paper about how SQL syntactic clause order doesn't match semantic evaluation order.</p> <p>At the end of the day, we have two agents performing the following tasks -</p> <ol> <li>Brainstorm some greek letters</li> <li>Using the output of the previous task, select only the first 3</li> </ol> <p>With BlendSQL, we can use common table expressions (CTEs) to more closely mimic this order of 'agents'.</p>"},{"location":"reference/examples/blendsql-by-example/#using-return_type-to-influence-generation","title":"Using <code>return_type</code> to Influence Generation\u00b6","text":"<p>BlendSQL does its best to infer datatytpes given surrounding syntax. Sometimes, though, the user may want to override those assumptions, or inject new ones that were unable to be inferred.</p> <p>The <code>return_type</code> argument takes a Python-style type annotation like <code>int</code>, <code>str</code>, <code>bool</code> or <code>float</code>. Below we use that to guide the generation towards one-or-more integer.</p>"},{"location":"reference/examples/blendsql-by-example/#rag-for-unstructured-reasoning","title":"RAG for Unstructured Reasoning\u00b6","text":"<p>In addition to using the <code>LLMQA</code> ingredient as a method for generating with tight syntax-aware constraints, we can also relax a bit and let the model give us an unstructured generation for things like summarization.</p> <p>Also, we can use the <code>context</code> argument to provide relevant table context. This allows us to condition generation on a curated set of data (and do cool stuff with nested reasoning).</p>"},{"location":"reference/examples/blendsql-by-example/#internet-connected-rag","title":"Internet-Connected RAG\u00b6","text":"<p>So we know how to use a table subset as a context, by writing subqueries. But what if the knowledge we need to answer a question isn't present in the universe of our table?</p> <p>For this, we can hook up all of our ingredients with some search functions. Modifying the behavior of the default ingredients can be done by initializing it via <code>from_args()</code> call, and passing the new object in either the <code>bsql.execute(ingredients={new_obj})</code> call, or the original DB creation in <code>BlendSQL(ingredients={new_obj})</code>.</p>"},{"location":"reference/examples/teaching-blendsql-via-in-context-learning/","title":"Teaching BlendSQL via In-Context Learning","text":"In\u00a0[14]: Copied! <pre>from typing import List\nfrom textwrap import dedent\nimport outlines\n\nfrom blendsql import blend\nfrom blendsql.ingredients import LLMMap, LLMJoin, LLMQA\nfrom blendsql.models import OpenaiLLM\nfrom blendsql.models._model import Model\nfrom blendsql._program import Program\nfrom blendsql.db import SQLite\nfrom blendsql.utils import fetch_from_hub\n</pre> from typing import List from textwrap import dedent import outlines  from blendsql import blend from blendsql.ingredients import LLMMap, LLMJoin, LLMQA from blendsql.models import OpenaiLLM from blendsql.models._model import Model from blendsql._program import Program from blendsql.db import SQLite from blendsql.utils import fetch_from_hub In\u00a0[15]: Copied! <pre># 1) Define our few-shot examples\nexamples = [\n   {\n        \"serialized_db\": 'CREATE TABLE \"w\" (\\n\"index\" INTEGER,\\n  \"name\" TEXT,\\n  \"province\" TEXT,\\n  \"city\" TEXT,\\n  \"year\" TEXT,\\n  \"remarks\" TEXT\\n)\\n/*\\n3 example rows:\\nSELECT * FROM w LIMIT 3\\n index                      name          province     city year                                                         remarks\\n     0       abdul rahman mosque    kabul province    kabul 2009                                   largest mosque in afghanistan\\n     1 friday mosque of kandahar kandahar province kandahar 1750                houses the cloak of the islamic prophet muhammad\\n     2     omar al-farooq mosque kandahar province kandahar 2014 built on the site that was a popular cinema of kandahar . [ 1 ]\\n*/\\n\\nCREATE VIRTUAL TABLE \"documents\" USING fts5(title, content, tokenize = \\'trigram\\')',\n        \"question\": \"Who were the builders of the mosque in Herat with fire temples ?\",\n        \"blendsql\": \"\"\"\n        {{\n            LLMQA(\n                'Who were the builders of the mosque?',\n                (\n                    SELECT documents.title AS 'Building', documents.content FROM documents\n                    JOIN {{\n                        LLMJoin(\n                            left_on='w::name',\n                            right_on='documents::title'\n                        )\n                    }}\n                    WHERE w.city = 'herat' AND w.remarks LIKE '%fire temple%'\n                )\n            )\n        }}\n        \"\"\",\n    },\n    {\n        \"serialized_db\": 'CREATE TABLE \"w\" (\\n\"index\" INTEGER,\\n  \"no\" INTEGER,\\n  \"rider\" TEXT,\\n  \"team\" TEXT,\\n  \"motorcycle\" TEXT\\n)\\n/*\\n3 example rows:\\nSELECT * FROM w LIMIT 3\\n index  no          rider                 team      motorcycle\\n     0   1   carl fogarty   ducati performance      ducati 996\\n     1   4 akira yanagawa kawasaki racing team kawasaki zx-7rr\\n     2   5  colin edwards        castrol honda      honda rc45\\n*/\\n\\nCREATE VIRTUAL TABLE \"documents\" USING fts5(title, content, tokenize = \\'trigram\\')',\n        \"question\": \"After what season did the number 7 competitor retire ?\",\n        \"blendsql\": \"\"\"\n        {{\n            LLMQA(\n                'When did the competitor retire?',\n                (\n                    SELECT documents.title AS 'Competitor', documents.content FROM documents\n                    JOIN {{\n                        LLMJoin(\n                            left_on='w::rider',\n                            right_on='documents::title'\n                        )\n                    }}\n                    WHERE w.no = 7\n                )\n            )\n        }}\n        \"\"\",\n    },\n    {\n        \"serialized_db\": 'CREATE TABLE \"w\" (\\n\"index\" INTEGER,\\n  \"year\" TEXT,\\n  \"winner\" TEXT,\\n  \"position\" TEXT,\\n  \"school\" TEXT\\n)\\n/*\\n3 example rows:\\nSELECT * FROM w LIMIT 3\\n index    year         winner   position     school\\n     0 1961-62       ron ryan right wing      colby\\n     1 1962-63 bob brinkworth     center rensselaer\\n     2 1963-64 bob brinkworth     center rensselaer\\n*/\\n\\nCREATE VIRTUAL TABLE \"documents\" USING fts5(title, content, tokenize = \\'trigram\\')',\n        \"question\": \"What year was the 1971-72 ECAC Hockey Player of the Year born ?\",\n        \"blendsql\": \"\"\"\n        {{\n            LLMQA(\n                'What year was the player born?',\n                (\n                    SELECT documents.title AS 'Player', documents.content FROM documents\n                    JOIN {{\n                        LLMJoin(\n                            left_on = 'w::winner',\n                            right_on = 'documents::title'\n                        )\n                    }}\n                    WHERE w.year = '1971-72'\n                )\n            )\n        }}\n        \"\"\",\n    },\n    {\n        \"serialized_db\": 'CREATE TABLE \"w\" (\\n\"index\" INTEGER,\\n  \"date\" TEXT,\\n  \"language\" TEXT,\\n  \"language family\" TEXT,\\n  \"region\" TEXT\\n)\\n/*\\n3 example rows:\\nSELECT * FROM w LIMIT 3\\n index                     date language language family      region\\n     0 early 2nd millennium bce sumerian         isolate mesopotamia\\n     1       2nd millennium bce  eblaite         semitic       syria\\n     2            ca . 1100 bce  hittite       anatolian    anatolia\\n*/\\n\\nCREATE VIRTUAL TABLE \"documents\" USING fts5(title, content, tokenize = \\'trigram\\')',\n        \"question\": \"What was the language family that was used in Hattusa , as well as parts of the northern Levant and Upper Mesopotamia ?\",\n        \"blendsql\": \"\"\"\n        SELECT \"language family\" FROM w\n        WHERE language = {{\n            LLMQA(\n                'Which language was used in Hattusa, as well as parts of the northern Levant and Upper Mesopotamia ?',\n                (SELECT title, content FROM documents WHERE documents MATCH 'hattusa'),\n                options='w::language'\n            )\n        }}\n       \"\"\",\n    },\n]\n</pre> # 1) Define our few-shot examples examples = [    {         \"serialized_db\": 'CREATE TABLE \"w\" (\\n\"index\" INTEGER,\\n  \"name\" TEXT,\\n  \"province\" TEXT,\\n  \"city\" TEXT,\\n  \"year\" TEXT,\\n  \"remarks\" TEXT\\n)\\n/*\\n3 example rows:\\nSELECT * FROM w LIMIT 3\\n index                      name          province     city year                                                         remarks\\n     0       abdul rahman mosque    kabul province    kabul 2009                                   largest mosque in afghanistan\\n     1 friday mosque of kandahar kandahar province kandahar 1750                houses the cloak of the islamic prophet muhammad\\n     2     omar al-farooq mosque kandahar province kandahar 2014 built on the site that was a popular cinema of kandahar . [ 1 ]\\n*/\\n\\nCREATE VIRTUAL TABLE \"documents\" USING fts5(title, content, tokenize = \\'trigram\\')',         \"question\": \"Who were the builders of the mosque in Herat with fire temples ?\",         \"blendsql\": \"\"\"         {{             LLMQA(                 'Who were the builders of the mosque?',                 (                     SELECT documents.title AS 'Building', documents.content FROM documents                     JOIN {{                         LLMJoin(                             left_on='w::name',                             right_on='documents::title'                         )                     }}                     WHERE w.city = 'herat' AND w.remarks LIKE '%fire temple%'                 )             )         }}         \"\"\",     },     {         \"serialized_db\": 'CREATE TABLE \"w\" (\\n\"index\" INTEGER,\\n  \"no\" INTEGER,\\n  \"rider\" TEXT,\\n  \"team\" TEXT,\\n  \"motorcycle\" TEXT\\n)\\n/*\\n3 example rows:\\nSELECT * FROM w LIMIT 3\\n index  no          rider                 team      motorcycle\\n     0   1   carl fogarty   ducati performance      ducati 996\\n     1   4 akira yanagawa kawasaki racing team kawasaki zx-7rr\\n     2   5  colin edwards        castrol honda      honda rc45\\n*/\\n\\nCREATE VIRTUAL TABLE \"documents\" USING fts5(title, content, tokenize = \\'trigram\\')',         \"question\": \"After what season did the number 7 competitor retire ?\",         \"blendsql\": \"\"\"         {{             LLMQA(                 'When did the competitor retire?',                 (                     SELECT documents.title AS 'Competitor', documents.content FROM documents                     JOIN {{                         LLMJoin(                             left_on='w::rider',                             right_on='documents::title'                         )                     }}                     WHERE w.no = 7                 )             )         }}         \"\"\",     },     {         \"serialized_db\": 'CREATE TABLE \"w\" (\\n\"index\" INTEGER,\\n  \"year\" TEXT,\\n  \"winner\" TEXT,\\n  \"position\" TEXT,\\n  \"school\" TEXT\\n)\\n/*\\n3 example rows:\\nSELECT * FROM w LIMIT 3\\n index    year         winner   position     school\\n     0 1961-62       ron ryan right wing      colby\\n     1 1962-63 bob brinkworth     center rensselaer\\n     2 1963-64 bob brinkworth     center rensselaer\\n*/\\n\\nCREATE VIRTUAL TABLE \"documents\" USING fts5(title, content, tokenize = \\'trigram\\')',         \"question\": \"What year was the 1971-72 ECAC Hockey Player of the Year born ?\",         \"blendsql\": \"\"\"         {{             LLMQA(                 'What year was the player born?',                 (                     SELECT documents.title AS 'Player', documents.content FROM documents                     JOIN {{                         LLMJoin(                             left_on = 'w::winner',                             right_on = 'documents::title'                         )                     }}                     WHERE w.year = '1971-72'                 )             )         }}         \"\"\",     },     {         \"serialized_db\": 'CREATE TABLE \"w\" (\\n\"index\" INTEGER,\\n  \"date\" TEXT,\\n  \"language\" TEXT,\\n  \"language family\" TEXT,\\n  \"region\" TEXT\\n)\\n/*\\n3 example rows:\\nSELECT * FROM w LIMIT 3\\n index                     date language language family      region\\n     0 early 2nd millennium bce sumerian         isolate mesopotamia\\n     1       2nd millennium bce  eblaite         semitic       syria\\n     2            ca . 1100 bce  hittite       anatolian    anatolia\\n*/\\n\\nCREATE VIRTUAL TABLE \"documents\" USING fts5(title, content, tokenize = \\'trigram\\')',         \"question\": \"What was the language family that was used in Hattusa , as well as parts of the northern Levant and Upper Mesopotamia ?\",         \"blendsql\": \"\"\"         SELECT \"language family\" FROM w         WHERE language = {{             LLMQA(                 'Which language was used in Hattusa, as well as parts of the northern Levant and Upper Mesopotamia ?',                 (SELECT title, content FROM documents WHERE documents MATCH 'hattusa'),                 options='w::language'             )         }}        \"\"\",     }, ] In\u00a0[16]: Copied! <pre># 2) Define our prompt to the Parser LLM\nclass ParserProgram(Program):\n    def __call__(self, model: Model, examples: List[dict], serialized_db: str, question: str, **kwargs):\n        prompt = \"\"\n        prompt += dedent(\"\"\"\n        Generate BlendSQL given the question, table, and passages to answer the question correctly.\n        BlendSQL is a superset of SQLite, which adds external function calls for information not found within native SQLite.\n        These external functions should be wrapped in double curly brackets.\n\n        If question-relevant column(s) contents are not suitable for SQL comparisons or calculations, map it to a new column with clean content by a new grammar:\n            `LLMMap('question', '{table}::{column}')`\n\n        If mapping to a new column still cannot answer the question with valid SQL, turn to an end-to-end solution using a new grammar:\n            `LLMQA('{question}', ({blendsql}))`\n\n        If we need to do a `join` operation where there is imperfect alignment between table values, use the new grammar:\n            `LLMJoin(({blendsql}), options='{table}::{column}')`\n\n        ONLY use these BlendSQL ingredients if necessary.\n        Answer parts of the question in vanilla SQL, if possible.\n\n        Examples:\\n\n        \"\"\")\n        for example in examples:\n            prompt += f\"{example['serialized_db']}\\n\\n\"\n            prompt += f\"Question: {example['question']}\\n\"\n            prompt += f\"BlendSQL: {example['blendsql']}\\n\"\n        prompt += f\"{serialized_db}\\n\\n\"\n        prompt += f\"Question: {question}\\n\"\n        prompt += f\"BlendSQL: \"\n        generator = outlines.generate.text(model.model_obj)\n        result = generator(prompt)\n        return (result, prompt)\n</pre> # 2) Define our prompt to the Parser LLM class ParserProgram(Program):     def __call__(self, model: Model, examples: List[dict], serialized_db: str, question: str, **kwargs):         prompt = \"\"         prompt += dedent(\"\"\"         Generate BlendSQL given the question, table, and passages to answer the question correctly.         BlendSQL is a superset of SQLite, which adds external function calls for information not found within native SQLite.         These external functions should be wrapped in double curly brackets.          If question-relevant column(s) contents are not suitable for SQL comparisons or calculations, map it to a new column with clean content by a new grammar:             `LLMMap('question', '{table}::{column}')`          If mapping to a new column still cannot answer the question with valid SQL, turn to an end-to-end solution using a new grammar:             `LLMQA('{question}', ({blendsql}))`          If we need to do a `join` operation where there is imperfect alignment between table values, use the new grammar:             `LLMJoin(({blendsql}), options='{table}::{column}')`          ONLY use these BlendSQL ingredients if necessary.         Answer parts of the question in vanilla SQL, if possible.          Examples:\\n         \"\"\")         for example in examples:             prompt += f\"{example['serialized_db']}\\n\\n\"             prompt += f\"Question: {example['question']}\\n\"             prompt += f\"BlendSQL: {example['blendsql']}\\n\"         prompt += f\"{serialized_db}\\n\\n\"         prompt += f\"Question: {question}\\n\"         prompt += f\"BlendSQL: \"         generator = outlines.generate.text(model.model_obj)         result = generator(prompt)         return (result, prompt) In\u00a0[17]: Copied! <pre>def few_shot_blendsql(question: str, db: SQLite, parser: Model, blender: Model):\n    # 3) Call the parser with our prompt\n    predicted_query = parser.predict(\n        program=ParserProgram,\n        serialized_db=db.to_serialized(),\n        question=question,\n        examples=examples\n    )\n    # 4) Execute the BlendSQL query to get the final answer\n    smoothie = blend(\n        query=predicted_query,\n        db=db,\n        ingredients={LLMMap, LLMQA, LLMJoin},\n        verbose=False,\n        default_model=blender\n    )\n    return (predicted_query, smoothie)\n</pre> def few_shot_blendsql(question: str, db: SQLite, parser: Model, blender: Model):     # 3) Call the parser with our prompt     predicted_query = parser.predict(         program=ParserProgram,         serialized_db=db.to_serialized(),         question=question,         examples=examples     )     # 4) Execute the BlendSQL query to get the final answer     smoothie = blend(         query=predicted_query,         db=db,         ingredients={LLMMap, LLMQA, LLMJoin},         verbose=False,         default_model=blender     )     return (predicted_query, smoothie) In\u00a0[18]: Copied! <pre>blendsql, smoothie = few_shot_blendsql(\n    question=\"What team did New Zealand play in the city featuring the Mount Panorama racetrack ?\",\n    db=SQLite(fetch_from_hub(\"1884_New_Zealand_rugby_union_tour_of_New_South_Wales_1.db\")),\n    default_model=OpenaiLLM(\"gpt-3.5-turbo\"),\n    parser=OpenaiLLM(\"gpt-3.5-turbo\")\n)\n</pre> blendsql, smoothie = few_shot_blendsql(     question=\"What team did New Zealand play in the city featuring the Mount Panorama racetrack ?\",     db=SQLite(fetch_from_hub(\"1884_New_Zealand_rugby_union_tour_of_New_South_Wales_1.db\")),     default_model=OpenaiLLM(\"gpt-3.5-turbo\"),     parser=OpenaiLLM(\"gpt-3.5-turbo\") ) In\u00a0[19]: Copied! <pre>print(blendsql)\n</pre> print(blendsql) <pre>SELECT rival \nFROM w \nWHERE city = {{\n    LLMQA(\n        'What city features the Mount Panorama racetrack?',\n        (SELECT title, content FROM documents WHERE documents MATCH 'mount panorama racetrack'),\n        options='w::city'\n    )\n}}\n</pre> In\u00a0[20]: Copied! <pre>smoothie.df\n</pre> smoothie.df Out[20]: rival 0 western districts"},{"location":"reference/examples/teaching-blendsql-via-in-context-learning/#teaching-blendsql-via-in-context-learning","title":"Teaching BlendSQL via In-Context Learning\u00b6","text":"<p>NOTE: This notebook is using an old version of blendsql. The same ideas apply, but syntax might differ in the latest version. Reach out in our Discord, or email me at parkervg5@gmail.com if you want help!</p> <p>As described in our paper, the real power of BlendSQL comes when it is used as an intermediate representation for tasks requiring complex reasoning across many different forms of data.</p> <p>In this notebook, we show an example of how we can 'teach' an instruction-finetuned language model how to write with this new dialect of SQL. Our pipeline can be summarized as:</p> <ol> <li>Define few-shot examples, using our dataset</li> <li>Design a prompt for our Parser LLM, which explains the task we want it to achieve</li> <li>Call our Parser with our prompt + a question to get a BlendSQL query</li> <li>Execute the BlendSQL query with <code>blend()</code> to retrieve the final answer</li> </ol>"},{"location":"reference/examples/vqa-ingredient/","title":"Custom VQA Ingredient with LLaVA","text":"In\u00a0[1]: Copied! <pre>from typing import List\nfrom blendsql import blend\nfrom blendsql.models import TransformersLLM, ModelObj\nfrom blendsql.ingredients import MapIngredient, IngredientException\nfrom blendsql.utils import fetch_from_hub\nfrom blendsql.db import SQLite\n</pre> from typing import List from blendsql import blend from blendsql.models import TransformersLLM, ModelObj from blendsql.ingredients import MapIngredient, IngredientException from blendsql.utils import fetch_from_hub from blendsql.db import SQLite In\u00a0[2]: Copied! <pre>db = SQLite(fetch_from_hub(\"Fountains_in_Portland,_Oregon_0.db\"))\n</pre> db = SQLite(fetch_from_hub(\"Fountains_in_Portland,_Oregon_0.db\")) In\u00a0[3]: Copied! <pre>db.execute_to_df(\"SELECT * FROM w;\")\n</pre> db.execute_to_df(\"SELECT * FROM w;\") Out[3]: index title designer ( s ) year 0 0 animals in pools georgia gerber 1986 1 1 the car wash ( officially untitled ) carter , hull , nishita , mcculley and baxter 1977 2 2 the dreamer manuel izquierdo 1979 3 3 elk roland hinton perry 1900 4 4 holladay park fountain tim clemen ( murase associates ) 2000 5 5 keller fountain angela danadjieba ( lawrence halprin associates ) 1971 6 6 kelly fountain lee kelly 1977 7 7 lovejoy fountain lawrence halprin associates 1968 8 8 mccoy fountain murase associates 2000 9 9 pioneer courthouse square waterfall fountain will martin 1983 10 10 the rose petal none 1978 11 11 salmon street springs robert perron landscape architects 1988 12 12 shemanski fountain ( rebecca at the well ) carl l. linde oliver laurence barrett 1926 ( 1928 ) 13 13 skidmore fountain olin levi warner 1888 In\u00a0[29]: Copied! <pre>try:\n    from PIL import Image\nexcept:\n    print(\"Installing pillow...\")\n    !pip install pillow\n    from PIL import Image\n# Create our custom ingredient as a child of `MapIngredient`\nfrom io import BytesIO\nfrom transformers import pipeline\n\nclass VQAModel(TransformersLLM):\n    \n    def _load_model(self) -&gt; ModelObj:\n        return pipeline(\"image-to-text\", model=self.model_name_or_path)\n\n    def predict(self, question: str, img_bytes: List[bytes]) -&gt; str:\n        prompt = f\"USER: &lt;image&gt;\\n{question}\"\n        model_output = self.model_obj(\n            images=[\n                Image.open(BytesIO(value)) for value in img_bytes\n            ],\n            prompt=prompt,\n            generate_kwargs={\"max_new_tokens\": 200}\n        )\n        return [output[0][\"generated_text\"].lstrip(prompt).strip() for output in model_output]\n\nclass VQA(MapIngredient):\n    def run(self, model: VQAModel, question: str, values: List[bytes], **kwargs):\n        \"\"\"Given a list of byte arrays, calls a tiny Llava model\n        to answer a given question.\n        \"\"\"\n        if not all(isinstance(value, bytes) for value in values):\n            raise IngredientException(f\"All values must be 'byte' type for LlavaVQA!\")\n        model_output = model.predict(question=question, img_bytes=values)\n        return model_output\n</pre> try:     from PIL import Image except:     print(\"Installing pillow...\")     !pip install pillow     from PIL import Image # Create our custom ingredient as a child of `MapIngredient` from io import BytesIO from transformers import pipeline  class VQAModel(TransformersLLM):          def _load_model(self) -&gt; ModelObj:         return pipeline(\"image-to-text\", model=self.model_name_or_path)      def predict(self, question: str, img_bytes: List[bytes]) -&gt; str:         prompt = f\"USER: \\n{question}\"         model_output = self.model_obj(             images=[                 Image.open(BytesIO(value)) for value in img_bytes             ],             prompt=prompt,             generate_kwargs={\"max_new_tokens\": 200}         )         return [output[0][\"generated_text\"].lstrip(prompt).strip() for output in model_output]  class VQA(MapIngredient):     def run(self, model: VQAModel, question: str, values: List[bytes], **kwargs):         \"\"\"Given a list of byte arrays, calls a tiny Llava model         to answer a given question.         \"\"\"         if not all(isinstance(value, bytes) for value in values):             raise IngredientException(f\"All values must be 'byte' type for LlavaVQA!\")         model_output = model.predict(question=question, img_bytes=values)         return model_output In\u00a0[30]: Copied! <pre># Initialize our VQA model\nmodel = VQAModel(model_name_or_path=\"bczhou/tiny-llava-v1-hf\")\n</pre> # Initialize our VQA model model = VQAModel(model_name_or_path=\"bczhou/tiny-llava-v1-hf\") <pre>Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n</pre> In\u00a0[31]: Copied! <pre>b = db.execute_to_list(\"SELECT img_bytes FROM images WHERE title = 'the car wash ( officially untitled )'\")[0]\nImage.open(BytesIO(b))\n</pre> b = db.execute_to_list(\"SELECT img_bytes FROM images WHERE title = 'the car wash ( officially untitled )'\")[0] Image.open(BytesIO(b)) Out[31]: In\u00a0[\u00a0]: Copied! <pre>smoothie = blend(\n    query=\"\"\"\n    SELECT {{VQA('What is in this image?', 'images::img_bytes')}}\n        FROM images WHERE title = 'the car wash ( officially untitled )'\n    \"\"\",\n    db=db,\n    ingredients={VQA},\n    default_model=model\n)\n</pre> smoothie = blend(     query=\"\"\"     SELECT {{VQA('What is in this image?', 'images::img_bytes')}}         FROM images WHERE title = 'the car wash ( officially untitled )'     \"\"\",     db=db,     ingredients={VQA},     default_model=model ) In\u00a0[33]: Copied! <pre>smoothie.df.values[0][0]\n</pre> smoothie.df.values[0][0] Out[33]: <pre>'A large, curved, waterfall-like fountain is located in a park. The fountain is surrounded by a concrete walkway, and it is surrounded by trees.'</pre> In\u00a0[20]: Copied! <pre>b = db.execute_query(\"SELECT img_bytes FROM images WHERE title = 'animals in pools'\").values[0][0]\nImage.open(BytesIO(b))\n</pre> b = db.execute_query(\"SELECT img_bytes FROM images WHERE title = 'animals in pools'\").values[0][0] Image.open(BytesIO(b)) Out[20]: In\u00a0[22]: Copied! <pre># How many animals are in the fountain designed by Georgia Gerber?\nsmoothie = blend(\n    query=\"\"\"\n    SELECT w.title, w.\"designer ( s )\", {{VQA('How many animals are in this fountain?', 'images::img_bytes')}}\n        FROM images JOIN w ON w.title = images.title\n        WHERE \"designer ( s )\" = 'georgia gerber'\n    \"\"\",\n    db=db,\n    ingredients={VQA},\n    default_model=model\n)\n</pre> # How many animals are in the fountain designed by Georgia Gerber? smoothie = blend(     query=\"\"\"     SELECT w.title, w.\"designer ( s )\", {{VQA('How many animals are in this fountain?', 'images::img_bytes')}}         FROM images JOIN w ON w.title = images.title         WHERE \"designer ( s )\" = 'georgia gerber'     \"\"\",     db=db,     ingredients={VQA},     default_model=model ) In\u00a0[23]: Copied! <pre>smoothie.df\n</pre> smoothie.df Out[23]: title designer ( s ) How many animals are in this fountain? 0 animals in pools georgia gerber There are three animals in the fountain."},{"location":"reference/examples/vqa-ingredient/#custom-vqa-ingredient-with-llava","title":"Custom VQA Ingredient with LLaVA\u00b6","text":"<p>NOTE: This notebook is using an old version of blendsql. The same ideas apply, but syntax might differ in the latest version. Reach out in our Discord, or email me at parkervg5@gmail.com if you want help!</p> <p>Below, we use BlendSQL on a multi-table database containing data from https://en.wikipedia.org/wiki/Fountains_in_Portland,_Oregon.</p> <ul> <li><code>w</code>: Structured data</li> <li><code>documents</code>: Unstructured article content</li> <li><code>images</code>: Images stored as bytes from the article</li> </ul> <p>We demonstrate how BlendSQL can be used to call a tiny VQA (visual question-answering) model (https://huggingface.co/bczhou/tiny-llava-v1-hf) and do reasoning over various forms of data.</p> <p>This is a simple example of the approach taken in EHRXQA: A Multi-Modal Question Answering Dataset for Electronic Health Records with Chest X-ray Images</p>"},{"location":"reference/examples/vqa-ingredient/#simple-image-description","title":"Simple Image Description\u00b6","text":""},{"location":"reference/examples/vqa-ingredient/#multi-hop-multi-modal-reasoning","title":"Multi-hop, Multi-modal Reasoning\u00b6","text":""},{"location":"reference/ingredients/creating-custom-ingredients/","title":"Creating Custom BlendSQL Ingredients","text":"<p>All the built-in LLM ingredients inherit from the base classes <code>QAIngredient</code>, <code>MapIngredient</code>, <code>JoinIngredient</code>, and <code>AliasIngredient</code>.</p> <p>These are intended to be helpful abstractions, so that the user can easily implement their own functions to run within a BlendSQL script.</p> <p>The processing logic for a custom ingredient should go in a <code>run()</code> class function, and accept <code>**kwargs</code> in their signature.</p>"},{"location":"reference/ingredients/creating-custom-ingredients/#aliasingredient","title":"AliasIngredient","text":"<p>               Bases: <code>Ingredient</code></p> <p>This ingredient performs no other function than to act as a stand-in for complex chainings of other ingredients. This allows us (or our lms) to write less verbose BlendSQL queries, while maximizing the information we embed.</p> <p>The <code>run()</code> function should return a tuple containing both the query text that should get subbed in, and any ingredient classes which are dependencies for executing the aliased query.</p> <p>Examples:</p> <pre><code>from textwrap import dedent\nfrom typing import Tuple, Collection\n\nfrom blendsql.ingredients import AliasIngredient, LLMQA\n\nclass FetchDefinition(AliasIngredient):\n    def run(self, term: str, *args, **kwargs) -&gt; Tuple[str, Collection[Ingredient]]:\n        new_query = dedent(\n        f\"\"\"\n        {{{{\n            LLMQA(\n                \"What does {term} mean?\"\n            )\n        }}}}\n        \"\"\")\n        ingredient_dependencies = {LLMQA}\n        return (new_query, ingredient_dependencies)\n\n# Now, we can use the ingredient like below\nblendsql_query = \"\"\"\nSELECT {{FetchDefinition('delve')}} AS \"Definition\"\n\"\"\"\n</code></pre> Source code in <code>blendsql/ingredients/ingredient.py</code> <pre><code>@dataclass\nclass AliasIngredient(Ingredient):\n    '''This ingredient performs no other function than to act as a stand-in for\n    complex chainings of other ingredients. This allows us (or our lms) to write less verbose\n    BlendSQL queries, while maximizing the information we embed.\n\n    The `run()` function should return a tuple containing both the query text that should get subbed in,\n    and any ingredient classes which are dependencies for executing the aliased query.\n\n    Examples:\n        ```python\n        from textwrap import dedent\n        from typing import Tuple, Collection\n\n        from blendsql.ingredients import AliasIngredient, LLMQA\n\n        class FetchDefinition(AliasIngredient):\n            def run(self, term: str, *args, **kwargs) -&gt; Tuple[str, Collection[Ingredient]]:\n                new_query = dedent(\n                f\"\"\"\n                {{{{\n                    LLMQA(\n                        \"What does {term} mean?\"\n                    )\n                }}}}\n                \"\"\")\n                ingredient_dependencies = {LLMQA}\n                return (new_query, ingredient_dependencies)\n\n        # Now, we can use the ingredient like below\n        blendsql_query = \"\"\"\n        SELECT {{FetchDefinition('delve')}} AS \"Definition\"\n        \"\"\"\n        ```\n    '''\n\n    ingredient_type: str = IngredientType.ALIAS.value\n    allowed_output_types: tuple[Type] = (tuple[str, Collection[Ingredient]],)\n\n    def __call__(self, *args, **kwargs):\n        return self._run(*args, **kwargs)\n</code></pre>"},{"location":"reference/ingredients/creating-custom-ingredients/#qaingredient","title":"QAIngredient","text":"<p>               Bases: <code>Ingredient</code></p> <p>Given a table subset in the form of a pd.DataFrame 'context', returns a scalar or array of scalars (in the form of a tuple).</p> <p>Useful for end-to-end question answering tasks.</p> Source code in <code>blendsql/ingredients/ingredient.py</code> <pre><code>@dataclass\nclass QAIngredient(Ingredient):\n    \"\"\"\n    Given a table subset in the form of a pd.DataFrame 'context',\n    returns a scalar or array of scalars (in the form of a tuple).\n\n    Useful for end-to-end question answering tasks.\n    \"\"\"\n\n    ingredient_type: str = IngredientType.QA.value\n    allowed_output_types: tuple[Type] = (str | int | float | tuple | bool,)\n\n    def __call__(\n        self,\n        question: str | None = None,\n        *context: str | pl.DataFrame,\n        options: list | str | None = None,\n        **kwargs,\n    ) -&gt; tuple[str | int | float | tuple | exp.Expression | None]:\n        in_deterministic_mode = bool(\n            int(os.getenv(DETERMINISTIC_KEY, DEFAULT_DETERMINISTIC))\n        )\n        # Unpack kwargs\n        # Extract single `context` from kwargs if provided\n        if \"context\" in kwargs:\n            context_kwarg = kwargs.pop(\"context\")\n            # Combine positional and keyword context\n            if isinstance(context_kwarg, (list, tuple)):\n                context = context + tuple(context_kwarg)\n            else:\n                context = context + (context_kwarg,)\n        aliases_to_tablenames: dict[str, str] = kwargs[\"aliases_to_tablenames\"]\n\n        subtables: list[pl.DataFrame] = []\n        for _context in context:\n            if isinstance(_context, ColumnRef):\n                tablename, colname = utils.get_tablename_colname(_context)\n                tablename = aliases_to_tablenames.get(tablename, tablename)\n                # Optionally materialize a CTE\n                if tablename in self.db.lazy_tables:\n                    materialized_smoothie = self.db.lazy_tables.pop(tablename).collect()\n                    self.num_values_passed += (\n                        materialized_smoothie.meta.num_values_passed\n                    )\n                    subtable = materialized_smoothie.pl.select([colname])\n                    if isinstance(subtable, pl.LazyFrame):\n                        subtable = subtable.collect()\n                else:\n                    subtable: pl.DataFrame = self.db.execute_to_df(\n                        f'SELECT \"{colname}\" FROM \"{tablename}\"', lazy=False\n                    )\n            elif isinstance(_context, pl.DataFrame):\n                subtable: pl.DataFrame = _context\n            else:\n                subtable = pl.DataFrame({\"_col\": _context})\n            if subtable.is_empty():\n                raise LMFunctionException(\"Empty subtable passed to QAIngredient!\")\n            self.num_values_passed += len(subtable)\n            subtables.append(subtable)\n\n        if options is not None:\n            options = self.unpack_options(\n                options=options,\n                aliases_to_tablenames=aliases_to_tablenames,\n                deterministic=in_deterministic_mode,\n            )\n\n        if question is not None and \"{}\" in question:\n            if len(subtables) == 0:\n                raise LMFunctionException(\n                    f\"Passed question with string template '{question}', but no context was passed to fill!\"\n                )\n            unpacked_values = []\n            for subtable in subtables:\n                curr_values = (\n                    subtable.to_series().to_list()\n                    if subtable.width == 1\n                    else list(subtable.to_pandas().values.flat)\n                )\n                if len(curr_values) &gt; 1:\n                    logger.debug(\n                        Color.error(\n                            f\"More than 1 value found in {question}: {curr_values[:10]}\\nThis could be a sign of a malformed query.\"\n                        )\n                    )\n                unpacked_values.append(curr_values[0])\n            question = question.format(*unpacked_values)\n            logger.debug(Color.quiet_update(f\"Unpacked question to '{question}'\"))\n            # This will now override whatever context we passed\n            subtables = []\n\n        response: [str | int | float | tuple] = self._run(\n            question=question,\n            context=subtables if subtables else None,\n            options=options,\n            **self.__dict__ | kwargs,\n        )\n        if isinstance(response, tuple):\n            response = format_tuple(\n                response, kwargs.get(\"wrap_tuple_in_parentheses\", True)\n            )\n        return response\n\n    @abstractmethod\n    def run(self, *args, **kwargs) -&gt; str | int | float | tuple:\n        ...\n</code></pre>"},{"location":"reference/ingredients/creating-custom-ingredients/#mapingredient","title":"MapIngredient","text":"<p>               Bases: <code>Ingredient</code></p> <p>For a given table/column pair, maps an external function to each of the given values, creating a new column.</p> <p>Examples:</p> <pre><code>from typing import List\nfrom blendsql.ingredients import MapIngredient\nimport requests\n\n\nclass GetQRCode(MapIngredient):\n    \"\"\"Calls API to generate QR code for a given URL.\n    Saves bytes to file in qr_codes/ and returns list of paths.\n    https://goqr.me/api/doc/create-qr-code/\"\"\"\n\n\n    def run(self, values: List[str], **kwargs) -&gt; List[str]:\n        imgs_as_bytes = []\n        for value in values:\n            qr_code_bytes = requests.get(\n                \"https://api.qrserver.com/v1/create-qr-code/?data=https://{}/&amp;size=100x100\".format(value)\n            ).content\n            imgs_as_bytes.append(qr_code_bytes)\n        return imgs_as_bytes\n\n\n    if __name__ == \"__main__\":\n        from blendsql import BlendSQL\n        from blendsql.db import SQLite\n        from blendsql.utils import fetch_from_hub\n\n        bsql = BlendSQL(fetch_from_hub('urls.db'), ingredients={GetQRCode})\n\n        smoothie = bsql.execute(\"SELECT genre, url, {{GetQRCode('QR Code as Bytes:', 'w::url')}} FROM w WHERE genre = 'social'\")\n\n        smoothie.df\n        # | genre  | url           | QR Code as Bytes:      |\n        # |--------|---------------|-----------------------|\n        # | social | facebook.com  | b'...'                |\n</code></pre> Source code in <code>blendsql/ingredients/ingredient.py</code> <pre><code>@dataclass\nclass MapIngredient(Ingredient):\n    '''For a given table/column pair, maps an external function\n    to each of the given values, creating a new column.\n\n    Examples:\n        ```python\n        from typing import List\n        from blendsql.ingredients import MapIngredient\n        import requests\n\n\n        class GetQRCode(MapIngredient):\n            \"\"\"Calls API to generate QR code for a given URL.\n            Saves bytes to file in qr_codes/ and returns list of paths.\n            https://goqr.me/api/doc/create-qr-code/\"\"\"\n\n\n            def run(self, values: List[str], **kwargs) -&gt; List[str]:\n                imgs_as_bytes = []\n                for value in values:\n                    qr_code_bytes = requests.get(\n                        \"https://api.qrserver.com/v1/create-qr-code/?data=https://{}/&amp;size=100x100\".format(value)\n                    ).content\n                    imgs_as_bytes.append(qr_code_bytes)\n                return imgs_as_bytes\n\n\n            if __name__ == \"__main__\":\n                from blendsql import BlendSQL\n                from blendsql.db import SQLite\n                from blendsql.utils import fetch_from_hub\n\n                bsql = BlendSQL(fetch_from_hub('urls.db'), ingredients={GetQRCode})\n\n                smoothie = bsql.execute(\"SELECT genre, url, {{GetQRCode('QR Code as Bytes:', 'w::url')}} FROM w WHERE genre = 'social'\")\n\n                smoothie.df\n                # | genre  | url           | QR Code as Bytes:      |\n                # |--------|---------------|-----------------------|\n                # | social | facebook.com  | b'...'                |\n        ```\n    '''\n\n    ingredient_type: str = IngredientType.MAP.value\n    allowed_output_types: tuple[Type] = (Iterable[Any],)\n\n    def unpack_default_kwargs(self, **kwargs):\n        return unpack_default_kwargs(**kwargs)\n\n    def __call__(\n        self,\n        question: str | None = None,\n        values: ColumnRef | None = None,\n        *additional_args: ColumnRef,\n        context: str | pd.DataFrame | None = None,\n        options: ColumnRef | list | None = None,\n        **kwargs,\n    ) -&gt; tuple[str, str, str, pl.LazyFrame]:\n        \"\"\"Returns tuple with format (arg, tablename, colname, new_table)\"\"\"\n        in_deterministic_mode = bool(\n            int(os.getenv(DETERMINISTIC_KEY, DEFAULT_DETERMINISTIC))\n        )\n        # Extract single `additional_args` from kwargs if provided\n        if \"additional_args\" in kwargs:\n            additional_args_kwarg = kwargs.pop(\"additional_args\")\n            # Combine positional and keyword context\n            if isinstance(additional_args_kwarg, (list, tuple)):\n                additional_args = additional_args + tuple(additional_args_kwarg)\n            else:\n                additional_args = additional_args + (additional_args_kwarg,)\n\n        additional_args_passed = bool(additional_args)\n        aliases_to_tablenames: dict[str, str] = kwargs[\"aliases_to_tablenames\"]\n        get_temp_subquery_table: Callable = kwargs[\"get_temp_subquery_table\"]\n        get_temp_session_table: Callable = kwargs[\"get_temp_session_table\"]\n        prev_subquery_map_columns: set[str] = kwargs[\"prev_subquery_map_columns\"]\n        cascade_filter: LazyTable | None = kwargs[\"cascade_filter\"]\n\n        if isinstance(values, StringConcatenation):\n            # original_tablenames could be aliases\n            _original_tablenames, _ = zip(\n                *[utils.get_tablename_colname(c) for c in values]\n            )\n            _original_tablenames = set(_original_tablenames)\n            if len(_original_tablenames) &gt; 1:\n                raise LMFunctionException(\n                    \"Can only concatenate two columns from the same table for now!\"\n                )\n\n            original_tablename = _original_tablenames.pop()\n            tablename = aliases_to_tablenames.get(\n                original_tablename, original_tablename\n            )\n            colname = \"__concat__\"\n            value_source_tablename, _ = self.maybe_get_temp_table(\n                temp_table_func=get_temp_subquery_table, tablename=tablename\n            )\n            concat_expr = re.sub(\n                rf\"{re.escape(original_tablename)}\\.\", \"\", values.raw_expr\n            )\n\n            logger.debug(\n                Color.update(\"Prepping string concatenations for Map ingredient...\")\n            )\n            # Add a '__concat__' column to our existing temp subquery table\n            if value_source_tablename in self.db.lazy_tables:\n                materialized_smoothie = self.db.lazy_tables.pop(\n                    value_source_tablename\n                ).collect()\n                self.num_values_passed += materialized_smoothie.meta.num_values_passed\n\n            _query = f\"\"\"SELECT *, {concat_expr} AS __concat__ FROM \"{double_quote_escape(value_source_tablename)}\" \"\"\"\n            logger.debug(\n                Color.quiet_update(\"Executing \")\n                + Color.quiet_sql(_query, ignore_prefix=True)\n                + Color.quiet_update(\n                    f\" and setting to {value_source_tablename}...\", ignore_prefix=True\n                )\n            )\n            table_with_concat_column = self.db.execute_to_df(_query)\n            self.db.to_temp_table(\n                table_with_concat_column,\n                value_source_tablename,\n            )\n\n            # Also add a placeholder column to the main table\n            # TODO: we don't really need to concat over ALL columns, since we only need the subset\n            #   we processed above. But, in order for the final map aggregation to work,\n            #   we join on the '__concat__' column.\n            (\n                temp_session_tablename,\n                temp_session_table_exists,\n            ) = self.maybe_get_temp_table(\n                temp_table_func=get_temp_session_table, tablename=tablename\n            )\n            original_table = self.db.execute_to_df(\n                f\"\"\"\n               SELECT *, {concat_expr} AS __concat__ FROM \"{double_quote_escape(tablename)}\"\n               \"\"\"\n            )\n            self.db.to_temp_table(original_table, temp_session_tablename)\n\n        else:\n            original_table = None\n            # TODO: make sure we support all types of ValueArray references here\n            tablename_or_aliasname, colname = utils.get_tablename_colname(values)\n            tablename = aliases_to_tablenames.get(\n                tablename_or_aliasname, tablename_or_aliasname\n            )\n\n        # Check for previously created temporary tables\n        value_source_tablename, _ = self.maybe_get_temp_table(\n            temp_table_func=get_temp_subquery_table, tablename=tablename\n        )\n        (\n            temp_session_tablename,\n            temp_session_table_exists,\n        ) = self.maybe_get_temp_table(\n            temp_table_func=get_temp_session_table, tablename=tablename\n        )\n\n        cascade_filter_colnames = set()\n        if cascade_filter is not None:\n            cascade_filter: pl.LazyFrame | None = cascade_filter.collect()\n            if cascade_filter is not None:\n                cascade_filter_colnames = set(cascade_filter.collect_schema().names())\n\n        # Construct a `SELECT DISTINCT` function to get all unique combinations of values we need to apply the `Map` to\n        # In the most basic case, this is the single column name that was passed\n        # But, we also need to consider distinct pairs of values if `f(column1, column2)` was passed\n        resolved_additional_args: list[AdditionalMapArg] = []\n        if additional_args_passed:\n            for additional_arg in additional_args:\n                if isinstance(additional_arg, ColumnRef):\n                    (\n                        additional_arg_tablename_or_alias,\n                        additional_arg_columnname,\n                    ) = utils.get_tablename_colname(additional_arg)\n                    resolved_additional_args.append(\n                        AdditionalMapArg(\n                            columnname=additional_arg_columnname,\n                            tablename=aliases_to_tablenames.get(\n                                additional_arg_tablename_or_alias,\n                                additional_arg_tablename_or_alias,\n                            ),\n                        )\n                    )\n                else:\n                    raise ValueError(\n                        f\"`Map` ingredients can only receive `ColumnRef` objects (e.g. `{{tablename}}.{{columnname}}`) as additional args\\nDid you try to pass a subquery instead?\"\n                    )\n            select_distinct_arg = \", \".join(\n                f'\"{double_quote_escape(c)}\"'\n                for c in set(\n                    set([colname])\n                    | set([i.columnname for i in resolved_additional_args])\n                    | cascade_filter_colnames\n                )\n            )\n            select_distinct_fn = lambda q: self.db.execute_to_df(q)\n        else:\n            if cascade_filter_colnames:\n                select_distinct_arg = \", \".join(\n                    f'\"{double_quote_escape(c)}\"'\n                    for c in set(set([colname]) | cascade_filter_colnames)\n                )\n                select_distinct_fn = lambda q: self.db.execute_to_df(q)\n            else:\n                # Simplest base case - just a single column's values were passed\n                select_distinct_arg = f'\"{double_quote_escape(colname)}\"'\n                select_distinct_fn = lambda q: self.db.execute_to_list(q)\n\n        # i.e, if we didn't create a string concatenation table\n        # Optionally materialize a CTE\n        if original_table is None:\n            if tablename in self.db.lazy_tables:\n                materialized_smoothie = self.db.lazy_tables.pop(tablename).collect()\n                self.num_values_passed += materialized_smoothie.meta.num_values_passed\n                original_table = materialized_smoothie.pl.lazy()\n            else:\n                original_table = self.db.execute_to_df(\n                    f\"\"\"SELECT {select_distinct_arg} FROM \"{tablename}\" ORDER BY rowid\"\"\"\n                )\n        # Need to be sure the new column doesn't already exist here\n        new_arg_column = question or uuid.uuid4().hex[:4]\n        while (\n            new_arg_column in set(self.db.iter_columns(tablename))\n            # new_arg_column in set(self.db.iter_columns(value_source_tablename))\n            or new_arg_column in prev_subquery_map_columns\n        ):\n            new_arg_column = \"_\" + new_arg_column\n\n        suffix = \"\"\n        if in_deterministic_mode:\n            suffix = \" ORDER BY rowid\"\n        # Get a list of values to map\n        # First, check if we've already dumped some `MapIngredient` output to the main session table\n        if temp_session_table_exists:\n            temp_session_table = self.db.execute_to_df(\n                f'SELECT * FROM \"{double_quote_escape(temp_session_tablename)}\" LIMIT 1'\n            )\n            # We don't need to run this function on everything,\n            #   if a previous subquery already got to certain values\n            if new_arg_column in temp_session_table.collect_schema().names():\n                distinct_values = select_distinct_fn(\n                    f'SELECT DISTINCT {select_distinct_arg} FROM \"{temp_session_tablename}\" WHERE \"{new_arg_column}\" IS NULL'\n                    + suffix\n                )\n            # Base case: this is the first time we've used this particular ingredient\n            # BUT, temp_session_tablename still exists\n            else:\n                distinct_values = select_distinct_fn(\n                    f'SELECT DISTINCT {select_distinct_arg} FROM \"{temp_session_tablename}\"'\n                    + suffix\n                )\n        else:\n            distinct_values = select_distinct_fn(\n                f'SELECT DISTINCT {select_distinct_arg} FROM \"{value_source_tablename}\"'\n                + suffix\n            )\n\n        if cascade_filter is not None:\n            # cascade_filters is a pl.LazyFrame containing some additional filters to apply to our distinct values\n            # For example:\n            # cascade_filters.collect() ==\n            # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            # \u2502 Name              \u2506 Known_For                       \u2502\n            # \u2502 ---               \u2506 ---                             \u2502\n            # \u2502 str               \u2506 str                             \u2502\n            # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n            # \u2502 Sabrina Carpenter \u2506 Nonsense, Emails I Cant Send, \u2026 \u2502\n            # \u2502 Charli XCX        \u2506 Crash, How Im Feeling Now, Boo\u2026 \u2502\n            # \u2502 Elvis Presley     \u2506 14 Grammys, King of Rock n Rol\u2026 \u2502\n            # \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            # ...means we only take values where `Name`, `Known_For` columns are present in the above.\n            logger.debug(\n                Color.optimization(\n                    f\"[ \ud83c\udf0a ] Applying cascade filter from previous LM function...\"\n                )\n            )\n            distinct_values = distinct_values.join(\n                cascade_filter, on=cascade_filter_colnames, how=\"semi\"\n            )\n            # Remove columns, if they were only needed for the cascade_filter\n            distinct_values = distinct_values.select(\n                set([colname]) | set([i.columnname for i in resolved_additional_args])\n            )\n\n        if additional_args_passed or cascade_filter is not None:\n            # We have a dataframe object we need to disentangle\n            df = distinct_values.collect()\n            if cascade_filter is not None:\n                unpacked_values = (\n                    df[colname].unique(maintain_order=in_deterministic_mode).to_list()\n                )\n            else:\n                unpacked_values = df[colname].to_list()\n            for additional_arg in resolved_additional_args:\n                additional_arg.values = df.get_column(\n                    additional_arg.columnname\n                ).to_list()\n        else:\n            # Base case: a simple list of unique values from a column\n            unpacked_values: list = distinct_values\n\n        # No need to run ingredient if we have no values to map onto\n        if not unpacked_values:\n            original_table = original_table.with_columns(\n                pl.lit(None).alias(new_arg_column)\n            )\n            return (new_arg_column, tablename, colname, original_table)\n\n        unpacked_options = None\n        if options is not None:\n            unpacked_options = self.unpack_options(\n                options=options,\n                aliases_to_tablenames=aliases_to_tablenames,\n                deterministic=in_deterministic_mode,\n            )\n\n        global_subtable_context = None\n        if context is not None:\n            if isinstance(context, ColumnRef):\n                tablename, colname = utils.get_tablename_colname(additional_arg)\n                tablename = aliases_to_tablenames.get(tablename, tablename)\n                # Optionally materialize a CTE\n                if tablename in self.db.lazy_tables:\n                    materialized_smoothie = self.db.lazy_tables.pop(tablename).collect()\n                    self.num_values_passed += (\n                        materialized_smoothie.meta.num_values_passed\n                    )\n                    global_subtable_context = materialized_smoothie.pl.select([colname])\n                    if isinstance(global_subtable_context, pl.LazyFrame):\n                        global_subtable_context = global_subtable_context.collect()\n                else:\n                    global_subtable_context: pl.DataFrame = self.db.execute_to_df(\n                        f'SELECT \"{colname}\" FROM \"{tablename}\"', lazy=False\n                    )\n            elif isinstance(context, pl.DataFrame):\n                global_subtable_context: pl.DataFrame = context\n            else:\n                global_subtable_context = pl.DataFrame({\"_col\": context})\n            self.num_values_passed += len(global_subtable_context)\n\n        # Unpack questions, to later pass to a `context_searcher` or `options_searcher`\n        unpacked_questions = None\n        if question is not None and \"{}\" in question:\n            unpacked_questions = [question.format(value) for value in unpacked_values]\n\n            logger.debug(\n                Color.quiet_update(f\"Unpacked question to '{unpacked_questions[:10]}'\")\n            )\n\n        mapped_values = self._run(\n            question=question,\n            unpacked_questions=unpacked_questions,\n            values=unpacked_values,\n            additional_args=resolved_additional_args,\n            global_subtable_context=global_subtable_context,\n            options=unpacked_options,\n            tablename=tablename,\n            colname=colname,\n            **self.__dict__ | kwargs,\n        )\n        df_as_dict = {\n            colname: list(unpacked_values),\n            new_arg_column: list(mapped_values),\n        }\n        mapped_subtable = pl.LazyFrame(\n            df_as_dict, strict=False\n        )  # strict=False allows mixed types\n\n        # Add new_table to original table\n        if additional_args_passed:\n            _mapped_subtable = pl.concat(\n                [distinct_values, mapped_subtable.select(new_arg_column)],\n                how=\"horizontal\",\n            )\n            new_table = original_table.join(\n                _mapped_subtable,\n                how=\"left\",\n                # We DON'T need to join on cascade_filter_colnames, since these weren't neccesarily operated on in the map call.\n                on=set([colname])\n                | set([i.columnname for i in resolved_additional_args]),\n            )\n        else:\n            new_table = original_table.join(mapped_subtable, how=\"left\", on=colname)\n        # Now, new table has original columns + column with the name of the question we answered\n        return (new_arg_column, tablename, colname, new_table)\n\n    @abstractmethod\n    def run(self, *args, **kwargs) -&gt; Iterable[Any]:\n        ...\n</code></pre>"},{"location":"reference/ingredients/creating-custom-ingredients/#joiningredient","title":"JoinIngredient","text":"<p>               Bases: <code>Ingredient</code></p> <p>Executes an <code>INNER JOIN</code> using dict mapping. 'Join on color of food'</p> <p>Examples:</p> <pre><code>from blendsql.ingredients import JoinIngredient\n\nclass do_join(JoinIngredient):\n    \"\"\"A very silly, overcomplicated way to do a traditional SQL join.\n    But useful for testing.\n    \"\"\"\n\n    def run(self, left_values: List[str], right_values: List[str], **kwargs) -&gt; dict:\n        return {left_value: left_value for left_value in left_values}\n\nblendsql_query = \"\"\"\nSELECT Account, Quantity FROM returns r\nJOIN account_history ah ON {{\n    do_join(\n        left_on=ah.Symbol,\n        right_on=r.Symbol\n    )\n}}\n\"\"\"\n</code></pre> Source code in <code>blendsql/ingredients/ingredient.py</code> <pre><code>@dataclass\nclass JoinIngredient(Ingredient):\n    '''Executes an `INNER JOIN` using dict mapping.\n    'Join on color of food'\n    {\"tomato\": \"red\", \"broccoli\": \"green\", \"lemon\": \"yellow\"}\n\n    Examples:\n        ```python\n        from blendsql.ingredients import JoinIngredient\n\n        class do_join(JoinIngredient):\n            \"\"\"A very silly, overcomplicated way to do a traditional SQL join.\n            But useful for testing.\n            \"\"\"\n\n            def run(self, left_values: List[str], right_values: List[str], **kwargs) -&gt; dict:\n                return {left_value: left_value for left_value in left_values}\n\n        blendsql_query = \"\"\"\n        SELECT Account, Quantity FROM returns r\n        JOIN account_history ah ON {{\n            do_join(\n                left_on=ah.Symbol,\n                right_on=r.Symbol\n            )\n        }}\n        \"\"\"\n        ```\n    '''\n\n    use_skrub_joiner: bool = field(default=True)\n\n    ingredient_type: str = IngredientType.JOIN.value\n    allowed_output_types: tuple[Type] = (dict,)\n\n    def __call__(\n        self,\n        left_on: str | None = None,\n        right_on: str | None = None,\n        join_criteria: str | None = None,\n        *args,\n        **kwargs,\n    ) -&gt; tuple:\n        # Unpack kwargs\n        aliases_to_tablenames: dict[str, str] = kwargs[\"aliases_to_tablenames\"]\n        get_temp_subquery_table: Callable = kwargs[\"get_temp_subquery_table\"]\n        get_temp_session_table: Callable = kwargs[\"get_temp_session_table\"]\n        # Depending on the size of the underlying data, it may be optimal to swap\n        #   the order of 'left_on' and 'right_on' columns during processing\n        swapped = False\n        values = []\n        original_lr_identifiers = []\n        modified_lr_identifiers = []\n        mapping: dict[str, str] = {}\n        for on_arg in [left_on, right_on]:\n            # Since LLMJoin is unique, in that we need to inject the referenced tablenames back to the query,\n            #   make sure we keep the `referenced_tablename` variable.\n            # So the below works:\n            #     SELECT f.name, colors.name FROM fruits f\n            #     JOIN colors c ON {{LLMJoin(f.name, c.name, join_criteria='Align the fruit to its color')}}\n            referenced_tablename, colname = utils.get_tablename_colname(on_arg)\n            tablename = aliases_to_tablenames.get(\n                referenced_tablename, referenced_tablename\n            )\n            original_lr_identifiers.append((referenced_tablename, colname))\n            tablename, _ = self.maybe_get_temp_table(\n                temp_table_func=get_temp_subquery_table,\n                tablename=tablename,\n            )\n            values.append(\n                self.db.execute_to_list(\n                    f'SELECT DISTINCT \"{colname}\" FROM \"{tablename}\"', to_type=str\n                )\n            )\n            modified_lr_identifiers.append((tablename, colname))\n\n        sorted_values = values\n        swapped = False\n        if join_criteria is None:\n            # Only do order optimization if we haven't passed a custom `join_criteria`\n            sorted_values = sorted(values, key=len)\n            # check swapping only once, at the beginning\n            if sorted_values != values:\n                swapped = True\n            # First, check which values we actually need to call Model on\n            # We don't want to join when there's already an intuitive alignment\n            # First, make sure outer loop is shorter of the two lists\n            outer, inner = sorted_values\n            _outer = []\n            inner = set(inner)\n            mapping = {}\n            for l in outer:\n                if l in inner:\n                    # Define this mapping, and remove from Model inference call\n                    mapping[l] = l\n                    inner.remove(l)\n                else:\n                    _outer.append(l)\n                if len(inner) == 0:\n                    break\n            # Remained _outer and inner lists preserved the sorting order in length:\n            # len(_outer) = len(outer) - #matched &lt;= len(inner original) - matched = len(inner)\n            if self.use_skrub_joiner and all(len(x) &gt; 1 for x in [inner, _outer]):\n                try:\n                    from skrub import Joiner\n                except ImportError:\n                    print(\n                        \"`use_skrub_joiner` is `True`, but skrub is not installed. Install it with `pip install skrub` \"\n                        \"to use the Joiner functionality.\"\n                    )\n                    self.use_skrub_joiner = False\n                else:\n                    # Create the main_table DataFrame\n                    main_table = pd.DataFrame(_outer, columns=[\"out\"])\n                    # Create the aux_table DataFrame\n                    aux_table = pd.DataFrame(inner, columns=[\"in\"])\n                    joiner = Joiner(\n                        aux_table,\n                        main_key=\"out\",\n                        aux_key=\"in\",\n                        max_dist=0.9,\n                        add_match_info=False,\n                    )\n                    res = joiner.fit_transform(main_table)\n                    # Below is essentially set.difference on aux_table and those paired in res\n                    inner = aux_table.loc[\n                        ~aux_table[\"in\"].isin(res[\"in\"]), \"in\"\n                    ].tolist()\n                    # length(new inner) = length(inner) - #matched by fuzzy join\n                    _outer = res[\"out\"][res[\"in\"].isnull()].to_list()\n                    # length(new _outer) = length(_outer) - #matched by fuzzy join\n                    _skrub_mapping = (\n                        res.dropna(subset=[\"in\"]).set_index(\"out\")[\"in\"].to_dict()\n                    )\n                    logger.debug(\n                        Color.warning(\n                            \"Made the following alignment with `skrub.Joiner`:\"\n                        )\n                    )\n                    logger.debug(Color.warning(json.dumps(_skrub_mapping, indent=4)))\n                    mapping = mapping | _skrub_mapping\n            # order by length is still preserved regardless of using fuzzy join, so after initial matching and possible fuzzy join matching\n            # This is because the lengths of each list will decrease at the same rate, so whichever list was larger at the beginning,\n            # will be larger here at the end.\n            # len(_outer) &lt;= len(inner)\n            sorted_values = [_outer, inner]\n\n        # Now, we have our final values to process.\n        left_values, right_values = sorted_values\n        # right_values, left_values = sorted_values\n\n        (left_tablename, left_colname), (\n            right_tablename,\n            right_colname,\n        ) = original_lr_identifiers\n        (_left_tablename, _left_colname), (\n            _right_tablename,\n            _right_colname,\n        ) = modified_lr_identifiers\n\n        if all(len(x) &gt; 0 for x in [left_values, right_values]):\n            # Some alignment still left to do\n            self.num_values_passed += len(left_values) + len(right_values)\n\n            _predicted_mapping: dict[str, str] = self._run(\n                left_values=left_values,\n                right_values=right_values,\n                join_criteria=join_criteria,\n                *args,\n                **self.__dict__ | kwargs,\n            )\n            mapping = mapping | _predicted_mapping\n        # Using mapped left/right values, create intermediary mapping table\n        temp_join_tablename = get_temp_session_table(uuid.uuid4().hex[:4])\n        # Below, we check to see if 'swapped' is True\n        # If so, we need to inverse what is 'left', and what is 'right'\n        joined_values_df = pl.DataFrame(\n            data={\n                \"left\" if not swapped else \"right\": mapping.keys(),\n                \"right\" if not swapped else \"left\": mapping.values(),\n            }\n        )\n        self.db.to_temp_table(df=joined_values_df, tablename=temp_join_tablename)\n\n        if right_tablename in aliases_to_tablenames:\n            right_table_ref = (\n                f'\"{aliases_to_tablenames[right_tablename]}\" AS \"{right_tablename}\"'\n            )\n        else:\n            right_table_ref = f'\"{right_tablename}\"'\n\n        join_clause = (\n            f'JOIN \"{temp_join_tablename}\" ON \"{left_tablename}\".\"{left_colname}\" = \"{temp_join_tablename}\".left\\n'\n            f'JOIN {right_table_ref} ON \"{right_tablename}\".\"{right_colname}\" = \"{temp_join_tablename}\".right'\n        )\n\n        return (left_tablename, right_tablename, join_clause, temp_join_tablename)\n\n    @abstractmethod\n    def run(self, *args, **kwargs) -&gt; dict:\n        ...\n</code></pre>"},{"location":"reference/ingredients/ingredients/","title":"Ingredients","text":"<p>Ingredients are at the core of a BlendSQL script. </p> <p>They are callable functions that perform one the task paradigms defined in ingredient.py.</p> <p>At their core, these are not a new concept. User-defined functions (UDFs), or Application-Defined Functions in SQLite have existed for quite some time. </p> <p>However, ingredients in BlendSQL are intended to be optimized towards LLM-based functions, defining an order of operations for traversing the AST such that the minimal amount of data is passed into your expensive GPT-4/Llama 2/Mistral 7b/etc. prompt.</p> <p>Ingredient calls are denoted by wrapping them in double curly brackets, <code>{{ingredient}}</code>.</p>"},{"location":"reference/models/models/","title":"Models","text":""},{"location":"reference/models/models/#model","title":"<code>Model</code>","text":"<p>Parent class for all BlendSQL Models.</p> Source code in <code>blendsql/models/model_base.py</code> <pre><code>@dataclass\nclass ModelBase:\n    \"\"\"Parent class for all BlendSQL Models.\"\"\"\n\n    model_name_or_path: str = field()\n    caching: bool = field(default=False)\n    cache: Cache | None = field(default=None)\n    _allows_parallel_requests: bool = field(default=False)\n\n    prompt_tokens: int = 0\n    completion_tokens: int = 0\n    cached_tokens: int = 0\n    num_generation_calls: int = 0\n    num_cache_hits: int = 0\n\n    def __post_init__(self):\n        self.cache = Cache(\n            Path(platformdirs.user_cache_dir(\"blendsql\"))\n            / f\"{self.model_name_or_path}.diskcache\"\n        )\n\n    def _create_key(\n        self, *args, funcs: Sequence[Callable] | None = None, **kwargs\n    ) -&gt; str:\n        \"\"\"Generates a hash to use in diskcache Cache.\n        This way, we don't need to send our prompts to the same Model\n        if our context of Model + args + kwargs is the same.\n\n        Returns:\n            md5 hash used as key in diskcache\n        \"\"\"\n        hasher = hashlib.md5()\n        params_str = \"\"\n        if len(kwargs) &gt; 0:\n            params_str += str(sorted([(k, str(v)) for k, v in kwargs.items()]))\n        if len(args) &gt; 0:\n            params_str += str([arg for arg in args])\n        if funcs:\n            params_str += \"\\n\".join([dedent(inspect.getsource(func)) for func in funcs])\n        combined_str = \"{}||{}\".format(\n            f\"{self.model_name_or_path}||{type(self)}\",\n            params_str,\n        ).encode()\n        hasher.update(combined_str)\n        return hasher.hexdigest()\n\n    def check_cache(\n        self, *args, funcs: Sequence[Callable] | None = None, **kwargs\n    ) -&gt; Tuple[Any, str]:\n        response: dict[str, str] = None  # type: ignore\n        key: str = self._create_key(funcs=funcs, *args, **kwargs)\n        if key in self.cache:\n            self.num_cache_hits += 1\n            logger.debug(\n                Color.model_or_data_update(\n                    f\"Using model cache ({self.num_cache_hits})...\"\n                )\n            )\n            response = self.cache.get(key)  # type: ignore\n        return (response, key)\n\n    def reset_stats(self):\n        self.prompt_tokens = 0\n        self.completion_tokens = 0\n        self.cached_tokens = 0\n        self.num_generation_calls = 0\n        self.num_cache_hits = 0\n</code></pre>"},{"location":"reference/models/models/#vllm","title":"<code>VLLM</code>","text":"<p>               Bases: <code>ModelBase</code></p> <p>Class for vLLM endpoints.</p> <p>Parameters:</p> Name Type Description Default <code>model_name_or_path</code> <code>str</code> <p>Name of the model</p> required <code>base_url</code> <code>str</code> <p>Base URL for http requests</p> required <p>Examples:</p> <pre><code>from blendsql.models import VLLM\n\nmodel = VLLM(\"RedHatAI/gemma-3-12b-it-quantized.w4a16\", base_url=\"http://localhost:8000/v1/\")\n</code></pre> Source code in <code>blendsql/models/vllm.py</code> <pre><code>class VLLM(ModelBase):\n    \"\"\"Class for vLLM endpoints.\n\n    Args:\n        model_name_or_path: Name of the model\n        base_url: Base URL for http requests\n\n    Examples:\n        ```python\n        from blendsql.models import VLLM\n\n        model = VLLM(\"RedHatAI/gemma-3-12b-it-quantized.w4a16\", base_url=\"http://localhost:8000/v1/\")\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        model_name_or_path: str,\n        base_url: str,\n        api_key: str = \"N/A\",\n        tokenizer: \"BaseTokenizer\" = None,\n        extra_body: dict | None = None,\n        caching: bool = False,\n        **kwargs,\n    ):\n        from openai import AsyncOpenAI\n\n        self.extra_body = extra_body or dict()\n\n        super().__init__(\n            model_name_or_path=model_name_or_path,\n            caching=caching,\n            _allows_parallel_requests=True,\n            **kwargs,\n        )\n        if tokenizer is None:\n            from huggingface_hub import hf_hub_download\n            import json\n\n            with open(\n                hf_hub_download(\n                    repo_id=model_name_or_path, filename=\"tokenizer_config.json\"\n                ),\n                \"r\",\n            ) as f:\n                config = json.load(f)\n            self.chat_template = config[\"chat_template\"]\n            with open(\n                hf_hub_download(\n                    repo_id=model_name_or_path, filename=\"special_tokens_map.json\"\n                ),\n                \"r\",\n            ) as f:\n                special_tokens_map = json.load(f)\n            self.special_tokens_map = {\n                k: v[\"content\"] if isinstance(v, dict) else v\n                for k, v in special_tokens_map.items()\n            }\n        self.tokenizer = tokenizer\n        self.client = AsyncOpenAI(base_url=base_url, api_key=api_key)\n\n    async def generate(\n        self, item: GenerationItem, cancel_event: asyncio.Event | None = None\n    ):\n        buffer = \"\"\n        extra_body = (\n            DEFAULT_BODY\n            | {\"max_tokens\": int(os.getenv(MAX_TOKENS_KEY, DEFAULT_MAX_TOKENS))}\n            | self.extra_body\n        )\n        if item.grammar:\n            extra_body |= {\n                \"guided_decoding_backend\": \"guidance\",\n                \"guided_grammar\": item.grammar,\n                \"structured_outputs\": {\"grammar\": item.grammar},\n            }\n        messages = [{\"role\": \"user\", \"content\": item.prompt}]\n        if item.assistant_continuation is not None:\n            messages.append(\n                {\"role\": \"assistant\", \"content\": item.assistant_continuation}\n            )\n\n        if self.tokenizer is None:\n            from .tokenization import render_jinja_template\n\n            prompt_to_send = render_jinja_template(\n                messages=messages,\n                chat_template=self.chat_template,\n                continue_final_message=item.assistant_continuation is not None,\n                add_generation_prompt=item.assistant_continuation is None,\n                **self.special_tokens_map,\n            )\n        else:\n            prompt_to_send = self.tokenizer.apply_chat_template(\n                messages,\n                tokenize=False,\n                continue_final_message=item.assistant_continuation is not None,\n                add_generation_prompt=item.assistant_continuation is None,\n            )\n\n        stream = await self.client.completions.create(\n            model=self.model_name_or_path,\n            prompt=prompt_to_send,\n            stream=True,\n            stream_options={\"include_usage\": True},\n            extra_body=extra_body,\n        )\n        self.num_generation_calls += 1\n        add_to_global_history(prompt_to_send)\n\n        try:\n            async for chunk in stream:\n                if cancel_event and cancel_event.is_set():\n                    return GenerationResult(item.identifier, buffer, completed=False)\n\n                if chunk.choices and chunk.choices[0].text:\n                    buffer += chunk.choices[0].text\n\n                if hasattr(chunk, \"usage\") and chunk.usage is not None:\n                    self.prompt_tokens += chunk.usage.prompt_tokens\n                    self.completion_tokens += chunk.usage.completion_tokens\n                    if chunk.usage.prompt_tokens_details is not None:\n                        self.cached_tokens += (\n                            chunk.usage.prompt_tokens_details.cached_tokens\n                        )\n\n        finally:\n            await stream.close()\n\n        return GenerationResult(item.identifier, buffer, completed=True)\n</code></pre>"},{"location":"reference/models/vllm/","title":"vLLM","text":""},{"location":"reference/models/vllm/#vllm","title":"<code>VLLM</code>","text":"<p>To begin, start a vLLM server. Be sure to specify <code>--structured-outputs-config.backend guidance</code> if your vLLM version is <code>&gt;0.12.0</code>. </p> <pre><code>vllm serve RedHatAI/gemma-3-12b-it-quantized.w4a16 --host 0.0.0.0 \\\n--port 8000 \\\n--enable-prefix-caching \\\n--max-model-len 8000 \\\n--structured-outputs-config.backend guidance \\\n--gpu_memory_utilization 0.8 \\\n--enable-prompt-tokens-details\n</code></pre> <p>               Bases: <code>ModelBase</code></p> <p>Class for vLLM endpoints.</p> <p>Parameters:</p> Name Type Description Default <code>model_name_or_path</code> <code>str</code> <p>Name of the model</p> required <code>base_url</code> <code>str</code> <p>Base URL for http requests</p> required <p>Examples:</p> <pre><code>from blendsql.models import VLLM\n\nmodel = VLLM(\"RedHatAI/gemma-3-12b-it-quantized.w4a16\", base_url=\"http://localhost:8000/v1/\")\n</code></pre> Source code in <code>blendsql/models/vllm.py</code> <pre><code>class VLLM(ModelBase):\n    \"\"\"Class for vLLM endpoints.\n\n    Args:\n        model_name_or_path: Name of the model\n        base_url: Base URL for http requests\n\n    Examples:\n        ```python\n        from blendsql.models import VLLM\n\n        model = VLLM(\"RedHatAI/gemma-3-12b-it-quantized.w4a16\", base_url=\"http://localhost:8000/v1/\")\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        model_name_or_path: str,\n        base_url: str,\n        api_key: str = \"N/A\",\n        tokenizer: \"BaseTokenizer\" = None,\n        extra_body: dict | None = None,\n        caching: bool = False,\n        **kwargs,\n    ):\n        from openai import AsyncOpenAI\n\n        self.extra_body = extra_body or dict()\n\n        super().__init__(\n            model_name_or_path=model_name_or_path,\n            caching=caching,\n            _allows_parallel_requests=True,\n            **kwargs,\n        )\n        if tokenizer is None:\n            from huggingface_hub import hf_hub_download\n            import json\n\n            with open(\n                hf_hub_download(\n                    repo_id=model_name_or_path, filename=\"tokenizer_config.json\"\n                ),\n                \"r\",\n            ) as f:\n                config = json.load(f)\n            self.chat_template = config[\"chat_template\"]\n            with open(\n                hf_hub_download(\n                    repo_id=model_name_or_path, filename=\"special_tokens_map.json\"\n                ),\n                \"r\",\n            ) as f:\n                special_tokens_map = json.load(f)\n            self.special_tokens_map = {\n                k: v[\"content\"] if isinstance(v, dict) else v\n                for k, v in special_tokens_map.items()\n            }\n        self.tokenizer = tokenizer\n        self.client = AsyncOpenAI(base_url=base_url, api_key=api_key)\n\n    async def generate(\n        self, item: GenerationItem, cancel_event: asyncio.Event | None = None\n    ):\n        buffer = \"\"\n        extra_body = (\n            DEFAULT_BODY\n            | {\"max_tokens\": int(os.getenv(MAX_TOKENS_KEY, DEFAULT_MAX_TOKENS))}\n            | self.extra_body\n        )\n        if item.grammar:\n            extra_body |= {\n                \"guided_decoding_backend\": \"guidance\",\n                \"guided_grammar\": item.grammar,\n                \"structured_outputs\": {\"grammar\": item.grammar},\n            }\n        messages = [{\"role\": \"user\", \"content\": item.prompt}]\n        if item.assistant_continuation is not None:\n            messages.append(\n                {\"role\": \"assistant\", \"content\": item.assistant_continuation}\n            )\n\n        if self.tokenizer is None:\n            from .tokenization import render_jinja_template\n\n            prompt_to_send = render_jinja_template(\n                messages=messages,\n                chat_template=self.chat_template,\n                continue_final_message=item.assistant_continuation is not None,\n                add_generation_prompt=item.assistant_continuation is None,\n                **self.special_tokens_map,\n            )\n        else:\n            prompt_to_send = self.tokenizer.apply_chat_template(\n                messages,\n                tokenize=False,\n                continue_final_message=item.assistant_continuation is not None,\n                add_generation_prompt=item.assistant_continuation is None,\n            )\n\n        stream = await self.client.completions.create(\n            model=self.model_name_or_path,\n            prompt=prompt_to_send,\n            stream=True,\n            stream_options={\"include_usage\": True},\n            extra_body=extra_body,\n        )\n        self.num_generation_calls += 1\n        add_to_global_history(prompt_to_send)\n\n        try:\n            async for chunk in stream:\n                if cancel_event and cancel_event.is_set():\n                    return GenerationResult(item.identifier, buffer, completed=False)\n\n                if chunk.choices and chunk.choices[0].text:\n                    buffer += chunk.choices[0].text\n\n                if hasattr(chunk, \"usage\") and chunk.usage is not None:\n                    self.prompt_tokens += chunk.usage.prompt_tokens\n                    self.completion_tokens += chunk.usage.completion_tokens\n                    if chunk.usage.prompt_tokens_details is not None:\n                        self.cached_tokens += (\n                            chunk.usage.prompt_tokens_details.cached_tokens\n                        )\n\n        finally:\n            await stream.close()\n\n        return GenerationResult(item.identifier, buffer, completed=True)\n</code></pre>"}]}