{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"SQL \ud83e\udd1d LLMs  <p>Paper  GitHub </p> <pre><code>pip install blendsql\n</code></pre>"},{"location":"#news","title":"\u2728 News","text":"<ul> <li>(5/6/25): New blog post: Language Models, SQL, and Types, Oh My!</li> <li>(5/1/15): Single-page function documentation</li> <li>(3/16/25) Use BlendSQL with 100+ LLM APIs, using LiteLLM!</li> <li>(10/26/24) New tutorial! blendsql-by-example.ipynb</li> <li>(10/18/24) Concurrent async requests in 0.0.29! OpenAI and Anthropic <code>LLMMap</code> calls are speedy now.</li> <li>Customize max concurrent async calls via <code>blendsql.config.set_async_limit(10)</code></li> </ul>"},{"location":"#features","title":"Features","text":"<ul> <li>Supports many DBMS \ud83d\udcbe</li> <li>SQLite, PostgreSQL, DuckDB, Pandas (aka duckdb in a trenchcoat)</li> <li>Supports many models \u2728<ul> <li>Transformers, OpenAI, Anthropic, Ollama</li> </ul> </li> <li>Easily extendable to multi-modal usecases \ud83d\uddbc\ufe0f</li> <li>Write your normal queries - smart parsing optimizes what is passed to external functions \ud83e\udde0<ul> <li>Traverses abstract syntax tree with sqlglot to minimize LLM function calls \ud83c\udf33</li> </ul> </li> <li>Constrained decoding with guidance \ud83d\ude80<ul> <li>When using local models, we only generate syntactically valid outputs according to query syntax + database contents</li> </ul> </li> <li>LLM function caching, built on diskcache \ud83d\udd11</li> </ul> <p>BlendSQL is a superset of SQLite for problem decomposition and hybrid question-answering with LLMs.</p> <p>As a result, we can Blend together...</p> <ul> <li>\ud83e\udd64 ...operations over heterogeneous data sources (e.g. tables, text, images)</li> <li>\ud83e\udd64 ...the structured &amp; interpretable reasoning of SQL with the generalizable reasoning of LLMs</li> </ul> <p>It can be viewed as an inversion of the typical text-to-SQL paradigm, where a user calls a LLM, and the LLM calls a SQL program.</p> <p>Now, the user is given the control to oversee all calls (LLM + SQL) within a unified query language.</p> <p></p> <p>For example, imagine we have the following table titled <code>parks</code>, containing info on national parks in the United States.</p> <p>We can use BlendSQL to build a travel planning LLM chatbot to help us navigate the options below.</p> Name Image Location Area Recreation Visitors (2022) Description Death Valley California, Nevada 3,408,395.63 acres (13,793.3 km2) 1,128,862 Death Valley is the hottest, lowest, and driest place in the United States, with daytime temperatures that have exceeded 130 \u00b0F (54 \u00b0C). Everglades Alaska 7,523,897.45 acres (30,448.1 km2) 9,457 The country's northernmost park protects an expanse of pure wilderness in Alaska's Brooks Range and has no park facilities. New River Gorge West Virgina 7,021 acres (28.4 km2) 1,593,523 The New River Gorge is the deepest river gorge east of the Mississippi River. Katmai Alaska 3,674,529.33 acres (14,870.3 km2) 33,908 This park on the Alaska Peninsula protects the Valley of Ten Thousand Smokes, an ash flow formed by the 1912 eruption of Novarupta. <p>BlendSQL allows us to ask the following questions by injecting \"ingredients\", which are callable functions denoted by double curly brackets (<code>{{</code>, <code>}}</code>).</p> <p>Which parks don't have park facilities? <pre><code>SELECT \"Name\", \"Description\" FROM parks\n  WHERE {{\n      LLMMap(\n          'Does this location have park facilities?',\n          values='parks::Description'\n      )\n  }} = FALSE\n</code></pre></p> Name Description Everglades The country's northernmost park protects an expanse of pure wilderness in Alaska's Brooks Range and has no park facilities. <p>What does the largest park in Alaska look like?</p> <pre><code>SELECT \"Name\",\n{{ImageCaption('parks::Image')}} as \"Image Description\",\n{{\n    LLMMap(\n        question='Size in km2?',\n        values='parks::Area'\n    )\n}} as \"Size in km\" FROM parks\nWHERE \"Location\" = 'Alaska'\nORDER BY \"Size in km\" DESC LIMIT 1\n</code></pre> Name Image Description Size in km Everglades A forest of tall trees with a sunset in the background. 30448.1 <p>Which state is the park in that protects an ash flow?</p> <pre><code>SELECT \"Location\", \"Name\" AS \"Park Protecting Ash Flow\" FROM parks\n    WHERE \"Name\" = {{\n      LLMQA(\n        'Which park protects an ash flow?',\n        context=(SELECT \"Name\", \"Description\" FROM parks),\n        options=\"parks::Name\"\n      )\n  }}\n</code></pre> Location Park Protecting Ash Flow Alaska Katmai <p>How many parks are located in more than 1 state?</p> <pre><code>SELECT COUNT(*) FROM parks\n    WHERE {{LLMMap('How many states?', 'parks::Location')}} &gt; 1\n</code></pre> Count 1 <p>Now, we have an intermediate representation for our LLM to use that is explainable, debuggable, and very effective at hybrid question-answering tasks.</p> <p>For in-depth descriptions of the above queries, check out our documentation.</p>"},{"location":"#citation","title":"Citation","text":"<pre><code>@article{glenn2024blendsql,\n      title={BlendSQL: A Scalable Dialect for Unifying Hybrid Question Answering in Relational Algebra},\n      author={Parker Glenn and Parag Pravin Dakle and Liang Wang and Preethi Raghavan},\n      year={2024},\n      eprint={2402.17882},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n</code></pre>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>Special thanks to those below for inspiring this project. Definitely recommend checking out the linked work below, and citing when applicable!</p> <ul> <li>The authors of Binding Language Models in Symbolic Languages<ul> <li>This paper was the primary inspiration for BlendSQL.</li> </ul> </li> <li>The authors of EHRXQA: A Multi-Modal Question Answering Dataset for Electronic Health Records with Chest X-ray Images<ul> <li>As far as I can tell, the first publication to propose unifying model calls within SQL</li> <li>Served as the inspiration for the vqa-ingredient.ipynb example</li> </ul> </li> <li>The authors of Grammar Prompting for Domain-Specific Language Generation with Large Language Models</li> <li>The maintainers of the Guidance library for powering the constrained decoding capabilities of BlendSQL</li> </ul>"},{"location":"by-example/","title":"Some Cool Things by Example","text":""},{"location":"by-example/#inferring-regular-expression-constraints","title":"Inferring Regular Expression Constraints","text":"<p><pre><code>SELECT \"Name\" FROM parks\nWHERE \"Location\" = 'Alaska'\nORDER BY {{\n    LLMMap(\n        'Size in km2?',\n        Area\n    )\n}} DESC LIMIT 1\n</code></pre> By virtue of the <code>ORDER BY</code> clause, we assume that the output of the <code>{{LLMMap}</code> ingredient should be a numeric. BlendSQL constrains the generation of the language model, then, to the regular expression corresponding to a integer (or floating point) <code>(\\d+(\\.\\d+)?){n}</code>, where <code>n</code> is the number of values in the <code>Area</code> column, and <code>-</code> represents a null value.</p>"},{"location":"by-example/#automatic-options-injection","title":"Automatic <code>options</code> Injection","text":"<p><pre><code>SELECT \"Location\", \"Name\" AS \"Park Protecting Ash Flow\" FROM parks\n    WHERE \"Name\" = {{\n      LLMQA(\n        'Which park protects an ash flow?',\n        (SELECT \"Name\", \"Description\" FROM parks)\n      )\n  }}\n</code></pre> We can omit the <code>options</code> argument, and BlendSQL will automatically infer the <code>options=\"parks::Name\"</code> argument.</p>"},{"location":"by-example/#referencing-cte-passing-in-enumerated-options","title":"Referencing CTE, Passing in Enumerated Options","text":"<p><pre><code>WITH w AS (\n    SELECT *\n    FROM account_history\n    WHERE Symbol IS NOT NULL\n) SELECT Symbol, {{\n    LLMMap(\n        'Sells cell phones?',\n        Description,\n        ('t', 'f')\n    )\n}} FROM w\n</code></pre> The <code>context</code> arg can reference a table created from a CTE, and our <code>options</code> value can be a semi-colon seperated list of strings.</p>"},{"location":"by-example/#conditional-materializing-of-cte-statements","title":"Conditional Materializing of CTE Statements","text":"<p><pre><code>WITH a AS (\n    SELECT * FROM portfolio WHERE Quantity &gt; 200\n), b AS\n(\n    SELECT Symbol FROM portfolio AS w WHERE w.Symbol LIKE \"A%\"\n),\nSELECT * FROM a WHERE {{test_starts_with('F', a.Symbol)}} = TRUE\nJOIN b ON a.Symbol = b.Symbol\n</code></pre> We only eagerly materialize a table from a CTE if it's used within an ingredient. Above, BlendSQL will materialize the <code>a</code> table, but not <code>b</code>.</p>"},{"location":"faq/","title":"FAQ","text":""},{"location":"faq/#how-does-blendsql-execute-a-query","title":"How does BlendSQL execute a query?","text":"<p>BlendSQL handles traversal of the SQL AST and creation of temporary tables to execute a given query.  This allows BlendSQL to be DBMS-agnostic, and extendable into both SQLite, PostgreSQL, and other DBMS.</p>"},{"location":"faq/#why-not-just-implement-blendsql-as-a-user-defined-function-in-sqlite","title":"Why not just implement BlendSQL as a user-defined function in SQLite?","text":"<p>LLMs are expensive, both in terms of $ cost and compute time. When applying them to SQLite databases, we want to take special care in ensuring we're not applying them to contexts where they're not required.  This is not easily achievable with UDFs, even when marked as a deterministic function.</p> <p>BlendSQL is specifically designed to enforce an order-of-operations that 1) prioritizes vanilla SQL operations first, and 2) caches results from LLM ingredients so they don't need to be recomputed. For example: <pre><code>SELECT {{LLMMap('What state is this NBA team from?', 'w::team')} FROM w \n   WHERE num_championships &gt; 3 \n   ORDER BY {{LLMMap('What state is this NBA team from?', 'w::team')}\n</code></pre> BlendSQL makes sure to only pass those <code>team</code> values from rows which satisfy the condition <code>num_championship &gt; 3</code> to the LLM. Additionally, since we assume the function is deterministic, we make a single LLM call and cache the results, despite the ingredient function being used twice.</p>"},{"location":"faq/#so-i-get-how-to-write-blendsql-queries-but-why-would-i-use-this-over-vanilla-sqlite","title":"So I get how to write BlendSQL queries. But why would I use this over vanilla SQLite?","text":"<p>Certain ingredients, like LLMJoin, will likely give seasoned SQL experts a headache at first. However, BlendSQL's real strength comes from it's use as an intermediate representation for reasoning over structured + unstructured with LLMs. Some examples of this can be found here.</p>"},{"location":"installation/","title":"Installation","text":"<pre><code>pip install blendsql\n</code></pre>"},{"location":"quickstart/","title":"Quickstart","text":"<pre><code>import pandas as pd\n\nfrom blendsql import BlendSQL\nfrom blendsql.models import TransformersLLM, LiteLLM\n\nUSE_LOCAL_CONSTRAINED_MODEL = False\n\n# Load model, either a local transformers model, or remote provider via LiteLLM\nif USE_LOCAL_CONSTRAINED_MODEL:\n    model = TransformersLLM(\n        \"meta-llama/Llama-3.2-3B-Instruct\", config={\"device_map\": \"auto\"}\n    )  # Local models enable BlendSQL's predicate-guided constrained decoding\nelse:\n    model = LiteLLM(\"openai/gpt-4o-mini\")\n\n# Prepare our BlendSQL connection\nbsql = BlendSQL(\n    {\n        \"People\": pd.DataFrame(\n            {\n                \"Name\": [\n                    \"George Washington\",\n                    \"John Adams\",\n                    \"Thomas Jefferson\",\n                    \"James Madison\",\n                    \"James Monroe\",\n                    \"Alexander Hamilton\",\n                    \"Sabrina Carpenter\",\n                    \"Charli XCX\",\n                    \"Elon Musk\",\n                    \"Michelle Obama\",\n                    \"Elvis Presley\",\n                ],\n                \"Known_For\": [\n                    \"Established federal government, First U.S. President\",\n                    \"XYZ Affair, Alien and Sedition Acts\",\n                    \"Louisiana Purchase, Declaration of Independence\",\n                    \"War of 1812, Constitution\",\n                    \"Monroe Doctrine, Missouri Compromise\",\n                    \"Created national bank, Federalist Papers\",\n                    \"Nonsense, Emails I Cant Send, Mean Girls musical\",\n                    \"Crash, How Im Feeling Now, Boom Clap\",\n                    \"Tesla, SpaceX, Twitter/X acquisition\",\n                    \"Lets Move campaign, Becoming memoir\",\n                    \"14 Grammys, King of Rock n Roll\",\n                ],\n            }\n        ),\n        \"Eras\": pd.DataFrame({\"Years\": [\"1700-1800\", \"1800-1900\", \"1900-2000\", \"2000-Now\"]}),\n    },\n    model=model,\n    verbose=True,\n)\n\nsmoothie = bsql.execute(\n    \"\"\"\n    SELECT * FROM People P\n    WHERE P.Name IN {{\n        LLMQA('First 3 presidents of the U.S?', quantifier='{3}')\n    }}\n    \"\"\",\n    infer_gen_constraints=True,\n)\n\nprint(smoothie.df)\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 Name              \u2502 Known_For                                             \u2502\n# \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n# \u2502 George Washington \u2502 Established federal government, First U.S. Preside... \u2502\n# \u2502 John Adams        \u2502 XYZ Affair, Alien and Sedition Acts                   \u2502\n# \u2502 Thomas Jefferson  \u2502 Louisiana Purchase, Declaration of Independence       \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nprint(smoothie.summary())\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502   Time (s) \u2502   # Generation Calls \u2502   Prompt Tokens \u2502   Completion Tokens \u2502\n# \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n# \u2502    1.25158 \u2502                    1 \u2502             296 \u2502                  16 \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\nsmoothie = bsql.execute(\n    \"\"\"\n    SELECT GROUP_CONCAT(Name, ', ') AS 'Names',\n    {{\n        LLMMap(\n            'In which time period was this person born?',\n            'People::Name',\n            options='Eras::Years'\n        )\n    }} AS Born\n    FROM People\n    GROUP BY Born\n    \"\"\",\n)\n\nprint(smoothie.df)\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 Names                                                 \u2502 Born      \u2502\n# \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n# \u2502 George Washington, John Adams, Thomas Jefferson, J... \u2502 1700-1800 \u2502\n# \u2502 Sabrina Carpenter, Charli XCX, Elon Musk, Michelle... \u2502 2000-Now  \u2502\n# \u2502 Elvis Presley                                         \u2502 1900-2000 \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nprint(smoothie.summary())\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502   Time (s) \u2502   # Generation Calls \u2502   Prompt Tokens \u2502   Completion Tokens \u2502\n# \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n# \u2502    1.03858 \u2502                    2 \u2502             544 \u2502                  75 \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nsmoothie = bsql.execute(\"\"\"\n    SELECT {{\n        LLMQA(\n            'Describe BlendSQL in 50 words',\n            (\n                SELECT content[0:5000] AS \"README\"\n                FROM read_text('https://raw.githubusercontent.com/parkervg/blendsql/main/README.md');\n            )\n        )\n    }} AS answer\n\"\"\")\n\nprint(smoothie.df)\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 answer                                              \u2502\n# \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n# \u2502 BlendSQL is a Python library that combines SQL a... \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nprint(smoothie.summary())\n\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502   Time (s) \u2502   # Generation Calls \u2502   Prompt Tokens \u2502   Completion Tokens \u2502\n# \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n# \u2502    4.07617 \u2502                    1 \u2502            1921 \u2502                  50 \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"examples/feverous/","title":"FEVEROUS","text":"<p>Here, we deal not with questions, but truth claims given a context of unstructured and structured data.</p> <p>These claims should be judged as \"SUPPORTS\" or \"REFUTES\". Using BlendSQL, we can formulate this determination of truth as a function over facts. </p> <p>Oyedaea is part of the family Asteraceae in the order Asterales. <pre><code>SELECT EXISTS (\n    SELECT * FROM w0 WHERE \"family:\" = 'asteraceae' AND \"order:\" = 'asterales'\n) \n</code></pre></p> <p>Sixty two year old Welsh journalist Jan Moir worked for a couple other papers before working at Daily Mail as an opinion columnist and has won several awards for her writing. <pre><code>SELECT (\n    SELECT {{LLMMap('What age?', 'w0::born')}} = 62 FROM w0\n) AND (\n    {{\n        LLMValidate(\n            'Did Jan Moir work at a couple other papers before working at Daily Mail as an opinion columnist?',\n            (SELECT * FROM documents)\n        ) \n    }}\n) AND (\n    {{\n        LLMValidate(\n            'Has Jan Moir won several awards for her writing?',\n            (SELECT * FROM documents)\n        ) \n    }}\n)\n</code></pre></p> <p>Saunders College of Business, which is accredited by the Association to Advance Collegiate Schools of Business International, is one of the colleges of Rochester Institute of Technology established in 1910 and is currently under the supervision of Dean Jacqueline R. Mozrall. <pre><code>SELECT EXISTS(\n    SELECT * FROM w0 \n    WHERE \"parent institution\" = 'rochester institute of technology'\n    AND \"established\" = '1910'\n    AND \"dean\" = 'jacqueline r. mozrall'\n) AND (\n    {{\n        LLMValidate(\n            'Is Saunders College of Business (SCB) accredited by the Association to Advance Collegiate Schools of Business International (AACSB)?',\n            (SELECT * FROM documents)\n        )\n    }}\n)\n</code></pre></p>"},{"location":"examples/hybridqa/","title":"HybridQA","text":"<p>For this setting, our database contains 2 tables: a table from Wikipedia <code>w</code>, and a collection of unstructured Wikipedia articles in the table <code>documents</code>.</p> <p>What is the state flower of the smallest state by area ? <pre><code>SELECT \"common name\" AS 'State Flower' FROM w \nWHERE state = {{\n    LLMQA(\n        'Which is the smallest state by area?',\n        (SELECT title, content FROM documents),\n        options='w::state'\n    )\n}}\n</code></pre></p> <p>Who were the builders of the mosque in Herat with fire temples ? <pre><code>{{\n    LLMQA(\n        'Who were the builders of the mosque?',\n        (\n            SELECT documents.title AS 'Building', documents.content FROM documents\n            JOIN {{\n                LLMJoin(\n                    left_on='w::name',\n                    right_on='documents::title'\n                )\n            }}\n            WHERE w.city = 'herat' AND w.remarks LIKE '%fire temple%'\n        )\n    )\n}}\n</code></pre></p> <p>What is the capacity of the venue that was named in honor of Juan Antonio Samaranch in 2010 after his death ? <pre><code>SELECT capacity FROM w WHERE venue = {{\n    LLMQA(\n        'Which venue is named in honor of Juan Antonio Samaranch?',\n        (SELECT title AS 'Venue', content FROM documents),\n        options='w::venue'\n    )\n}}\n</code></pre></p>"},{"location":"examples/ottqa/","title":"OTT-QA","text":"<p>Unlike HybridQA, these questions are open-domain, where we don't know in advance where the answer of a given open question appears in a passage or a table.</p> <p>As a result, we need to play the role of both the retriever (to select relevant context) and reader (to read from relevant contexts and return the given answer).</p> <p>As the underlying database consists of 400K tables and 5M documents, it's important to set <code>LIMIT</code> clauses appropriately to ensure reasonable execution times.</p> <p>The examples below also demonstrate how BlendSQL unpacks CTE statements to ensure we only pass necessary data into the BlendSQL ingredient calls. </p> <p>When was the third highest paid Rangers F.C . player born ? <pre><code>{{\n    LLMQA(\n        'When was the Rangers Player born?',\n        (\n            WITH t AS (\n                SELECT player FROM (\n                    SELECT * FROM \"./List of Rangers F.C. records and statistics (0)\"\n                    UNION ALL SELECT * FROM \"./List of Rangers F.C. records and statistics (1)\"\n                ) ORDER BY trim(fee, '\u00a3') DESC LIMIT 1 OFFSET 2\n            ), d AS (\n                SELECT * FROM documents JOIN t WHERE documents MATCH t.player || ' OR rangers OR fc' ORDER BY rank LIMIT 5\n            ) SELECT d.content, t.player AS 'Rangers Player' FROM d JOIN t\n        )\n    )\n}}\n</code></pre></p> <p>In which Track Cycling World Championships event was the person born in Matanzas , Cuba ranked highest ? <pre><code>{{\n    LLMQA(\n        'In what event was the cyclist ranked highest?',\n        (\n            SELECT * FROM (\n                SELECT * FROM \"./Cuba at the UCI Track Cycling World Championships (2)\"\n            ) as w WHERE w.name = {{\n                LLMQA(\n                    \"Which cyclist was born in Matanzas, Cuba?\",\n                    (\n                        SELECT * FROM documents \n                            WHERE documents MATCH 'matanzas AND (cycling OR track OR born)' \n                            ORDER BY rank LIMIT 3\n                    ),\n                    options=\"w::name\"\n                )\n            }}\n        ),\n        options='w::event'\n    )\n}}\n</code></pre></p> <p>Who is the director the Togolese film that was a 30 minute film that was shot in 16mm ? <pre><code>SELECT director FROM \"./List of African films (4)\" as w\nWHERE title = {{\n    LLMQA(\n        'What is the name of the Togolese film that was 30 minutes and shot in 16mm?',\n        (SELECT * FROM documents WHERE documents MATCH 'togolese OR 30 OR 16mm OR film' ORDER BY rank LIMIT 5),\n        options='w::title'\n    )\n}}\n</code></pre></p>"},{"location":"reference/execute-blendsql/","title":"Execute a BlendSQL Query","text":""},{"location":"reference/execute-blendsql/#blendsql-class","title":"BlendSQL Class","text":"<p>Core <code>BlendSQL</code> class that provides high level interface for executing BlendSQL queries.</p> <p>Parameters:</p> Name Type Description Default <code>db</code> <code>Union[DataFrame, dict, str, Database]</code> <p>Database to connect to. Can be:</p> <ul> <li> <p>pandas DataFrame or dict of DataFrames</p> </li> <li> <p>Path to SQLite database file</p> </li> <li> <p>PostgreSQL connection string</p> </li> <li> <p><code>Database</code> object</p> </li> </ul> <code>None</code> <code>model</code> <code>Optional[Model]</code> <p>Model instance to use for LLM operations. Can also be provided during query execution.</p> <code>None</code> <code>ingredients</code> <code>Optional[Collection[Type[Ingredient]]]</code> <p>Collection of ingredients to make available for queries. Can also be     provided during query execution.</p> <code>list()</code> <code>verbose</code> <code>bool</code> <p>Whether to output debug logging information. Defaults to False.</p> <code>False</code> <code>infer_gen_constraints</code> <code>bool</code> <p>Whether to automatically infer constraints for LLM generation based on query context. Defaults to True.</p> <code>True</code> <code>table_to_title</code> <code>Optional[Dict[str, str]]</code> <p>Optional mapping from table names to descriptive titles, useful for datasets where table titles contain metadata.</p> <code>None</code> Source code in <code>blendsql/blendsql.py</code> <pre><code>@dataclass\nclass BlendSQL:\n    \"\"\"Core `BlendSQL` class that provides high level interface for executing BlendSQL queries.\n\n    Args:\n        db (Union[pd.DataFrame, dict, str, Database]): Database to connect to. Can be:\n\n            - pandas DataFrame or dict of DataFrames\n\n            - Path to SQLite database file\n\n            - PostgreSQL connection string\n\n            - `Database` object\n        model (Optional[Model]): Model instance to use for LLM operations. Can also be\n            provided during query execution.\n        ingredients (Optional[Collection[Type[Ingredient]]]): Collection of ingredients to\n            make available for queries. Can also be\n                provided during query execution.\n        verbose (bool): Whether to output debug logging information. Defaults to False.\n        infer_gen_constraints (bool): Whether to automatically infer constraints for\n            LLM generation based on query context. Defaults to True.\n        table_to_title (Optional[Dict[str, str]]): Optional mapping from table names to\n            descriptive titles, useful for datasets where table titles contain metadata.\n    \"\"\"\n\n    db: t.Union[pd.DataFrame, dict, str, Database] = field(default=None)\n    model: t.Optional[Model] = field(default=None)\n    ingredients: t.Optional[Collection[t.Type[Ingredient]]] = field(\n        default_factory=list\n    )\n\n    verbose: bool = field(default=False)\n    infer_gen_constraints: bool = field(default=True)\n    table_to_title: t.Optional[t.Dict[str, str]] = field(default=None)\n\n    def __post_init__(self):\n        if not isinstance(self.db, Database):\n            self.db = self._infer_db_type(self.db)\n        if self.db is None:\n            raise ValueError(\"df_or_db_path must be provided\")\n        self.ingredients = self._merge_default_ingredients(self.ingredients)\n        self._toggle_verbosity(self.verbose)\n\n    @staticmethod\n    def _toggle_verbosity(verbose_in_use: bool):\n        def set_level(l: int):\n            logger.setLevel(l)\n            for handler in logger.handlers:\n                handler.setLevel(l)\n\n        if verbose_in_use:\n            set_level(logging.DEBUG)\n        else:\n            set_level(logging.ERROR)\n\n    @staticmethod\n    def _merge_default_ingredients(\n        ingredients: t.Optional[Collection[t.Type[Ingredient]]],\n    ):\n        from blendsql.ingredients import LLMQA, LLMMap, LLMJoin\n\n        DEFAULT_INGREDIENTS = {LLMQA, LLMMap, LLMJoin}\n        ingredients = set(ingredients)\n        try:\n            ingredient_names = {i.__name__ for i in ingredients}\n        except AttributeError as e:\n            raise IngredientException(\n                \"All arguments passed to `ingredients` should be `Ingredient` classes!\"\n            ) from e\n        for default_ingredient in DEFAULT_INGREDIENTS:\n            if default_ingredient.__name__ not in ingredient_names:\n                ingredients.add(default_ingredient)\n        return ingredients\n\n    @staticmethod\n    def _infer_db_type(df_or_db_path) -&gt; Database:\n        from pathlib import Path\n\n        if df_or_db_path is None:\n            from .db.pandas import Pandas\n\n            return Pandas({})  # Load an empty DuckDB connection\n\n        elif isinstance(df_or_db_path, (pd.DataFrame, dict)):\n            from .db.pandas import Pandas\n\n            return Pandas(df_or_db_path)\n        elif isinstance(df_or_db_path, (str, Path)):\n            if Path(df_or_db_path).exists():\n                from .db.sqlite import SQLite\n\n                return SQLite(df_or_db_path)\n            else:\n                from .db.postgresql import PostgreSQL\n\n                return PostgreSQL(df_or_db_path)\n        else:\n            raise ValueError(\n                f\"Could not resolve '{df_or_db_path}' to a valid database type!\"\n            )\n\n    def visualize(self, query: str, output_path: t.Optional[str] = None, format=\"pdf\"):\n        \"\"\"Visualize query as a DAG with graphviz.\"\"\"\n        from .visualize import SQLGlotASTVisualizer\n\n        visualizer = SQLGlotASTVisualizer()\n\n        dialect: sqlglot.Dialect = get_dialect(self.db.__class__.__name__)\n\n        # Generate visualization\n        dot = visualizer.visualize(\n            _parse_one(query, dialect=dialect, schema=self.db.sqlglot_schema)\n        )\n\n        if output_path is not None:\n            # Save as PDF\n            dot.render(output_path, format=format, cleanup=True)\n        return dot\n\n    def execute(\n        self,\n        query: str,\n        ingredients: t.Optional[Collection[t.Type[Ingredient]]] = None,\n        model: t.Optional[str] = None,\n        infer_gen_constraints: t.Optional[bool] = None,\n        verbose: t.Optional[bool] = None,\n    ) -&gt; Smoothie:\n        '''The `execute()` function is used to execute a BlendSQL query against a database and\n        return the final result, in addition to the intermediate reasoning steps taken.\n        Execution is done on a database given an ingredient context.\n\n        Args:\n            query: The BlendSQL query to execute\n            ingredients: Collection of ingredient objects, to use in interpreting BlendSQL query\n            verbose: Boolean defining whether to run with logger in debug mode\n            default_model: Which BlendSQL model to use in performing ingredient tasks in the current query\n            infer_gen_constraints: Optionally infer the output format of an `IngredientMap` call, given the predicate context\n                For example, in `{{LLMMap('convert to date', 'w::listing date')}} &lt;= '1960-12-31'`\n                We can infer the output format should look like '1960-12-31' and both:\n                    1) Put this string in the `example_outputs` kwarg\n                    2) If we have a LocalModel, pass the r'\\d{4}-\\d{2}-\\d{2}' pattern to guidance\n            table_to_title: Optional mapping from table name to title of table.\n                Useful for datasets like WikiTableQuestions, where relevant info is stored in table title.\n\n        Returns:\n            smoothie: `Smoothie` dataclass containing pd.DataFrame output and execution metadata\n\n        Examples:\n            ```python\n            import pandas as pd\n\n            from blendsql import BlendSQL, config\n            from blendsql.ingredients import LLMMap, LLMQA, LLMJoin\n            from blendsql.models import LiteLLM, TransformersLLM\n\n            # Optionally set how many async calls to allow concurrently\n            # This depends on your OpenAI/Anthropic/etc. rate limits\n            config.set_async_limit(10)\n\n            # Load model\n            model = LiteLLM(\"openai/gpt-4o-mini\") # requires .env file with `OPENAI_API_KEY`\n            # model = LiteLLM(\"anthropic/claude-3-haiku-20240307\") # requires .env file with `ANTHROPIC_API_KEY`\n            # model = TransformersLLM(\n            #    \"meta-llama/Llama-3.2-1B-Instruct\",\n            #    config={\"chat_template\": Llama3ChatTemplate, \"device_map\": \"auto\"},\n            # ) # run with any local Transformers model\n\n            # Prepare our BlendSQL connection\n            bsql = BlendSQL(\n                {\n                    \"People\": pd.DataFrame(\n                        {\n                            \"Name\": [\n                                \"George Washington\",\n                                \"John Quincy Adams\",\n                                \"Thomas Jefferson\",\n                                \"James Madison\",\n                                \"James Monroe\",\n                                \"Alexander Hamilton\",\n                                \"Sabrina Carpenter\",\n                                \"Charli XCX\",\n                                \"Elon Musk\",\n                                \"Michelle Obama\",\n                                \"Elvis Presley\",\n                            ],\n                            \"Known_For\": [\n                                \"Established federal government, First U.S. President\",\n                                \"XYZ Affair, Alien and Sedition Acts\",\n                                \"Louisiana Purchase, Declaration of Independence\",\n                                \"War of 1812, Constitution\",\n                                \"Monroe Doctrine, Missouri Compromise\",\n                                \"Created national bank, Federalist Papers\",\n                                \"Nonsense, Emails I Cant Send, Mean Girls musical\",\n                                \"Crash, How Im Feeling Now, Boom Clap\",\n                                \"Tesla, SpaceX, Twitter/X acquisition\",\n                                \"Lets Move campaign, Becoming memoir\",\n                                \"14 Grammys, King of Rock n Roll\",\n                            ],\n                        }\n                    ),\n                    \"Eras\": pd.DataFrame({\"Years\": [\"1800-1900\", \"1900-2000\", \"2000-Now\"]}),\n                },\n                ingredients={LLMMap, LLMQA, LLMJoin},\n                model=model,\n            )\n\n            smoothie = bsql.execute(\n                \"\"\"\n                SELECT * FROM People P\n                WHERE P.Name IN {{\n                    LLMQA('First 3 presidents of the U.S?', quantifier='{3}')\n                }}\n                \"\"\"\n            )\n\n            print(smoothie.df)\n            # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            # \u2502 Name              \u2502 Known_For                                             \u2502\n            # \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n            # \u2502 George Washington \u2502 Established federal government, First U.S. Preside... \u2502\n            # \u2502 John Quincy Adams \u2502 XYZ Affair, Alien and Sedition Acts                   \u2502\n            # \u2502 Thomas Jefferson  \u2502 Louisiana Purchase, Declaration of Independence       \u2502\n            # \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            print(smoothie.summary())\n            # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            # \u2502   Time (s) \u2502   # Generation Calls \u2502   Prompt Tokens \u2502   Completion Tokens \u2502\n            # \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n            # \u2502    1.25158 \u2502                    1 \u2502             296 \u2502                  16 \u2502\n            # \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            ```\n        '''\n        self._toggle_verbosity(verbose if verbose is not None else self.verbose)\n\n        start = time.time()\n        model_in_use = model or self.model\n        try:\n            smoothie = _blend(\n                query=query,\n                db=self.db,\n                default_model=model_in_use,\n                ingredients=self._merge_default_ingredients(\n                    ingredients or self.ingredients\n                ),\n                infer_gen_constraints=infer_gen_constraints\n                if infer_gen_constraints is not None\n                else self.infer_gen_constraints,\n                table_to_title=self.table_to_title,\n            )\n        except Exception as error:\n            raise error\n        finally:\n            # In the case of a recursive `_blend()` call,\n            #   this logic allows temp tables to persist until\n            #   the final base case is fulfilled.\n            self.db._reset_connection()\n        smoothie.meta.process_time_seconds = time.time() - start\n        # Reset model stats, so future executions don't add here\n        if model_in_use is not None:\n            model_in_use.reset_stats()\n        return smoothie\n</code></pre>"},{"location":"reference/execute-blendsql/#blendsql.BlendSQL.execute","title":"<code>execute(query, ingredients=None, model=None, infer_gen_constraints=None, verbose=None)</code>","text":"<p>The <code>execute()</code> function is used to execute a BlendSQL query against a database and return the final result, in addition to the intermediate reasoning steps taken. Execution is done on a database given an ingredient context.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The BlendSQL query to execute</p> required <code>ingredients</code> <code>Optional[Collection[Type[Ingredient]]]</code> <p>Collection of ingredient objects, to use in interpreting BlendSQL query</p> <code>None</code> <code>verbose</code> <code>Optional[bool]</code> <p>Boolean defining whether to run with logger in debug mode</p> <code>None</code> <code>default_model</code> <p>Which BlendSQL model to use in performing ingredient tasks in the current query</p> required <code>infer_gen_constraints</code> <code>Optional[bool]</code> <p>Optionally infer the output format of an <code>IngredientMap</code> call, given the predicate context For example, in <code>{{LLMMap('convert to date', 'w::listing date')}} &lt;= '1960-12-31'</code> We can infer the output format should look like '1960-12-31' and both:     1) Put this string in the <code>example_outputs</code> kwarg     2) If we have a LocalModel, pass the r'\\d{4}-\\d{2}-\\d{2}' pattern to guidance</p> <code>None</code> <code>table_to_title</code> <p>Optional mapping from table name to title of table. Useful for datasets like WikiTableQuestions, where relevant info is stored in table title.</p> required <p>Returns:</p> Name Type Description <code>smoothie</code> <code>Smoothie</code> <p><code>Smoothie</code> dataclass containing pd.DataFrame output and execution metadata</p> <p>Examples:</p> <pre><code>import pandas as pd\n\nfrom blendsql import BlendSQL, config\nfrom blendsql.ingredients import LLMMap, LLMQA, LLMJoin\nfrom blendsql.models import LiteLLM, TransformersLLM\n\n# Optionally set how many async calls to allow concurrently\n# This depends on your OpenAI/Anthropic/etc. rate limits\nconfig.set_async_limit(10)\n\n# Load model\nmodel = LiteLLM(\"openai/gpt-4o-mini\") # requires .env file with `OPENAI_API_KEY`\n# model = LiteLLM(\"anthropic/claude-3-haiku-20240307\") # requires .env file with `ANTHROPIC_API_KEY`\n# model = TransformersLLM(\n#    \"meta-llama/Llama-3.2-1B-Instruct\",\n#    config={\"chat_template\": Llama3ChatTemplate, \"device_map\": \"auto\"},\n# ) # run with any local Transformers model\n\n# Prepare our BlendSQL connection\nbsql = BlendSQL(\n    {\n        \"People\": pd.DataFrame(\n            {\n                \"Name\": [\n                    \"George Washington\",\n                    \"John Quincy Adams\",\n                    \"Thomas Jefferson\",\n                    \"James Madison\",\n                    \"James Monroe\",\n                    \"Alexander Hamilton\",\n                    \"Sabrina Carpenter\",\n                    \"Charli XCX\",\n                    \"Elon Musk\",\n                    \"Michelle Obama\",\n                    \"Elvis Presley\",\n                ],\n                \"Known_For\": [\n                    \"Established federal government, First U.S. President\",\n                    \"XYZ Affair, Alien and Sedition Acts\",\n                    \"Louisiana Purchase, Declaration of Independence\",\n                    \"War of 1812, Constitution\",\n                    \"Monroe Doctrine, Missouri Compromise\",\n                    \"Created national bank, Federalist Papers\",\n                    \"Nonsense, Emails I Cant Send, Mean Girls musical\",\n                    \"Crash, How Im Feeling Now, Boom Clap\",\n                    \"Tesla, SpaceX, Twitter/X acquisition\",\n                    \"Lets Move campaign, Becoming memoir\",\n                    \"14 Grammys, King of Rock n Roll\",\n                ],\n            }\n        ),\n        \"Eras\": pd.DataFrame({\"Years\": [\"1800-1900\", \"1900-2000\", \"2000-Now\"]}),\n    },\n    ingredients={LLMMap, LLMQA, LLMJoin},\n    model=model,\n)\n\nsmoothie = bsql.execute(\n    \"\"\"\n    SELECT * FROM People P\n    WHERE P.Name IN {{\n        LLMQA('First 3 presidents of the U.S?', quantifier='{3}')\n    }}\n    \"\"\"\n)\n\nprint(smoothie.df)\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 Name              \u2502 Known_For                                             \u2502\n# \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n# \u2502 George Washington \u2502 Established federal government, First U.S. Preside... \u2502\n# \u2502 John Quincy Adams \u2502 XYZ Affair, Alien and Sedition Acts                   \u2502\n# \u2502 Thomas Jefferson  \u2502 Louisiana Purchase, Declaration of Independence       \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nprint(smoothie.summary())\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502   Time (s) \u2502   # Generation Calls \u2502   Prompt Tokens \u2502   Completion Tokens \u2502\n# \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n# \u2502    1.25158 \u2502                    1 \u2502             296 \u2502                  16 \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Source code in <code>blendsql/blendsql.py</code> <pre><code>def execute(\n    self,\n    query: str,\n    ingredients: t.Optional[Collection[t.Type[Ingredient]]] = None,\n    model: t.Optional[str] = None,\n    infer_gen_constraints: t.Optional[bool] = None,\n    verbose: t.Optional[bool] = None,\n) -&gt; Smoothie:\n    '''The `execute()` function is used to execute a BlendSQL query against a database and\n    return the final result, in addition to the intermediate reasoning steps taken.\n    Execution is done on a database given an ingredient context.\n\n    Args:\n        query: The BlendSQL query to execute\n        ingredients: Collection of ingredient objects, to use in interpreting BlendSQL query\n        verbose: Boolean defining whether to run with logger in debug mode\n        default_model: Which BlendSQL model to use in performing ingredient tasks in the current query\n        infer_gen_constraints: Optionally infer the output format of an `IngredientMap` call, given the predicate context\n            For example, in `{{LLMMap('convert to date', 'w::listing date')}} &lt;= '1960-12-31'`\n            We can infer the output format should look like '1960-12-31' and both:\n                1) Put this string in the `example_outputs` kwarg\n                2) If we have a LocalModel, pass the r'\\d{4}-\\d{2}-\\d{2}' pattern to guidance\n        table_to_title: Optional mapping from table name to title of table.\n            Useful for datasets like WikiTableQuestions, where relevant info is stored in table title.\n\n    Returns:\n        smoothie: `Smoothie` dataclass containing pd.DataFrame output and execution metadata\n\n    Examples:\n        ```python\n        import pandas as pd\n\n        from blendsql import BlendSQL, config\n        from blendsql.ingredients import LLMMap, LLMQA, LLMJoin\n        from blendsql.models import LiteLLM, TransformersLLM\n\n        # Optionally set how many async calls to allow concurrently\n        # This depends on your OpenAI/Anthropic/etc. rate limits\n        config.set_async_limit(10)\n\n        # Load model\n        model = LiteLLM(\"openai/gpt-4o-mini\") # requires .env file with `OPENAI_API_KEY`\n        # model = LiteLLM(\"anthropic/claude-3-haiku-20240307\") # requires .env file with `ANTHROPIC_API_KEY`\n        # model = TransformersLLM(\n        #    \"meta-llama/Llama-3.2-1B-Instruct\",\n        #    config={\"chat_template\": Llama3ChatTemplate, \"device_map\": \"auto\"},\n        # ) # run with any local Transformers model\n\n        # Prepare our BlendSQL connection\n        bsql = BlendSQL(\n            {\n                \"People\": pd.DataFrame(\n                    {\n                        \"Name\": [\n                            \"George Washington\",\n                            \"John Quincy Adams\",\n                            \"Thomas Jefferson\",\n                            \"James Madison\",\n                            \"James Monroe\",\n                            \"Alexander Hamilton\",\n                            \"Sabrina Carpenter\",\n                            \"Charli XCX\",\n                            \"Elon Musk\",\n                            \"Michelle Obama\",\n                            \"Elvis Presley\",\n                        ],\n                        \"Known_For\": [\n                            \"Established federal government, First U.S. President\",\n                            \"XYZ Affair, Alien and Sedition Acts\",\n                            \"Louisiana Purchase, Declaration of Independence\",\n                            \"War of 1812, Constitution\",\n                            \"Monroe Doctrine, Missouri Compromise\",\n                            \"Created national bank, Federalist Papers\",\n                            \"Nonsense, Emails I Cant Send, Mean Girls musical\",\n                            \"Crash, How Im Feeling Now, Boom Clap\",\n                            \"Tesla, SpaceX, Twitter/X acquisition\",\n                            \"Lets Move campaign, Becoming memoir\",\n                            \"14 Grammys, King of Rock n Roll\",\n                        ],\n                    }\n                ),\n                \"Eras\": pd.DataFrame({\"Years\": [\"1800-1900\", \"1900-2000\", \"2000-Now\"]}),\n            },\n            ingredients={LLMMap, LLMQA, LLMJoin},\n            model=model,\n        )\n\n        smoothie = bsql.execute(\n            \"\"\"\n            SELECT * FROM People P\n            WHERE P.Name IN {{\n                LLMQA('First 3 presidents of the U.S?', quantifier='{3}')\n            }}\n            \"\"\"\n        )\n\n        print(smoothie.df)\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502 Name              \u2502 Known_For                                             \u2502\n        # \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n        # \u2502 George Washington \u2502 Established federal government, First U.S. Preside... \u2502\n        # \u2502 John Quincy Adams \u2502 XYZ Affair, Alien and Sedition Acts                   \u2502\n        # \u2502 Thomas Jefferson  \u2502 Louisiana Purchase, Declaration of Independence       \u2502\n        # \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        print(smoothie.summary())\n        # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        # \u2502   Time (s) \u2502   # Generation Calls \u2502   Prompt Tokens \u2502   Completion Tokens \u2502\n        # \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n        # \u2502    1.25158 \u2502                    1 \u2502             296 \u2502                  16 \u2502\n        # \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        ```\n    '''\n    self._toggle_verbosity(verbose if verbose is not None else self.verbose)\n\n    start = time.time()\n    model_in_use = model or self.model\n    try:\n        smoothie = _blend(\n            query=query,\n            db=self.db,\n            default_model=model_in_use,\n            ingredients=self._merge_default_ingredients(\n                ingredients or self.ingredients\n            ),\n            infer_gen_constraints=infer_gen_constraints\n            if infer_gen_constraints is not None\n            else self.infer_gen_constraints,\n            table_to_title=self.table_to_title,\n        )\n    except Exception as error:\n        raise error\n    finally:\n        # In the case of a recursive `_blend()` call,\n        #   this logic allows temp tables to persist until\n        #   the final base case is fulfilled.\n        self.db._reset_connection()\n    smoothie.meta.process_time_seconds = time.time() - start\n    # Reset model stats, so future executions don't add here\n    if model_in_use is not None:\n        model_in_use.reset_stats()\n    return smoothie\n</code></pre>"},{"location":"reference/execute-blendsql/#blendsql.BlendSQL.visualize","title":"<code>visualize(query, output_path=None, format='pdf')</code>","text":"<p>Visualize query as a DAG with graphviz.</p> Source code in <code>blendsql/blendsql.py</code> <pre><code>def visualize(self, query: str, output_path: t.Optional[str] = None, format=\"pdf\"):\n    \"\"\"Visualize query as a DAG with graphviz.\"\"\"\n    from .visualize import SQLGlotASTVisualizer\n\n    visualizer = SQLGlotASTVisualizer()\n\n    dialect: sqlglot.Dialect = get_dialect(self.db.__class__.__name__)\n\n    # Generate visualization\n    dot = visualizer.visualize(\n        _parse_one(query, dialect=dialect, schema=self.db.sqlglot_schema)\n    )\n\n    if output_path is not None:\n        # Save as PDF\n        dot.render(output_path, format=format, cleanup=True)\n    return dot\n</code></pre>"},{"location":"reference/functions/","title":"General Syntax","text":""},{"location":"reference/functions/#valuearray","title":"<code>ValueArray</code>","text":"<p>A <code>ValueArray</code> is a reference to a list of values. This can be written using:</p> <ul> <li> <p>Standard column <code>{tablename}.{columnname}</code> syntax (<code>tablename</code> can be ommitted, and standard SQL binding logic will apply)</p> </li> <li> <p>SQL tuple (<code>(value1, value2)</code>) syntax</p> </li> <li> <p>A BlendSQL query which returns a 1d array of values (<code>(SELECT value FROM table WHERE ...)</code>)</p> </li> </ul>"},{"location":"reference/functions/#passing-options","title":"Passing <code>options</code>","text":"<p>The functions <code>LLMMap</code> and <code>LLMQA</code> support the passing of an <code>options</code> argument. This will constrain the output of the functions to only values appearing in the passed <code>ValueArray</code>.</p> <pre><code>SELECT {{\n    LLMMap(\n        'What is the sentiment of this text?',\n        content,\n        options=('positive', 'negative')\n    )      \n}}, content AS classification FROM posts LIMIT 10\n</code></pre>"},{"location":"reference/functions/#functions","title":"Functions","text":""},{"location":"reference/functions/#llmqa","title":"LLMQA","text":"<p>The <code>LLMQA</code> is an aggregate function that returns a single scalar value.</p>"},{"location":"reference/functions/#quantifier","title":"<code>Quantifier</code>","text":"<p>An optional <code>quantifier</code> argument can be passed, which will be used to modify the regular expression pattern powering the constrained decoding. The following greedy quantifiers are valid:</p> <ul> <li><code>'*'</code>, meaning 'zero-or-more'</li> <li><code>'+</code>', meaning 'one-or-more'</li> <li>Any string matching the pattern <code>{\\d(,\\d)?}</code> (e.g. <code>{1,2}</code>)</li> </ul> <pre><code>def LLMQA(\n    question: str,\n    *context: Query,\n    options: Optional[ValueArray] = None,\n    return_type: Optional[ReturnType] = None,\n    regex: Optional[str] = None,\n    quantifier: Optional[Quantifier] = None\n):\n    ...\n</code></pre> <p>Examples: <pre><code>SELECT preferred_foot FROM Player p\nWHERE p.player_name = {{\n    /* With `infer_gen_constraints=True` (which is default),\n    `options` will automatically be inferred, and the below\n    will select from a value in the `p.player_name` column. */\n    LLMQA(\n        \"Which player has the most Ballon d'Or awards?\"\n    )\n}}\n</code></pre></p> <pre><code>SELECT name FROM state_flowers\nWHERE state = {{\n    LLMQA(\n        \"Which state is known as 'The Golden State'?\",\n        /* Pass context via a subquery */\n        (SELECT title, content FROM documents)\n    )\n}}\n</code></pre> <pre><code>/* Generate 3 values in our generated tuple */\nSELECT * FROM VALUES {{LLMQA('What are the first 3 letters of the alphabet?', quantifier='{3}')}}\n</code></pre> <pre><code>SELECT {{\n    LLMQA(\n        /* Use f-string templating to insert the result of subqueries*/\n        'What do {} and {} have in common?',\n        /* Below are examples - any BlendSQL queries are valid here, \n        but they should return a single scalar value.   \n        */\n        (SELECT 'Saturn'),\n        (SELECT 'Jupiter')\n    )    \n}}\n</code></pre>"},{"location":"reference/functions/#also-see","title":"Also See:","text":"<ul> <li>LLMQA with search</li> <li>LLMQA with search + f-string templating</li> </ul>"},{"location":"reference/functions/#llmmap","title":"LLMMap","text":"<p>The <code>LLMMap</code> is a unary scalar function, much like <code>LENGTH</code> or <code>ABS</code> in SQlite. The output of this function is set as a new column in a temporary table, for later use within the wider query.</p> <pre><code>def LLMMap(\n    question: str,\n    values: ColumnRef,\n    *context: ValueArray,\n    options: Optional[ValueArray] = None,\n    return_type: Optional[ReturnType] = None,\n    regex: Optional[str] = None\n):\n    ...\n</code></pre> <p>Examples: <pre><code>SELECT COUNT(DISTINCT(s.CDSCode)) FROM schools s\nJOIN satscores sa ON s.CDSCode = sa.cds\nWHERE sa.AvgScrMath &gt; 560\n/* With `infer_gen_constraints=True`, generations below will be restricted to a boolean. */\nAND {{LLMMap('Is this a county in the California Bay Area?', s.County)}} = TRUE\n</code></pre></p> <pre><code>SELECT GROUP_CONCAT(Name, ', ') AS Names,\n{{\n    LLMMap(\n        'In which time period was this person born?',\n        p.Name,\n        /* BlendSQL differs from standard SQL binding logic below, \n        since we can invoke a table (`Eras`) not previously referenced */\n        options=Eras.Years\n    )\n}} AS Born\nFROM People p\nGROUP BY Born\n</code></pre> <pre><code>WITH player_stats AS (\n    SELECT *, {{\n        LLMMap(\n            'How many points and assists did {} have? Respond in the order [points, assists]. If a stat is not present for a player, return -1.', \n            player, \n            Report, /* Pass `Report` in as context for each `player` */\n            return_type='List[int]',\n            quantifier='{2}'\n        )\n    }} AS box_score_values\n    FROM w\n) SELECT \nplayer,\nReport,\nlist_element(box_score_values, 1) AS points,\nlist_element(box_score_values, 2) AS assists\nFROM player_stats\n</code></pre>"},{"location":"reference/functions/#also-see_1","title":"Also See:","text":"<ul> <li>LLMMap with search</li> <li>Mapping with <code>return_type='substring'</code></li> </ul>"},{"location":"reference/functions/#llmjoin","title":"LLMJoin","text":"<p>The <code>LLMJoin</code> function can be used to perform semantic entity linking between columns in tables. It is commonly used in conjunction with a <code>documents</code> table, to fetch articles related to a value in another table.</p> <pre><code>def LLMJoin(\n    left_on: ValueArray,\n    right_on: ValueArray,\n    join_criteria: Optional[str] = \"Join to same topics.\"\n):\n    ...\n</code></pre> <p>Examples: <pre><code>-- Get all articles on players older than 21\nSELECT * FROM Player p\nJOIN documents d ON {{\n    LLMJoin(\n        p.Name,\n        d.title\n    )\n}} WHERE p.age &gt; 21\n</code></pre></p> <pre><code>SELECT f.name, c.name FROM fruits f\nJOIN colors c ON {{\n    LLMJoin(\n        f.name,\n        c.name,\n        /* If we need to, we can pass a join_criteria.\n        Otherwise, the default 'Join by topic' is used. */\n        join_criteria='Align the fruit to its color.'\n    )\n}}\n</code></pre>"},{"location":"reference/query_optimization/","title":"Query optimization","text":""},{"location":"reference/query_optimization/#querycontextmanager","title":"QueryContextManager","text":"<p>Handles manipulation of underlying SQL query. We need to maintain two synced representations here:</p> <pre><code>1) The underlying sqlglot exp.Expression node\n\n2) The string representation of the query\n</code></pre> Source code in <code>blendsql/parse/parse.py</code> <pre><code>@attrs\nclass QueryContextManager:\n    \"\"\"Handles manipulation of underlying SQL query.\n    We need to maintain two synced representations here:\n\n        1) The underlying sqlglot exp.Expression node\n\n        2) The string representation of the query\n    \"\"\"\n\n    dialect: sqlglot.Dialect = attrib()\n\n    node: exp.Expression = attrib(default=None)\n    _query: str = attrib(default=None)\n    _last_to_string_node: exp.Expression = None\n\n    def parse(self, query, schema: t.Optional[t.Union[dict, Schema]] = None):\n        self._query = query\n        self.node = _parse_one(query, dialect=self.dialect, schema=schema)\n\n    def to_string(self):\n        # Only call `sql` if we need to\n        if hash(self.node) != hash(self._last_to_string_node):\n            self._query = self.node.sql(dialect=self.dialect)\n            self.last_to_string_node = self.node\n        return self._query\n\n    def __setattr__(self, name, value):\n        self.__dict__[name] = value\n</code></pre>"},{"location":"reference/query_optimization/#subquerycontextmanager","title":"SubqueryContextManager","text":"Source code in <code>blendsql/parse/parse.py</code> <pre><code>@attrs\nclass SubqueryContextManager:\n    dialect: sqlglot.Dialect = attrib()\n    node: exp.Select = attrib()\n    prev_subquery_has_ingredient: bool = attrib()\n    ingredient_alias_to_parsed_dict: dict = attrib()\n\n    # Keep a running log of what aliases we've initialized so far, per subquery\n    alias_to_subquery: dict = attrib(default=None)\n    alias_to_tablename: dict = attrib(init=False)\n    tablename_to_alias: dict = attrib(init=False)\n    columns_referenced_by_ingredients: dict = attrib(init=False)\n    root: sqlglot.optimizer.scope.Scope = attrib(init=False)\n\n    def __attrs_post_init__(self):\n        self.alias_to_tablename = {}\n        self.tablename_to_alias = {}\n        # https://github.com/tobymao/sqlglot/blob/v20.9.0/posts/ast_primer.md#scope\n        self.root = build_scope(self.node)\n        self.columns_referenced_by_ingredients = (\n            self.get_columns_referenced_by_ingredients(\n                self.ingredient_alias_to_parsed_dict\n            )\n        )\n\n    def _reset_root(self):\n        self.root = build_scope(self.node)\n\n    def set_node(self, node):\n        self.node = node\n        self._reset_root()\n\n    def get_columns_referenced_by_ingredients(\n        self, ingredient_alias_to_parsed_dict: dict\n    ):\n        # TODO: call infer_gen_constraints() first, to populate `options`\n        columns_referenced_by_ingredients = {}\n        ingredient_aliases = [i.name for i in check.get_ingredient_nodes(self.node)]\n        for ingredient_alias in ingredient_aliases:\n            kwargs_dict = ingredient_alias_to_parsed_dict[ingredient_alias][\n                \"kwargs_dict\"\n            ]\n            for raw_arg in {\n                # Below lists all arguments where a table may be referenced\n                # We omit `options`, since this should not take into account the\n                #   state of the filtered database.\n                kwargs_dict.get(\"context\", None),\n                kwargs_dict.get(\"values\", None),\n                kwargs_dict.get(\"left_on\", None),\n                kwargs_dict.get(\"right_on\", None),\n            }:\n                args = raw_arg\n                if not isinstance(raw_arg, (tuple, list)):\n                    args = [raw_arg]\n                for arg in args:\n                    if arg is None:\n                        continue\n                    # If `context` is a subquery, this gets executed on its own later.\n                    if isinstance(arg, ColumnRef):\n                        tablename, columnname = get_tablename_colname(arg)\n                        if tablename not in columns_referenced_by_ingredients:\n                            columns_referenced_by_ingredients[tablename] = set()\n                        columns_referenced_by_ingredients[tablename].add(columnname)\n        return columns_referenced_by_ingredients\n\n    def abstracted_table_selects(\n        self,\n    ) -&gt; t.Generator[t.Tuple[str, bool, str], None, None]:\n        \"\"\"For each table in a given query, generates a `SELECT *` query where all unneeded predicates\n        are set to `TRUE`.\n        We say `unneeded` in the sense that to minimize the data that gets passed to an ingredient,\n        we don't need to factor in this operation at the moment.\n\n        Args:\n            node: exp.Select node from which to construct abstracted versions of queries for each table.\n\n        Returns:\n            abstracted_queries: Generator with (tablename, postprocess_columns, abstracted_query_str).\n                postprocess_columns tells us if we potentially executed a query with a `JOIN`, and need to apply some extra post-processing.\n\n        Examples:\n            ```python\n            scm = SubqueryContextManager(\n                node=_parse_one(\n                    \"SELECT * FROM transactions WHERE {{Model('is this an italian restaurant?', 'transactions::merchant')}} = TRUE AND child_category = 'Restaurants &amp; Dining'\"\n                )\n            )\n            scm.abstracted_table_selects()\n            ```\n            Returns:\n            ```text\n            ('transactions', False, 'SELECT * FROM transactions WHERE TRUE AND child_category = \\'Restaurants &amp; Dining\\'')\n            ```\n        \"\"\"\n        # TODO: don't really know how to optimize with 'CASE' queries right now\n        if self.node.find(exp.Case):\n            return\n        # If we don't have an ingredient at the top-level, we can safely ignore\n        elif (\n            len(\n                list(\n                    get_scope_nodes(\n                        root=self.root,\n                        nodetype=exp.BlendSQLFunction,\n                        restrict_scope=True,\n                    ),\n                )\n            )\n            == 0\n        ):\n            return\n\n        self._gather_alias_mappings()\n        abstracted_query = self.node.transform(transform.set_ingredient_nodes_to_true)\n        # Special condition: If we *only* have an ingredient in the top-level `SELECT` clause\n        # ... then we should execute entire rest of SQL first and assign to temporary session table.\n        # Example: \"\"\"SELECT w.title, w.\"designer ( s )\", {{LLMMap('How many animals are in this image?', 'images::title')}}\n        #         FROM images JOIN w ON w.title = images.title\n        #         WHERE \"designer ( s )\" = 'georgia gerber'\"\"\"\n        # Below, we need `self.node.find(exp.Table)` in case we get a QAIngredient on its own\n        #   E.g. `SELECT A() AS _col_0` cases should be ignored\n        if (\n            self.node.find(exp.Table)\n            and check.ingredients_only_in_top_select(self.node)\n            and not check.ingredient_alias_in_query_body(self.node)\n        ):\n            for (\n                tablename,\n                columnnames,\n            ) in self.columns_referenced_by_ingredients.items():\n                yield (\n                    self.alias_to_tablename.get(tablename, tablename),\n                    self.node.find(exp.Join) is not None,\n                    set_select_to(abstracted_query, tablename, columnnames).sql(\n                        dialect=self.dialect\n                    ),\n                )\n            return\n\n        # Base case is below\n        abstracted_query = abstracted_query.transform(\n            transform.remove_nodetype,\n            (exp.Order, exp.Limit, exp.Group, exp.Offset, exp.Having),\n        )\n        # If our previous subquery has an ingredient, we can't optimize with subquery condition\n        # So, remove this subquery constraint and run\n        if self.prev_subquery_has_ingredient:\n            abstracted_query = abstracted_query.transform(\n                transform.maybe_set_subqueries_to_true\n            )\n        # Happens with {{LLMQA()}} cases, where we get 'SELECT *'\n        if abstracted_query.find(exp.Table) is None:\n            return\n        # Check here to see if we have no other predicates other than 'WHERE TRUE'\n        # There's no point in creating a temporary table in this situation\n        where_node = abstracted_query.find(exp.Where)\n        join_node = abstracted_query.find(exp.Join)\n        # If we have a join_node that's a cross join ('JOIN \"colors\" ON TRUE'),\n        #   this was likely created by a LLMJoin ingredient.\n        #   We don't need to create temp tables for these.\n        # TODO: This cross join is inefficient, make it a union\n        is_cross_join = lambda node: node.args.get(\"on\", None) == exp.true()\n        ignore_join = bool(not join_node or is_cross_join(join_node))\n        if where_node and ignore_join:\n            if where_node.args[\"this\"] == exp.true():\n                return\n            elif isinstance(where_node.args[\"this\"], exp.Column):\n                return\n            elif check.all_terminals_are_true(where_node):\n                return\n        elif where_node is None and not ignore_join:\n            return\n        for tablename, columnnames in self.columns_referenced_by_ingredients.items():\n            # TODO: execute query once, and then separate out the results to their respective tables\n            yield (\n                self.alias_to_tablename.get(tablename, tablename),\n                self.node.find(exp.Join) is not None,\n                set_select_to(abstracted_query, tablename, columnnames).sql(\n                    dialect=self.dialect\n                ),\n            )\n        return\n\n    def _gather_alias_mappings(\n        self,\n    ) -&gt; t.Generator[t.Tuple[str, exp.Select], None, None]:\n        \"\"\"For each table in the select query, generates a new query\n            selecting all columns with the given predicates (Relationships like x = y, x &gt; 1, x &gt;= y).\n\n        Args:\n            node: The exp.Select node containing the query to extract table_star queries for\n\n        Returns:\n            table_star_queries: Generator with (tablename, exp.Select). The exp.Select is the table_star query\n\n        Examples:\n            ```sql\n            SELECT \"Run Date\", Account, Action, ROUND(\"Amount ($)\", 2) AS 'Total Dividend Payout ($$)', Name\n                FROM account_history\n                LEFT JOIN constituents ON account_history.Symbol = constituents.Symbol\n                WHERE constituents.Sector = 'Information Technology'\n                AND lower(Action) like \"%dividend%\"\n            ```\n        \"\"\"\n        # Use `scope` to get all unique tablenodes in ast\n        tablenodes = set(\n            list(\n                get_scope_nodes(nodetype=exp.Table, root=self.root, restrict_scope=True)\n            )\n        )\n        # aliasnodes catch instances where we do something like\n        #   `SELECT (SELECT * FROM x) AS w`\n        curr_alias_to_tablename = {}\n        curr_alias_to_subquery = {}\n        subquery_node = self.node.find(exp.Subquery)\n        if subquery_node is not None:\n            # Make a note here: we need to create a new table with the name of the alias,\n            #   and set to results of this subquery\n            alias = None\n            if \"alias\" in subquery_node.args:\n                alias = subquery_node.args[\"alias\"]\n            if alias is None:\n                # Try to get from parent\n                parent_node = subquery_node.parent\n                if parent_node is not None:\n                    if \"alias\" in parent_node.args:\n                        alias = parent_node.args[\"alias\"]\n            if alias is not None:\n                if not any(x.name == alias.name for x in tablenodes):\n                    tablenodes.add(exp.Table(this=exp.Identifier(this=alias.name)))\n                curr_alias_to_subquery = {alias.name: subquery_node.args[\"this\"]}\n        for tablenode in tablenodes:\n            # Check to be sure this is in the top-level `SELECT`\n            if check.in_subquery(tablenode):\n                continue\n            # Check to see if we have a table alias\n            # e.g. `SELECT a FROM table AS w`\n            table_alias_node = tablenode.find(exp.TableAlias)\n            if table_alias_node is not None:\n                curr_alias_to_tablename = {table_alias_node.name: tablenode.name}\n            self.alias_to_tablename |= curr_alias_to_tablename\n            self.tablename_to_alias |= {\n                v: k for k, v in curr_alias_to_tablename.items()\n            }\n            self.alias_to_subquery |= curr_alias_to_subquery\n\n    def infer_gen_constraints(\n        self, function_node: exp.Expression, schema: dict, alias_to_tablename: dict\n    ) -&gt; dict:\n        \"\"\"Given syntax of BlendSQL query, infers a regex pattern (if possible) to guide\n            downstream Model generations.\n\n        For example:\n\n        ```sql\n        SELECT * FROM w WHERE {{LLMMap('Is this true?', 'w::colname')}}\n        ```\n\n        We can infer given the structure above that we expect `LLMMap` to return a boolean.\n        This function identifies that.\n\n        Arguments:\n            indices: The string indices pointing to the span within the overall BlendSQL query\n                containing our ingredient in question.\n\n        Returns:\n            dict, with keys:\n\n                - return_type\n                    - 'boolean' | 'integer' | 'float' | 'string'\n\n                - regex: regular expression pattern lambda to use in constrained decoding with Model\n                    - See `create_regex` for more info on these regex lambdas\n\n                - options: Optional str default to pass to `options` argument in a QAIngredient\n                    - Will have the form '{table}.{column}'\n        \"\"\"\n        added_kwargs: t.Dict[str, t.Any] = {}\n        if isinstance(function_node.parent, exp.Select):\n            # We don't want to traverse up in cases of `SELECT {{A()}} FROM table WHERE x &lt; y`\n            parent_node = function_node\n        else:\n            parent_node = function_node.parent\n        predicate_literals: t.List[str] = []\n        quantifier: QuantifierType = None\n\n        # Check for instances like `{column} = {QAIngredient}`\n        # where we can infer the space of possible options for QAIngredient\n        if isinstance(parent_node, (exp.EQ, exp.In)):\n            if isinstance(parent_node.args[\"this\"], exp.Column):\n                if \"table\" not in parent_node.args[\"this\"].args:\n                    if not isinstance(parent_node, exp.BlendSQLFunction):\n                        logger.debug(\n                            f\"When inferring `options` in infer_gen_kwargs, encountered column node with \"\n                            \"no table specified!\\nShould probably mark `schema_qualify` arg as True\"\n                        )\n                else:\n                    # This is valid for a default `options` set\n                    added_kwargs[\"options\"] = ColumnRef(\n                        f\"{parent_node.args['this'].args['table'].name}.{parent_node.args['this'].args['this'].name}\"\n                    )\n\n        output_type = None\n        # First check - is this predicate referencing an existing column with a non-TEXT datatype?\n        # If so, we adopt that type as our generation\n        column_in_predicate = parent_node.find(exp.Column)\n        if column_in_predicate is not None:\n            tablename = alias_to_tablename.get(\n                column_in_predicate.table, column_in_predicate.table\n            )\n            native_db_type = schema.get(tablename, {}).get(\n                column_in_predicate.this.name, None\n            )\n            if native_db_type is not None:\n                if native_db_type in DB_TYPE_TO_STR:\n                    resolved_type = DB_TYPE_TO_STR[native_db_type]\n                    if resolved_type != \"str\":\n                        output_type = STR_TO_DATATYPE[DB_TYPE_TO_STR[native_db_type]]\n                        logger.debug(\n                            Fore.LIGHTBLACK_EX\n                            + f\"The column in this predicate (`{column_in_predicate.this.name}`) has type `{native_db_type}`, so using regex for {resolved_type}...\"\n                            + Fore.RESET\n                        )\n                else:\n                    logger.debug(\n                        Fore.YELLOW\n                        + f\"No type logic for native DB type {native_db_type}!\"\n                        + Fore.RESET\n                    )\n        if output_type is None:\n            if isinstance(parent_node, (exp.In, exp.Tuple, exp.Values)):\n                if isinstance(parent_node, (exp.Tuple, exp.Values)):\n                    added_kwargs[\"wrap_tuple_in_parentheses\"] = False\n                if isinstance(parent_node, exp.In):\n                    # If the ingredient is in the 2nd arg place\n                    # E.g. not `{{LLMMap()}} IN ('a', 'b')`\n                    # Only `column IN {{LLMQA()}}`\n                    # AST will look like:\n                    # In(\n                    #     this=Column(\n                    #         this=Identifier(this=name, quoted=False),\n                    #         table=Identifier(this=c, quoted=False)),\n                    #     field=BlendSQLFunction(\n                    #         this=A))\n                    field_val = parent_node.args.get(\"field\", None)\n                    if field_val is not None:\n                        if parent_node == field_val:\n                            quantifier = \"+\"\n                    if isinstance(field_val, exp.BlendSQLFunction):\n                        quantifier = \"+\"\n                else:\n                    quantifier = \"+\"\n            if parent_node is not None and parent_node.expression is not None:\n                # Get predicate args\n                predicate_literals = []\n                # Literals\n                predicate_literals.extend(\n                    [\n                        literal_eval(i.this) if not i.is_string else i.this\n                        for i in parent_node.expression.find_all(exp.Literal)\n                    ]\n                )\n                # Booleans\n                predicate_literals.extend(\n                    [\n                        i.args[\"this\"]\n                        for i in parent_node.expression.find_all(exp.Boolean)\n                    ]\n                )\n            # Try to infer output type given the literals we've been given\n            # E.g. {{LLMap()}} IN ('John', 'Parker', 'Adam')\n            if len(predicate_literals) &gt; 0:\n                logger.debug(\n                    Fore.LIGHTBLACK_EX\n                    + f\"Extracted predicate literals `{predicate_literals}`\"\n                    + Fore.RESET\n                )\n                if all(isinstance(x, bool) for x in predicate_literals):\n                    output_type = DataTypes.BOOL(quantifier)\n                elif all(isinstance(x, float) for x in predicate_literals):\n                    output_type = DataTypes.FLOAT(quantifier)\n                elif all(isinstance(x, int) for x in predicate_literals):\n                    output_type = DataTypes.INT(quantifier)\n                else:\n                    predicate_literals = [str(i) for i in predicate_literals]\n                    added_kwargs[\"return_type\"] = DataTypes.ANY(quantifier)\n                    if len(predicate_literals) == 1:\n                        predicate_literals = predicate_literals + [\n                            predicate_literals[0]\n                        ]\n                    added_kwargs[\"example_outputs\"] = predicate_literals\n                    return added_kwargs\n            elif len(predicate_literals) == 0 and isinstance(\n                parent_node,\n                (\n                    exp.Order,\n                    exp.Ordered,\n                    exp.AggFunc,\n                    exp.GT,\n                    exp.GTE,\n                    exp.LT,\n                    exp.LTE,\n                    exp.Sum,\n                ),\n            ):\n                output_type = DataTypes.NUMERIC(\n                    quantifier\n                )  # `Numeric` = `t.Union[int, float]`\n            elif quantifier:\n                # Fallback to a generic list datatype\n                output_type = DataTypes.STR(quantifier)\n        added_kwargs[\"return_type\"] = output_type\n        return added_kwargs\n\n    def sql(self):\n        return self.node.sql(dialect=self.dialect)\n</code></pre>"},{"location":"reference/query_optimization/#blendsql.parse.parse.SubqueryContextManager.abstracted_table_selects","title":"<code>abstracted_table_selects()</code>","text":"<p>For each table in a given query, generates a <code>SELECT *</code> query where all unneeded predicates are set to <code>TRUE</code>. We say <code>unneeded</code> in the sense that to minimize the data that gets passed to an ingredient, we don't need to factor in this operation at the moment.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <p>exp.Select node from which to construct abstracted versions of queries for each table.</p> required <p>Returns:</p> Name Type Description <code>abstracted_queries</code> <code>None</code> <p>Generator with (tablename, postprocess_columns, abstracted_query_str). postprocess_columns tells us if we potentially executed a query with a <code>JOIN</code>, and need to apply some extra post-processing.</p> <p>Examples:</p> <p><pre><code>scm = SubqueryContextManager(\n    node=_parse_one(\n        \"SELECT * FROM transactions WHERE {{Model('is this an italian restaurant?', 'transactions::merchant')}} = TRUE AND child_category = 'Restaurants &amp; Dining'\"\n    )\n)\nscm.abstracted_table_selects()\n</code></pre> Returns: <pre><code>('transactions', False, 'SELECT * FROM transactions WHERE TRUE AND child_category = 'Restaurants &amp; Dining'')\n</code></pre></p> Source code in <code>blendsql/parse/parse.py</code> <pre><code>def abstracted_table_selects(\n    self,\n) -&gt; t.Generator[t.Tuple[str, bool, str], None, None]:\n    \"\"\"For each table in a given query, generates a `SELECT *` query where all unneeded predicates\n    are set to `TRUE`.\n    We say `unneeded` in the sense that to minimize the data that gets passed to an ingredient,\n    we don't need to factor in this operation at the moment.\n\n    Args:\n        node: exp.Select node from which to construct abstracted versions of queries for each table.\n\n    Returns:\n        abstracted_queries: Generator with (tablename, postprocess_columns, abstracted_query_str).\n            postprocess_columns tells us if we potentially executed a query with a `JOIN`, and need to apply some extra post-processing.\n\n    Examples:\n        ```python\n        scm = SubqueryContextManager(\n            node=_parse_one(\n                \"SELECT * FROM transactions WHERE {{Model('is this an italian restaurant?', 'transactions::merchant')}} = TRUE AND child_category = 'Restaurants &amp; Dining'\"\n            )\n        )\n        scm.abstracted_table_selects()\n        ```\n        Returns:\n        ```text\n        ('transactions', False, 'SELECT * FROM transactions WHERE TRUE AND child_category = \\'Restaurants &amp; Dining\\'')\n        ```\n    \"\"\"\n    # TODO: don't really know how to optimize with 'CASE' queries right now\n    if self.node.find(exp.Case):\n        return\n    # If we don't have an ingredient at the top-level, we can safely ignore\n    elif (\n        len(\n            list(\n                get_scope_nodes(\n                    root=self.root,\n                    nodetype=exp.BlendSQLFunction,\n                    restrict_scope=True,\n                ),\n            )\n        )\n        == 0\n    ):\n        return\n\n    self._gather_alias_mappings()\n    abstracted_query = self.node.transform(transform.set_ingredient_nodes_to_true)\n    # Special condition: If we *only* have an ingredient in the top-level `SELECT` clause\n    # ... then we should execute entire rest of SQL first and assign to temporary session table.\n    # Example: \"\"\"SELECT w.title, w.\"designer ( s )\", {{LLMMap('How many animals are in this image?', 'images::title')}}\n    #         FROM images JOIN w ON w.title = images.title\n    #         WHERE \"designer ( s )\" = 'georgia gerber'\"\"\"\n    # Below, we need `self.node.find(exp.Table)` in case we get a QAIngredient on its own\n    #   E.g. `SELECT A() AS _col_0` cases should be ignored\n    if (\n        self.node.find(exp.Table)\n        and check.ingredients_only_in_top_select(self.node)\n        and not check.ingredient_alias_in_query_body(self.node)\n    ):\n        for (\n            tablename,\n            columnnames,\n        ) in self.columns_referenced_by_ingredients.items():\n            yield (\n                self.alias_to_tablename.get(tablename, tablename),\n                self.node.find(exp.Join) is not None,\n                set_select_to(abstracted_query, tablename, columnnames).sql(\n                    dialect=self.dialect\n                ),\n            )\n        return\n\n    # Base case is below\n    abstracted_query = abstracted_query.transform(\n        transform.remove_nodetype,\n        (exp.Order, exp.Limit, exp.Group, exp.Offset, exp.Having),\n    )\n    # If our previous subquery has an ingredient, we can't optimize with subquery condition\n    # So, remove this subquery constraint and run\n    if self.prev_subquery_has_ingredient:\n        abstracted_query = abstracted_query.transform(\n            transform.maybe_set_subqueries_to_true\n        )\n    # Happens with {{LLMQA()}} cases, where we get 'SELECT *'\n    if abstracted_query.find(exp.Table) is None:\n        return\n    # Check here to see if we have no other predicates other than 'WHERE TRUE'\n    # There's no point in creating a temporary table in this situation\n    where_node = abstracted_query.find(exp.Where)\n    join_node = abstracted_query.find(exp.Join)\n    # If we have a join_node that's a cross join ('JOIN \"colors\" ON TRUE'),\n    #   this was likely created by a LLMJoin ingredient.\n    #   We don't need to create temp tables for these.\n    # TODO: This cross join is inefficient, make it a union\n    is_cross_join = lambda node: node.args.get(\"on\", None) == exp.true()\n    ignore_join = bool(not join_node or is_cross_join(join_node))\n    if where_node and ignore_join:\n        if where_node.args[\"this\"] == exp.true():\n            return\n        elif isinstance(where_node.args[\"this\"], exp.Column):\n            return\n        elif check.all_terminals_are_true(where_node):\n            return\n    elif where_node is None and not ignore_join:\n        return\n    for tablename, columnnames in self.columns_referenced_by_ingredients.items():\n        # TODO: execute query once, and then separate out the results to their respective tables\n        yield (\n            self.alias_to_tablename.get(tablename, tablename),\n            self.node.find(exp.Join) is not None,\n            set_select_to(abstracted_query, tablename, columnnames).sql(\n                dialect=self.dialect\n            ),\n        )\n    return\n</code></pre>"},{"location":"reference/query_optimization/#blendsql.parse.parse.SubqueryContextManager.infer_gen_constraints","title":"<code>infer_gen_constraints(function_node, schema, alias_to_tablename)</code>","text":"<p>Given syntax of BlendSQL query, infers a regex pattern (if possible) to guide     downstream Model generations.</p> <p>For example:</p> <pre><code>SELECT * FROM w WHERE {{LLMMap('Is this true?', 'w::colname')}}\n</code></pre> <p>We can infer given the structure above that we expect <code>LLMMap</code> to return a boolean. This function identifies that.</p> <p>Parameters:</p> Name Type Description Default <code>indices</code> <p>The string indices pointing to the span within the overall BlendSQL query containing our ingredient in question.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>dict, with keys:</p> <ul> <li> <p>return_type</p> <ul> <li>'boolean' | 'integer' | 'float' | 'string'</li> </ul> </li> <li> <p>regex: regular expression pattern lambda to use in constrained decoding with Model</p> <ul> <li>See <code>create_regex</code> for more info on these regex lambdas</li> </ul> </li> <li> <p>options: Optional str default to pass to <code>options</code> argument in a QAIngredient</p> <ul> <li>Will have the form '{table}.{column}'</li> </ul> </li> </ul> Source code in <code>blendsql/parse/parse.py</code> <pre><code>def infer_gen_constraints(\n    self, function_node: exp.Expression, schema: dict, alias_to_tablename: dict\n) -&gt; dict:\n    \"\"\"Given syntax of BlendSQL query, infers a regex pattern (if possible) to guide\n        downstream Model generations.\n\n    For example:\n\n    ```sql\n    SELECT * FROM w WHERE {{LLMMap('Is this true?', 'w::colname')}}\n    ```\n\n    We can infer given the structure above that we expect `LLMMap` to return a boolean.\n    This function identifies that.\n\n    Arguments:\n        indices: The string indices pointing to the span within the overall BlendSQL query\n            containing our ingredient in question.\n\n    Returns:\n        dict, with keys:\n\n            - return_type\n                - 'boolean' | 'integer' | 'float' | 'string'\n\n            - regex: regular expression pattern lambda to use in constrained decoding with Model\n                - See `create_regex` for more info on these regex lambdas\n\n            - options: Optional str default to pass to `options` argument in a QAIngredient\n                - Will have the form '{table}.{column}'\n    \"\"\"\n    added_kwargs: t.Dict[str, t.Any] = {}\n    if isinstance(function_node.parent, exp.Select):\n        # We don't want to traverse up in cases of `SELECT {{A()}} FROM table WHERE x &lt; y`\n        parent_node = function_node\n    else:\n        parent_node = function_node.parent\n    predicate_literals: t.List[str] = []\n    quantifier: QuantifierType = None\n\n    # Check for instances like `{column} = {QAIngredient}`\n    # where we can infer the space of possible options for QAIngredient\n    if isinstance(parent_node, (exp.EQ, exp.In)):\n        if isinstance(parent_node.args[\"this\"], exp.Column):\n            if \"table\" not in parent_node.args[\"this\"].args:\n                if not isinstance(parent_node, exp.BlendSQLFunction):\n                    logger.debug(\n                        f\"When inferring `options` in infer_gen_kwargs, encountered column node with \"\n                        \"no table specified!\\nShould probably mark `schema_qualify` arg as True\"\n                    )\n            else:\n                # This is valid for a default `options` set\n                added_kwargs[\"options\"] = ColumnRef(\n                    f\"{parent_node.args['this'].args['table'].name}.{parent_node.args['this'].args['this'].name}\"\n                )\n\n    output_type = None\n    # First check - is this predicate referencing an existing column with a non-TEXT datatype?\n    # If so, we adopt that type as our generation\n    column_in_predicate = parent_node.find(exp.Column)\n    if column_in_predicate is not None:\n        tablename = alias_to_tablename.get(\n            column_in_predicate.table, column_in_predicate.table\n        )\n        native_db_type = schema.get(tablename, {}).get(\n            column_in_predicate.this.name, None\n        )\n        if native_db_type is not None:\n            if native_db_type in DB_TYPE_TO_STR:\n                resolved_type = DB_TYPE_TO_STR[native_db_type]\n                if resolved_type != \"str\":\n                    output_type = STR_TO_DATATYPE[DB_TYPE_TO_STR[native_db_type]]\n                    logger.debug(\n                        Fore.LIGHTBLACK_EX\n                        + f\"The column in this predicate (`{column_in_predicate.this.name}`) has type `{native_db_type}`, so using regex for {resolved_type}...\"\n                        + Fore.RESET\n                    )\n            else:\n                logger.debug(\n                    Fore.YELLOW\n                    + f\"No type logic for native DB type {native_db_type}!\"\n                    + Fore.RESET\n                )\n    if output_type is None:\n        if isinstance(parent_node, (exp.In, exp.Tuple, exp.Values)):\n            if isinstance(parent_node, (exp.Tuple, exp.Values)):\n                added_kwargs[\"wrap_tuple_in_parentheses\"] = False\n            if isinstance(parent_node, exp.In):\n                # If the ingredient is in the 2nd arg place\n                # E.g. not `{{LLMMap()}} IN ('a', 'b')`\n                # Only `column IN {{LLMQA()}}`\n                # AST will look like:\n                # In(\n                #     this=Column(\n                #         this=Identifier(this=name, quoted=False),\n                #         table=Identifier(this=c, quoted=False)),\n                #     field=BlendSQLFunction(\n                #         this=A))\n                field_val = parent_node.args.get(\"field\", None)\n                if field_val is not None:\n                    if parent_node == field_val:\n                        quantifier = \"+\"\n                if isinstance(field_val, exp.BlendSQLFunction):\n                    quantifier = \"+\"\n            else:\n                quantifier = \"+\"\n        if parent_node is not None and parent_node.expression is not None:\n            # Get predicate args\n            predicate_literals = []\n            # Literals\n            predicate_literals.extend(\n                [\n                    literal_eval(i.this) if not i.is_string else i.this\n                    for i in parent_node.expression.find_all(exp.Literal)\n                ]\n            )\n            # Booleans\n            predicate_literals.extend(\n                [\n                    i.args[\"this\"]\n                    for i in parent_node.expression.find_all(exp.Boolean)\n                ]\n            )\n        # Try to infer output type given the literals we've been given\n        # E.g. {{LLMap()}} IN ('John', 'Parker', 'Adam')\n        if len(predicate_literals) &gt; 0:\n            logger.debug(\n                Fore.LIGHTBLACK_EX\n                + f\"Extracted predicate literals `{predicate_literals}`\"\n                + Fore.RESET\n            )\n            if all(isinstance(x, bool) for x in predicate_literals):\n                output_type = DataTypes.BOOL(quantifier)\n            elif all(isinstance(x, float) for x in predicate_literals):\n                output_type = DataTypes.FLOAT(quantifier)\n            elif all(isinstance(x, int) for x in predicate_literals):\n                output_type = DataTypes.INT(quantifier)\n            else:\n                predicate_literals = [str(i) for i in predicate_literals]\n                added_kwargs[\"return_type\"] = DataTypes.ANY(quantifier)\n                if len(predicate_literals) == 1:\n                    predicate_literals = predicate_literals + [\n                        predicate_literals[0]\n                    ]\n                added_kwargs[\"example_outputs\"] = predicate_literals\n                return added_kwargs\n        elif len(predicate_literals) == 0 and isinstance(\n            parent_node,\n            (\n                exp.Order,\n                exp.Ordered,\n                exp.AggFunc,\n                exp.GT,\n                exp.GTE,\n                exp.LT,\n                exp.LTE,\n                exp.Sum,\n            ),\n        ):\n            output_type = DataTypes.NUMERIC(\n                quantifier\n            )  # `Numeric` = `t.Union[int, float]`\n        elif quantifier:\n            # Fallback to a generic list datatype\n            output_type = DataTypes.STR(quantifier)\n    added_kwargs[\"return_type\"] = output_type\n    return added_kwargs\n</code></pre>"},{"location":"reference/smoothie/","title":"Smoothie","text":""},{"location":"reference/smoothie/#smoothie","title":"Smoothie","text":"<p>The <code>Smoothie</code> object defines the output of an executed BlendSQL script.</p> Source code in <code>blendsql/smoothie.py</code> <pre><code>@dataclass\nclass Smoothie:\n    df: pd.DataFrame = field()\n    meta: SmoothieMeta = field()\n\n    def __post_init__(self):\n        self.df = PrettyDataFrame(self.df)\n\n    def summary(self):\n        s = \"-------------------------------- SUMMARY --------------------------------\\n\"\n        s += self.meta.query + \"\\n\"\n        s += tabulate(\n            pd.DataFrame(\n                {\n                    \"Time (s)\": self.meta.process_time_seconds\n                    if hasattr(self.meta, \"process_time_seconds\")\n                    else \"N.A.\",\n                    \"# Generation Calls\": self.meta.num_generation_calls,\n                    \"Prompt Tokens\": self.meta.prompt_tokens,\n                    \"Completion Tokens\": self.meta.completion_tokens,\n                },\n                index=[0],\n            )\n        )\n        return s\n\n    def __str__(self):\n        return self.summary()\n</code></pre> Source code in <code>blendsql/smoothie.py</code> <pre><code>@dataclass\nclass SmoothieMeta:\n    num_values_passed: int = (\n        field()\n    )  # Number of values passed to a Map/Join/QA ingredient\n    num_generation_calls: int = field()  # Number of generation calls made to the model\n    prompt_tokens: int = field()\n    completion_tokens: int = field()\n    prompts: t.List[dict] = field()  # Log of prompts submitted to model\n    raw_prompts: t.List[str] = field()\n    ingredients: t.Iterable[t.Type[Ingredient]] = field()\n    query: str = field()\n    db_url: str = field()\n    contains_ingredient: bool = field(default=True)\n    process_time_seconds: float = field(default=\"N.A.\")\n</code></pre>"},{"location":"reference/string-ingredient/","title":"StringIngredient","text":"<p>This is the simplest type of ingredient. This will output a string to be placed directly into the SQL query.</p> <p>We have the <code>DT</code> function as a builtin StringIngredient.</p> <pre><code>SELECT merchant FROM transactions\n    WHERE {{DT('transactions::date', start='q2')}}\n</code></pre> <p>This will call a Python function that uses <code>datetime</code> to interpret the absolute dates which the relative phrase \"q2\" most likely refers to.</p> <p>We do not create any new tables or perform any joins with a StringIngredient; instead, we simply get the following SQL query.</p> <p>[!NOTE] The below SQL interpretation of the <code>DT</code> function assumes we're calling it in December, 2022. The phrase 'q2' will be interpreted differently in, say, March 1998.</p> <pre><code>SELECT merchant FROM transactions\n    WHERE date &gt; '2022-09-30' AND date &lt; '2022-12-01'\n</code></pre>"},{"location":"reference/technical_walkthrough/","title":"Technical walkthrough","text":"<p>All the below logic can be found in the <code>blend()</code> function from <code>blendsql/blendsql.py</code>.</p>"},{"location":"reference/technical_walkthrough/#example","title":"Example","text":"<p>We can take the following query as an example.</p> <pre><code>--- 'Show me dividends from tech companies that manufacture cell phones'\nSELECT \"Run Date\", Account, Action, ROUND(\"Amount ($)\", 2) AS 'Total Dividend Payout ($$)', Name\n    FROM account_history\n    LEFT JOIN constituents ON account_history.Symbol = constituents.Symbol\n    WHERE constituents.Sector = 'Information Technology'\n    AND {{\n           LLM(\n               'does this company manufacture cell phones?',\n               'constituents::Name',\n            )\n    }} = 1\n    AND lower(account_history.Action) like \"%dividend%\"\n</code></pre>"},{"location":"reference/technical_walkthrough/#1-generate-a-session-uuid","title":"1) Generate a Session UUID","text":"<p>This uuid allows us to create new temporary tables containing the output of our BlendSQL functions rather than overwriting the original, underlying SQL tables.</p> <pre><code>import uuid \n\nsession_uuid = str(uuid.uuid4())[:5]\n</code></pre>"},{"location":"reference/technical_walkthrough/#2-identify-all-subqueries","title":"2) Identify All Subqueries","text":"<p>Here, we define subqueries as any select statement from a single table. These may or may not have their own <code>SELECT</code> clause.</p> <p>In our example, we only have a single query.</p>"},{"location":"reference/technical_walkthrough/#3-for-each-table-generate-select-statements","title":"3) For Each Table, Generate Select Statements","text":"<p>Iterating through our subqueries, we now need to write each table reference as its own <code>SELECT</code> statement.</p> <p>To do this, we iterate through each table and get the following queries.</p> <p>Notice how in the <code>account_history</code> query, we change the specific columns to the <code>*</code>, so we get everything.</p> <pre><code>SELECT * FROM account_history\n    WHERE lower(account_history.Action) like \"%dividend%\"\n</code></pre> <pre><code>SELECT * FROM constituents\n    WHERE constituents.Sector = 'Information Technology'\n    AND {{\n           LLM(\n               'does this company manufacture cell phones?',\n               'constituents::Name',\n            )\n    }} = 1\n</code></pre>"},{"location":"reference/technical_walkthrough/#4-abstract-away-selects","title":"4) Abstract Away Selects","text":"<p>In our <code>constituents</code> subquery, we have an expensive LLM operation.</p> <p>In order to make sure we pass minimal required data to our BlendSQL ingredients while still honoring the SQL logic, we abstract away external functions to <code>True</code> to calculate the theoretical upper bound of data that might get returned.</p> <pre><code>-- Abstracted query\nSELECT * FROM constituents\n    WHERE constituents.Sector = 'Information Technology'\n    AND TRUE\n</code></pre> <p>We execute each of these queries and assign them to new temporary tables, <code>f\"{session_uuid}_{tablename}_{subquery_idx}\"</code>.</p>"},{"location":"reference/technical_walkthrough/#4-execute-blendsql-ingredients-on-our-new-tables","title":"4) Execute BlendSQL Ingredients on our New Tables","text":"<p>Now we can execute some external functions.</p> <p>For example, if we have a session_id of '1234': <pre><code>SELECT Symbol FROM \"1234_constituents_0\" \n    WHERE sector = 'Information Technology' \n    AND {{\n            LLM(\n                'does this company manufacture cell phones?', \n                'constituents::Name'\n            )\n        }} = 1\n</code></pre></p> <p>The table \"1234_constituents_0\" now only has those entries where <code>sector = 'Information Technology'</code>. This minimizes the data that the <code>{{LLM()}}</code> call actually needs to process.</p> <p>Once we've executed our functions, we now have a table with a new column, <code>'does this company manufacture cell phones?'</code>.</p> <p>We do a left join with the original <code>constituents</code> table to create the new session table \"1234_constituents\". </p> <p>Then, we can move to the next subquery. In this case, there is no BlendSQL ingredient, so we're done with our processing.</p>"},{"location":"reference/technical_walkthrough/#5-execute-our-final-sql-query","title":"5) Execute our Final SQL Query","text":"<p>At the end of our processing, we have the underlying SQL tables and query in a state that we can execute it like any other SQLite script. </p> <pre><code>SELECT \"Run Date\", Account, Action, ROUND(\"Amount ($)\", 2) AS 'Total Dividend Payout ($$)', Name\n    FROM account_history\n    LEFT JOIN '1c0b_constituents' ON account_history.Symbol = '1c0b_constituents'.Symbol\n    WHERE '1c0b_constituents'.Sector = 'Information Technology'\n    AND {{\n           LLM(\n               'does this company manufacture cell phones?',\n               'constituents::Name',\n            )\n    }} = 1\n    AND lower(account_history.Action) like \"%dividend%\"\n</code></pre> <p>Notice how <code>account_history</code> was not modified by a session_id, but <code>constituents</code> was. This is because the logic of filtering by <code>LIKE %dividend%</code> can just be done using raw SQL on the original table, we don't need any complicated BlendSQL processing.</p>"},{"location":"reference/databases/databases/","title":"Databases","text":"<p>Since BlendSQL relies on the package sqlglot for query optimization (which supports a wide variety of SQL dialects) and the notion of temporary tables, it can easily integrate with many different SQL DBMS. </p> <p>Currently, the following are supported.</p> <ul> <li>SQLite</li> <li>PostgreSQL</li> <li>DuckDB</li> <li>Pandas</li> </ul> <p>               Bases: <code>ABC</code></p> Source code in <code>blendsql/db/database.py</code> <pre><code>class Database(ABC):\n    db_url: t.Union[URL, str] = attrib()\n    lazy_tables: LazyTables = LazyTables()\n\n    def __str__(self):\n        return f\"{self.__class__} @ {self.db_url}\"\n\n    def __repr__(self):\n        return f\"{self.__class__} @ {self.db_url}\"\n\n    @abstractmethod\n    def _reset_connection(self) -&gt; None:\n        \"\"\"Reset connection, so that temp tables are cleared.\"\"\"\n        ...\n\n    @abstractmethod\n    def has_temp_table(self, tablename: str) -&gt; bool:\n        \"\"\"Temp tables are stored in different locations, depending on\n        the DBMS. For example, sqlite puts them in `sqlite_temp_master`,\n        and postgres goes in the main `information_schema.tables` with a\n        'pg_temp' prefix.\n        \"\"\"\n        ...\n\n    @property\n    @abstractmethod\n    def sqlglot_schema(self) -&gt; dict:\n        \"\"\"Returns database schema as a dictionary, in the format that\n        sqlglot.optimizer expects.\n\n        Examples:\n            ```python\n            db.sqlglot_schema\n            &gt; {\"x\": {\"A\": \"INT\", \"B\": \"INT\", \"C\": \"INT\", \"D\": \"INT\", \"Z\": \"STRING\"}}\n            ```\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def tables(self) -&gt; t.List[str]:\n        \"\"\"Get all table names associated with a database.\"\"\"\n        ...\n\n    @abstractmethod\n    def iter_columns(self, tablename: str) -&gt; t.Generator[str, None, None]:\n        \"\"\"Yield all column names associated with a tablename.\"\"\"\n        ...\n\n    @abstractmethod\n    def schema_string(self, use_tables: t.Optional[t.Collection[str]] = None) -&gt; str:\n        \"\"\"Converts the database to a series of 'CREATE TABLE' statements.\"\"\"\n\n    @abstractmethod\n    def to_temp_table(self, df: pd.DataFrame, tablename: str):\n        \"\"\"Write the given pandas dataframe as a temp table 'tablename'.\"\"\"\n        ...\n\n    @abstractmethod\n    def execute_to_df(\n        self, query: str, params: t.Optional[dict] = None\n    ) -&gt; pd.DataFrame:\n        \"\"\"\n        Execute the given query and return results as dataframe.\n\n        Args:\n            query: The SQL query to execute. Can use `named` paramstyle from PEP 249\n                https://peps.python.org/pep-0249/#paramstyle\n            params: Dict containing mapping from name to value.\n\n        Returns:\n            pd.DataFrame\n\n        Examples:\n            ```python\n            from blendsql.db import SQLite\n            db = SQLite(\"./path/to/database.db\")\n            db.execute_query(\"SELECT * FROM t WHERE c = :v\", {\"v\": \"value\"})\n            ```\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def execute_to_list(self, query: str, to_type: t.Callable = lambda x: x) -&gt; list:\n        \"\"\"A lower-level execute method that doesn't use the pandas processing logic.\n        Returns results as a list.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"reference/databases/duckdb/","title":"DuckDB","text":"<p>Installation</p> <p>You need to install the <code>duckdb</code> library to use this in blendsql.</p> <p>               Bases: <code>Database</code></p> <p>An in-memory DuckDB database connection. Can be initialized via any of the available class methods.</p> <p>Examples:</p> <pre><code>from blendsql.db import DuckDB\ndb = DuckDB.from_pandas(\n    pd.DataFrame(\n        {\n            \"name\": [\"John\", \"Parker\"],\n            \"age\": [12, 26]\n        },\n    )\n)\n# Or, load multiple dataframes\ndb = DuckDB.from_pandas(\n    {\n        \"students\": pd.DataFrame(\n            {\n                \"name\": [\"John\", \"Parker\"],\n                \"age\": [12, 26]\n            },\n        ),\n        \"classes\": pd.DataFrame(\n            {\n                \"class\": [\"Physics 101\", \"Chemistry\"],\n                \"size\": [50, 32]\n            },\n        ),\n    }\n)\n</code></pre> Source code in <code>blendsql/db/duckdb.py</code> <pre><code>@attrs\nclass DuckDB(Database):\n    \"\"\"An in-memory DuckDB database connection.\n    Can be initialized via any of the available class methods.\n\n    Examples:\n        ```python\n        from blendsql.db import DuckDB\n        db = DuckDB.from_pandas(\n            pd.DataFrame(\n                {\n                    \"name\": [\"John\", \"Parker\"],\n                    \"age\": [12, 26]\n                },\n            )\n        )\n        # Or, load multiple dataframes\n        db = DuckDB.from_pandas(\n            {\n                \"students\": pd.DataFrame(\n                    {\n                        \"name\": [\"John\", \"Parker\"],\n                        \"age\": [12, 26]\n                    },\n                ),\n                \"classes\": pd.DataFrame(\n                    {\n                        \"class\": [\"Physics 101\", \"Chemistry\"],\n                        \"size\": [50, 32]\n                    },\n                ),\n            }\n        )\n        ```\n    \"\"\"\n\n    # Can be either a dict from name -&gt; pd.DataFrame\n    # or, a single pd.DataFrame object\n    con: \"DuckDBPyConnection\" = attrib()\n    db_url: str = attrib()\n\n    # We use below to track which tables we should drop on '_reset_connection'\n    temp_tables: t.Set[str] = set()\n\n    @classmethod\n    def from_pandas(\n        cls,\n        data: t.Union[t.Dict[str, pd.DataFrame], pd.DataFrame],\n        tablename: str = \"w\",\n    ):\n        if not _has_duckdb:\n            raise ImportError(\n                \"Please install duckdb with `pip install duckdb`!\"\n            ) from None\n        import duckdb\n\n        con = duckdb.connect(database=\":memory:\")\n        if isinstance(data, pd.DataFrame):\n            db_url = \"Local pandas table\"\n            # I don't really understand the scope of duckdb's replacement scan here\n            # I assign the underlying data to _df, since passing self.data doesn't work\n            # in the self.con.sql call.\n            _df = data\n            con.sql(f\"CREATE TABLE {tablename} AS SELECT * FROM _df\")\n\n        elif isinstance(data, dict):\n            db_url = f\"Local pandas tables {', '.join(data.keys())}\"\n            for tablename, _df in data.items():\n                # Note: duckdb.sql connects to the default in-memory database connection\n                con.sql(f\"CREATE TABLE {tablename} AS SELECT * FROM _df\")\n        else:\n            raise ValueError(\n                \"Unknown datatype passed to `Pandas`!\\nWe expect either a single dataframe, or a dictionary mapping many tables from {tablename: df}\"\n            )\n        return cls(con=con, db_url=db_url)\n\n    @classmethod\n    def from_sqlite(cls, db_url: str):\n        \"\"\"TODO: any point in this if we already have dedicated SQLite databse class\n        and it's faster?\n        \"\"\"\n        if not _has_duckdb:\n            raise ImportError(\n                \"Please install duckdb with `pip install duckdb&lt;1`!\"\n            ) from None\n        import duckdb\n\n        con = duckdb.connect(database=\":memory:\")\n        db_url = str(Path(db_url).resolve())\n        con.sql(\"INSTALL sqlite;\")\n        con.sql(\"LOAD sqlite;\")\n        con.sql(f\"ATTACH '{db_url}' AS sqlite_db (TYPE sqlite);\")\n        con.sql(\"USE sqlite_db\")\n        return cls(con=con, db_url=db_url)\n\n    def _reset_connection(self):\n        \"\"\"Reset connection, so that temp tables are cleared.\"\"\"\n        for tablename in self.temp_tables:\n            self.con.sql(f'DROP TABLE IF EXISTS \"{tablename}\"')\n        self.temp_tables = set()\n\n    def has_temp_table(self, tablename: str) -&gt; bool:\n        return tablename in self.execute_to_list(\"SHOW TABLES\")\n\n    @cached_property\n    def sqlglot_schema(self) -&gt; dict:\n        \"\"\"Returns database schema as a dictionary, in the format that\n        sqlglot.optimizer expects.\n\n        Examples:\n            ```python\n            db.sqlglot_schema\n            &gt; {\"x\": {\"A\": \"INT\", \"B\": \"INT\", \"C\": \"INT\", \"D\": \"INT\", \"Z\": \"STRING\"}}\n            ```\n        \"\"\"\n        schema: t.Dict[str, dict] = {}\n        for tablename in self.tables():\n            schema[tablename] = {}\n            for column_name, column_type in self.con.sql(\n                f\"SELECT column_name, column_type FROM (DESCRIBE {tablename})\"\n            ).fetchall():\n                schema[tablename][column_name] = column_type\n        return schema\n\n    def tables(self) -&gt; t.List[str]:\n        return self.execute_to_list(\"SHOW TABLES;\")\n\n    def iter_columns(self, tablename: str) -&gt; t.Generator[str, None, None]:\n        for row in self.con.sql(\n            f\"SELECT column_name FROM (DESCRIBE {tablename})\"\n        ).fetchall():\n            yield row[0]\n\n    def schema_string(self, use_tables: t.Optional[t.Collection[str]] = None) -&gt; str:\n        \"\"\"Converts the database to a series of 'CREATE TABLE' statements.\"\"\"\n        # TODO\n        return None\n\n    def to_temp_table(self, df: pd.DataFrame, tablename: str):\n        \"\"\"Technically, when duckdb is run in-memory (as is the default),\n        all created tables are temporary tables (since they expire at the\n        end of the session). So, we don't really need to insert 'TEMP' keyword here?\n        \"\"\"\n        # DuckDB has this cool 'CREATE OR REPLACE' syntax\n        # https://duckdb.org/docs/sql/statements/create_table.html#create-or-replace\n        create_table_stmt = (\n            f'CREATE OR REPLACE TEMP TABLE \"{tablename}\" AS SELECT * FROM df'\n        )\n        logger.debug(Fore.LIGHTBLACK_EX + create_table_stmt + Fore.RESET)\n        self.con.sql(create_table_stmt)\n        self.temp_tables.add(tablename)\n        logger.debug(Fore.CYAN + f\"Created temp table {tablename}\" + Fore.RESET)\n\n    def execute_to_df(\n        self, query: str, params: t.Optional[dict] = None\n    ) -&gt; pd.DataFrame:\n        \"\"\"On params with duckdb: https://github.com/duckdb/duckdb/issues/9853#issuecomment-1832732933\"\"\"\n        return self.con.sql(query).df()\n\n    def execute_to_list(\n        self, query: str, to_type: t.Optional[t.Callable] = lambda x: x\n    ) -&gt; list:\n        res = []\n        for row in self.con.sql(query).fetchall():\n            res.append(to_type(row[0]))\n        return res\n</code></pre>"},{"location":"reference/databases/duckdb/#blendsql.db.duckdb.DuckDB.from_pandas","title":"<code>from_pandas(data, tablename='w')</code>  <code>classmethod</code>","text":"Source code in <code>blendsql/db/duckdb.py</code> <pre><code>@classmethod\ndef from_pandas(\n    cls,\n    data: t.Union[t.Dict[str, pd.DataFrame], pd.DataFrame],\n    tablename: str = \"w\",\n):\n    if not _has_duckdb:\n        raise ImportError(\n            \"Please install duckdb with `pip install duckdb`!\"\n        ) from None\n    import duckdb\n\n    con = duckdb.connect(database=\":memory:\")\n    if isinstance(data, pd.DataFrame):\n        db_url = \"Local pandas table\"\n        # I don't really understand the scope of duckdb's replacement scan here\n        # I assign the underlying data to _df, since passing self.data doesn't work\n        # in the self.con.sql call.\n        _df = data\n        con.sql(f\"CREATE TABLE {tablename} AS SELECT * FROM _df\")\n\n    elif isinstance(data, dict):\n        db_url = f\"Local pandas tables {', '.join(data.keys())}\"\n        for tablename, _df in data.items():\n            # Note: duckdb.sql connects to the default in-memory database connection\n            con.sql(f\"CREATE TABLE {tablename} AS SELECT * FROM _df\")\n    else:\n        raise ValueError(\n            \"Unknown datatype passed to `Pandas`!\\nWe expect either a single dataframe, or a dictionary mapping many tables from {tablename: df}\"\n        )\n    return cls(con=con, db_url=db_url)\n</code></pre>"},{"location":"reference/databases/duckdb/#blendsql.db.duckdb.DuckDB.from_sqlite","title":"<code>from_sqlite(db_url)</code>  <code>classmethod</code>","text":"<p>TODO: any point in this if we already have dedicated SQLite databse class and it's faster?</p> Source code in <code>blendsql/db/duckdb.py</code> <pre><code>@classmethod\ndef from_sqlite(cls, db_url: str):\n    \"\"\"TODO: any point in this if we already have dedicated SQLite databse class\n    and it's faster?\n    \"\"\"\n    if not _has_duckdb:\n        raise ImportError(\n            \"Please install duckdb with `pip install duckdb&lt;1`!\"\n        ) from None\n    import duckdb\n\n    con = duckdb.connect(database=\":memory:\")\n    db_url = str(Path(db_url).resolve())\n    con.sql(\"INSTALL sqlite;\")\n    con.sql(\"LOAD sqlite;\")\n    con.sql(f\"ATTACH '{db_url}' AS sqlite_db (TYPE sqlite);\")\n    con.sql(\"USE sqlite_db\")\n    return cls(con=con, db_url=db_url)\n</code></pre>"},{"location":"reference/databases/pandas/","title":"Pandas","text":"<p>This is just a wrapper over the <code>DuckDB.from_pandas</code> class method. Makes it more intuitive to do a <code>from blendsql.db import Pandas</code>, for those developers who might not know DuckDB supports pandas dataframes.</p> <p>Examples:</p> <pre><code>from blendsql.db import Pandas\ndb = Pandas(\n    pd.DataFrame(\n        {\n            \"name\": [\"John\", \"Parker\"],\n            \"age\": [12, 26]\n        },\n    )\n)\n# Or, load multiple dataframes\ndb = Pandas(\n    {\n        \"students\": pd.DataFrame(\n            {\n                \"name\": [\"John\", \"Parker\"],\n                \"age\": [12, 26]\n            },\n        ),\n        \"classes\": pd.DataFrame(\n            {\n                \"class\": [\"Physics 101\", \"Chemistry\"],\n                \"size\": [50, 32]\n            },\n        ),\n    }\n)\n</code></pre> Source code in <code>blendsql/db/pandas.py</code> <pre><code>def Pandas(\n    data: t.Union[t.Dict[str, pd.DataFrame], pd.DataFrame], tablename: str = \"w\"\n) -&gt; DuckDB:\n    \"\"\"This is just a wrapper over the `DuckDB.from_pandas` class method.\n    Makes it more intuitive to do a `from blendsql.db import Pandas`, for those\n    developers who might not know DuckDB supports pandas dataframes.\n\n    Examples:\n        ```python\n        from blendsql.db import Pandas\n        db = Pandas(\n            pd.DataFrame(\n                {\n                    \"name\": [\"John\", \"Parker\"],\n                    \"age\": [12, 26]\n                },\n            )\n        )\n        # Or, load multiple dataframes\n        db = Pandas(\n            {\n                \"students\": pd.DataFrame(\n                    {\n                        \"name\": [\"John\", \"Parker\"],\n                        \"age\": [12, 26]\n                    },\n                ),\n                \"classes\": pd.DataFrame(\n                    {\n                        \"class\": [\"Physics 101\", \"Chemistry\"],\n                        \"size\": [50, 32]\n                    },\n                ),\n            }\n        )\n        ```\n    \"\"\"\n    return DuckDB.from_pandas(data, tablename)\n</code></pre>"},{"location":"reference/databases/postgresql/","title":"PostreSQL","text":"<p>Installation</p> <p>You need to install the <code>psycopg2-binary</code> library to use this in blendsql.</p> <p>               Bases: <code>SQLAlchemyDatabase</code></p> <p>A PostgreSQL database connection. Can be initialized via the SQLAlchemy input string. https://docs.sqlalchemy.org/en/20/core/engines.html#postgresql</p> <p>Examples:</p> <pre><code>from blendsql.db import PostgreSQL\ndb = PostgreSQL(\"user:password@localhost/mydatabase\")\n</code></pre> Source code in <code>blendsql/db/postgresql.py</code> <pre><code>class PostgreSQL(SQLAlchemyDatabase):\n    \"\"\"A PostgreSQL database connection.\n    Can be initialized via the SQLAlchemy input string.\n    https://docs.sqlalchemy.org/en/20/core/engines.html#postgresql\n\n    Examples:\n        ```python\n        from blendsql.db import PostgreSQL\n        db = PostgreSQL(\"user:password@localhost/mydatabase\")\n        ```\n    \"\"\"\n\n    def __init__(self, db_path: str):\n        if not _has_psycopg2:\n            raise ImportError(\n                \"Please install psycopg2 with `pip install psycopg2-binary`!\"\n            ) from None\n        db_url: URL = make_url(f\"postgresql+psycopg2://{db_path}\")\n        if db_url.username is None:\n            logging.warning(\n                Fore.RED\n                + \"Connecting to postgreSQL database without specifying user!\\nIt is strongly encouraged to create a `blendsql` user with read-only permissions and temp table creation privileges.\"\n            )\n        super().__init__(db_url=db_url)\n\n    def has_temp_table(self, tablename: str) -&gt; bool:\n        return tablename in self.execute_to_list(\n            \"SELECT table_name FROM information_schema.tables WHERE table_schema LIKE 'pg_temp_%'\"\n        )\n\n    @cached_property\n    def sqlglot_schema(self) -&gt; dict:\n        schema: t.Dict[str, dict] = {}\n        for tablename in self.tables():\n            schema[tablename] = {}\n            for _, row in self.execute_to_df(\n                \"\"\"\n                    SELECT column_name as name, data_type as type \n                    FROM information_schema.columns \n                    WHERE table_name = :t\n                    AND table_schema = 'public'\n                    \"\"\",\n                {\"t\": tablename},\n            ).iterrows():\n                schema[tablename][row[\"name\"]] = row[\"type\"]\n        return schema\n</code></pre>"},{"location":"reference/databases/postgresql/#creating-a-blendsql-user","title":"Creating a <code>blendsql</code> User","text":"<p>When executing a BlendSQL query, there are internal checks to ensure prior to execution that a given query does not contain any 'modify' actions.</p> <p>However, it is still best practice when using PostgreSQL to create a dedicated 'blendsql' user with only the permissions needed. </p> <p>You can create a user with the required permissions with the script below (after invoking postgres via <code>psql</code>)</p> <pre><code>CREATE USER blendsql;\nGRANT pg_read_all_data TO blendsql;\nGRANT TEMP ON DATABASE mydb TO blendsql;\n</code></pre> <p>Now, we can initialize a PostgreSQL database with our new user.</p> <pre><code>from blendsql.db import PostgreSQL\ndb = PostgreSQL(\"blendsql@localhost:5432/mydb\")\n</code></pre>"},{"location":"reference/databases/sqlite/","title":"SQLite","text":"<p>               Bases: <code>SQLAlchemyDatabase</code></p> <p>A SQLite database connection. Can be initialized via a path to the database file.</p> <p>Examples:</p> <pre><code>from blendsql.db import SQLite\ndb = SQLite(\"./path/to/database.db\")\n</code></pre> Source code in <code>blendsql/db/sqlite.py</code> <pre><code>class SQLite(SQLAlchemyDatabase):\n    \"\"\"A SQLite database connection.\n    Can be initialized via a path to the database file.\n\n    Examples:\n        ```python\n        from blendsql.db import SQLite\n        db = SQLite(\"./path/to/database.db\")\n        ```\n    \"\"\"\n\n    def __init__(self, db_path: str):\n        db_url: URL = make_url(f\"sqlite:///{Path(db_path).resolve()}\")\n        super().__init__(db_url=db_url)\n\n    def has_temp_table(self, tablename: str) -&gt; bool:\n        return tablename in self.execute_to_list(\n            \"SELECT name FROM sqlite_temp_master WHERE type='table';\"\n        )\n\n    @cached_property\n    def sqlglot_schema(self) -&gt; dict:\n        \"\"\"Returns database schema as a dictionary, in the format that\n        sqlglot.optimizer expects.\n\n        Examples:\n            &gt;&gt;&gt; db.sqlglot_schema\n            {\"x\": {\"A\": \"INT\", \"B\": \"INT\", \"C\": \"INT\", \"D\": \"INT\", \"Z\": \"STRING\"}}\n        \"\"\"\n        schema: t.Dict[str, dict] = {}\n        for tablename in self.tables():\n            schema[tablename] = {}\n            for _, row in self.execute_to_df(\n                f\"\"\"\n            SELECT name, type FROM pragma_table_info(:t)\n            \"\"\",\n                {\"t\": tablename},\n            ).iterrows():\n                schema[tablename][row[\"name\"]] = row[\"type\"]\n        return schema\n</code></pre>"},{"location":"reference/examples/blendsql-by-example/","title":"BlendSQL by Example","text":"In\u00a0[2]: Copied! <pre>import pandas as pd\nimport nest_asyncio\nnest_asyncio.apply()\n\nfrom blendsql.db import Pandas\nfrom blendsql.common.utils import tabulate\nimport blendsql\n</pre> import pandas as pd import nest_asyncio nest_asyncio.apply()  from blendsql.db import Pandas from blendsql.common.utils import tabulate import blendsql <p>To begin, let's set up a local database using <code>from blendsql.db import Pandas</code>.</p> In\u00a0[3]: Copied! <pre>people_db = Pandas(\n    {\n        \"People\": pd.DataFrame(\n            {\n               'Name': [\n                   'George Washington', \n                   'John Quincy Adams', \n                   'Thomas Jefferson', \n                   'James Madison', \n                   'James Monroe', \n                   'Alexander Hamilton',\n                   'Sabrina Carpenter',\n                   'Charli XCX',\n                   'Elon Musk',\n                   'Michelle Obama',\n                   'Elvis Presley',\n               ],\n               'Known_For': [\n                   'Established federal government, First U.S. President',\n                   'XYZ Affair, Alien and Sedition Acts',\n                   'Louisiana Purchase, Declaration of Independence',\n                   'War of 1812, Constitution',\n                   'Monroe Doctrine, Missouri Compromise',\n                   'Created national bank, Federalist Papers',\n                   'Nonsense, Emails I Cant Send, Mean Girls musical',\n                   'Crash, How Im Feeling Now, Boom Clap',\n                   'Tesla, SpaceX, Twitter/X acquisition',\n                   'Lets Move campaign, Becoming memoir',\n                   '14 Grammys, King of Rock n Roll'\n               ]\n            }\n        ),\n        \"Eras\": pd.DataFrame(\n            {\n                'Years': [\n                    '1800-1900',\n                    '1900-2000',\n                    '2000-Now'\n                ]\n            }\n        )\n    }\n)\n# Print the tables in our database\nfor tablename in people_db.tables():\n    print(tablename)\n    print(tabulate(people_db.execute_to_df(f\"SELECT * FROM {tablename};\")))\n</pre> people_db = Pandas(     {         \"People\": pd.DataFrame(             {                'Name': [                    'George Washington',                     'John Quincy Adams',                     'Thomas Jefferson',                     'James Madison',                     'James Monroe',                     'Alexander Hamilton',                    'Sabrina Carpenter',                    'Charli XCX',                    'Elon Musk',                    'Michelle Obama',                    'Elvis Presley',                ],                'Known_For': [                    'Established federal government, First U.S. President',                    'XYZ Affair, Alien and Sedition Acts',                    'Louisiana Purchase, Declaration of Independence',                    'War of 1812, Constitution',                    'Monroe Doctrine, Missouri Compromise',                    'Created national bank, Federalist Papers',                    'Nonsense, Emails I Cant Send, Mean Girls musical',                    'Crash, How Im Feeling Now, Boom Clap',                    'Tesla, SpaceX, Twitter/X acquisition',                    'Lets Move campaign, Becoming memoir',                    '14 Grammys, King of Rock n Roll'                ]             }         ),         \"Eras\": pd.DataFrame(             {                 'Years': [                     '1800-1900',                     '1900-2000',                     '2000-Now'                 ]             }         )     } ) # Print the tables in our database for tablename in people_db.tables():     print(tablename)     print(tabulate(people_db.execute_to_df(f\"SELECT * FROM {tablename};\"))) <pre>Eras\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Years     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1800-1900 \u2502\n\u2502 1900-2000 \u2502\n\u2502 2000-Now  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nPeople\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Name               \u2502 Known_For                                            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 George Washington  \u2502 Established federal government, First U.S. President \u2502\n\u2502 John Quincy Adams  \u2502 XYZ Affair, Alien and Sedition Acts                  \u2502\n\u2502 Thomas Jefferson   \u2502 Louisiana Purchase, Declaration of Independence      \u2502\n\u2502 James Madison      \u2502 War of 1812, Constitution                            \u2502\n\u2502 James Monroe       \u2502 Monroe Doctrine, Missouri Compromise                 \u2502\n\u2502 Alexander Hamilton \u2502 Created national bank, Federalist Papers             \u2502\n\u2502 Sabrina Carpenter  \u2502 Nonsense, Emails I Cant Send, Mean Girls musical     \u2502\n\u2502 Charli XCX         \u2502 Crash, How Im Feeling Now, Boom Clap                 \u2502\n\u2502 Elon Musk          \u2502 Tesla, SpaceX, Twitter/X acquisition                 \u2502\n\u2502 Michelle Obama     \u2502 Lets Move campaign, Becoming memoir                  \u2502\n\u2502 Elvis Presley      \u2502 14 Grammys, King of Rock n Roll                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[4]: Copied! <pre># Define a utility function to make query execution easier\nblend = lambda query, *args, **kwargs: blendsql.blend(\n    query,\n    db=kwargs.get(\"db\", people_db),\n    ingredients={blendsql.LLMQA, blendsql.RAGQA, blendsql.LLMMap, blendsql.LLMJoin},\n    # This model can be changed, according to what your personal setup is\n    default_model=kwargs.get(\"model\", blendsql.models.AzurePhiModel(env=\"..\", caching=False)),\n    verbose=True\n)\n</pre> # Define a utility function to make query execution easier blend = lambda query, *args, **kwargs: blendsql.blend(     query,     db=kwargs.get(\"db\", people_db),     ingredients={blendsql.LLMQA, blendsql.RAGQA, blendsql.LLMMap, blendsql.LLMJoin},     # This model can be changed, according to what your personal setup is     default_model=kwargs.get(\"model\", blendsql.models.AzurePhiModel(env=\"..\", caching=False)),     verbose=True ) In\u00a0[56]: Copied! <pre>db = blendsql.db.SQLite(blendsql.common.utils.fetch_from_hub(\"california_schools.db\"))\nprint(\"{} total rows in the table\".format(db.execute_to_list(\"SELECT COUNT(*) FROM schools LIMIT 10;\")[0]))\nprint(\"{} total unique values in the 'City' column\".format(db.execute_to_list(\"SELECT COUNT(DISTINCT City) FROM schools LIMIT 10;\")[0]))\n</pre> db = blendsql.db.SQLite(blendsql.common.utils.fetch_from_hub(\"california_schools.db\")) print(\"{} total rows in the table\".format(db.execute_to_list(\"SELECT COUNT(*) FROM schools LIMIT 10;\")[0])) print(\"{} total unique values in the 'City' column\".format(db.execute_to_list(\"SELECT COUNT(DISTINCT City) FROM schools LIMIT 10;\")[0])) <pre>17686 total rows in the table\n1165 total unique values in the 'City' column\n</pre> In\u00a0[63]: Copied! <pre>smoothie = blend(\n    \"\"\"\n    SELECT City, {{LLMMap('Is this in the Bay Area?', 'schools::City', options='t;f')}} AS 'In Bay Area?' FROM schools;\n    \"\"\",\n    # Override the default database and model arguments\n    db=db,\n    model=blendsql.models.OpenaiLLM('gpt-4o-mini', caching=False, env='..')\n)\nprint(f\"Finished in {smoothie.meta.process_time_seconds} seconds\")\nprint(tabulate(smoothie.df.head(10)))\n</pre> smoothie = blend(     \"\"\"     SELECT City, {{LLMMap('Is this in the Bay Area?', 'schools::City', options='t;f')}} AS 'In Bay Area?' FROM schools;     \"\"\",     # Override the default database and model arguments     db=db,     model=blendsql.models.OpenaiLLM('gpt-4o-mini', caching=False, env='..') ) print(f\"Finished in {smoothie.meta.process_time_seconds} seconds\") print(tabulate(smoothie.df.head(10))) <pre>Executing `SELECT * FROM schools` and setting to `32d0_schools_0`...\nCREATE TEMP TABLE \"32d0_schools_0\" (\n\t\"CDSCode\" TEXT, \n\t\"NCESDist\" TEXT, \n\t\"NCESSchool\" TEXT, \n\t\"StatusType\" TEXT, \n\t\"County\" TEXT, \n\t\"District\" TEXT, \n\t\"School\" TEXT, \n\t\"Street\" TEXT, \n\t\"StreetAbr\" TEXT, \n\t\"City\" TEXT, \n\t\"Zip\" TEXT, \n\t\"State\" TEXT, \n\t\"MailStreet\" TEXT, \n\t\"MailStrAbr\" TEXT, \n\t\"MailCity\" TEXT, \n\t\"MailZip\" TEXT, \n\t\"MailState\" TEXT, \n\t\"Phone\" TEXT, \n\t\"Ext\" TEXT, \n\t\"Website\" TEXT, \n\t\"OpenDate\" TEXT, \n\t\"ClosedDate\" TEXT, \n\t\"Charter\" FLOAT, \n\t\"CharterNum\" TEXT, \n\t\"FundingType\" TEXT, \n\t\"DOC\" TEXT, \n\t\"DOCType\" TEXT, \n\t\"SOC\" TEXT, \n\t\"SOCType\" TEXT, \n\t\"EdOpsCode\" TEXT, \n\t\"EdOpsName\" TEXT, \n\t\"EILCode\" TEXT, \n\t\"EILName\" TEXT, \n\t\"GSoffered\" TEXT, \n\t\"GSserved\" TEXT, \n\t\"Virtual\" TEXT, \n\t\"Magnet\" FLOAT, \n\t\"Latitude\" FLOAT, \n\t\"Longitude\" FLOAT, \n\t\"AdmFName1\" TEXT, \n\t\"AdmLName1\" TEXT, \n\t\"AdmEmail1\" TEXT, \n\t\"AdmFName2\" TEXT, \n\t\"AdmLName2\" TEXT, \n\t\"AdmEmail2\" TEXT, \n\t\"AdmFName3\" TEXT, \n\t\"AdmLName3\" TEXT, \n\t\"AdmEmail3\" TEXT, \n\t\"LastUpdate\" TEXT\n)\nExecuting  `{{LLMMap('Is this in the Bay Area?', 'schools::City', options='t;f')}}`...\nUsing options '['t', 'f']'\nMaking calls to Model with batch_size 5: |          | 234/? [00:00&lt;00:00, 30475.61it/s]\nLLMMap with OpenaiLLM(gpt-4o-mini) only returned 1165 out of 1166 values\nFinished LLMMap with values:\n{\n    \"Hayward\": true,\n    \"Newark\": true,\n    \"Oakland\": true,\n    \"Berkeley\": true,\n    \"San Leandro\": true,\n    \"-\": false,\n    \"Dublin\": true,\n    \"Fremont\": false,\n    \"Sacramento\": true,\n    \"Alameda\": null\n}\nCombining 1 outputs for table `schools`\nCREATE TEMP TABLE \"32d0_schools\" (\n\t\"CDSCode\" TEXT, \n\t\"NCESDist\" TEXT, \n\t\"NCESSchool\" TEXT, \n\t\"StatusType\" TEXT, \n\t\"County\" TEXT, \n\t\"District\" TEXT, \n\t\"School\" TEXT, \n\t\"Street\" TEXT, \n\t\"StreetAbr\" TEXT, \n\t\"City\" TEXT, \n\t\"Zip\" TEXT, \n\t\"State\" TEXT, \n\t\"MailStreet\" TEXT, \n\t\"MailStrAbr\" TEXT, \n\t\"MailCity\" TEXT, \n\t\"MailZip\" TEXT, \n\t\"MailState\" TEXT, \n\t\"Phone\" TEXT, \n\t\"Ext\" TEXT, \n\t\"Website\" TEXT, \n\t\"OpenDate\" TEXT, \n\t\"ClosedDate\" TEXT, \n\t\"Charter\" FLOAT, \n\t\"CharterNum\" TEXT, \n\t\"FundingType\" TEXT, \n\t\"DOC\" TEXT, \n\t\"DOCType\" TEXT, \n\t\"SOC\" TEXT, \n\t\"SOCType\" TEXT, \n\t\"EdOpsCode\" TEXT, \n\t\"EdOpsName\" TEXT, \n\t\"EILCode\" TEXT, \n\t\"EILName\" TEXT, \n\t\"GSoffered\" TEXT, \n\t\"GSserved\" TEXT, \n\t\"Virtual\" TEXT, \n\t\"Magnet\" FLOAT, \n\t\"Latitude\" FLOAT, \n\t\"Longitude\" FLOAT, \n\t\"AdmFName1\" TEXT, \n\t\"AdmLName1\" TEXT, \n\t\"AdmEmail1\" TEXT, \n\t\"AdmFName2\" TEXT, \n\t\"AdmLName2\" TEXT, \n\t\"AdmEmail2\" TEXT, \n\t\"AdmFName3\" TEXT, \n\t\"AdmLName3\" TEXT, \n\t\"AdmEmail3\" TEXT, \n\t\"LastUpdate\" TEXT, \n\t\"Is this in the Bay Area?\" BOOLEAN\n)\nFinal Query:\nSELECT \"32d0_schools\".City AS City,  \"32d0_schools\".\"Is this in the Bay Area?\"  AS \"In Bay Area?\" FROM \"32d0_schools\"\n</pre> <pre>Finished in 6.575707912445068 seconds\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 City        \u2502   In Bay Area? \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Hayward     \u2502              1 \u2502\n\u2502 Newark      \u2502              1 \u2502\n\u2502 Oakland     \u2502              1 \u2502\n\u2502 Berkeley    \u2502              1 \u2502\n\u2502 Oakland     \u2502              1 \u2502\n\u2502 Oakland     \u2502              1 \u2502\n\u2502 Oakland     \u2502              1 \u2502\n\u2502 Hayward     \u2502              1 \u2502\n\u2502 San Leandro \u2502              1 \u2502\n\u2502 Hayward     \u2502              1 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[66]: Copied! <pre>smoothie = blend(\"\"\"\nSELECT GROUP_CONCAT(Name, ', ') AS 'Names',\n{{LLMMap('In which time period did the person live?', 'People::Name', options='Eras::Years')}} AS \"Lived During Classification\"\nFROM People\nGROUP BY \"Lived During Classification\"\n\"\"\")\nprint(smoothie.df)\n</pre> smoothie = blend(\"\"\" SELECT GROUP_CONCAT(Name, ', ') AS 'Names', {{LLMMap('In which time period did the person live?', 'People::Name', options='Eras::Years')}} AS \"Lived During Classification\" FROM People GROUP BY \"Lived During Classification\" \"\"\") print(smoothie.df) <pre>Executing  `{{LLMMap('In which time period did the person live?', 'People::Name', options='Eras::Years')}}`...\nUsing options '['2000-Now', '1900-2000', '1800-1900']'\nMaking calls to Model with batch_size 5: |          | 3/? [00:01&lt;00:00,  1.85it/s]    \nFinished LLMMap with values:\n{\n    \"Elvis Presley\": \"1900-2000\",\n    \"John Quincy Adams\": \"1800-1900\",\n    \"James Monroe\": \"1800-1900\",\n    \"Elon Musk\": \"2000-Now\",\n    \"George Washington\": \"1800-1900\",\n    \"Alexander Hamilton\": \"1800-1900\",\n    \"James Madison\": \"1800-1900\",\n    \"Sabrina Carpenter\": \"2000-Now\",\n    \"Thomas Jefferson\": \"1800-1900\",\n    \"Charli XCX\": \"2000-Now\"\n}\nCombining 1 outputs for table `People`\nCreated temp table e88a_People\nFinal Query:\nSELECT GROUP_CONCAT(Name, ', ') AS \"Names\",  \"e88a_People\".\"In which time period did the person live?\"  AS \"Lived During Classification\" FROM \"e88a_People\" GROUP BY \"Lived During Classification\"\n</pre> <pre>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Names                                                 \u2502 Lived During Classification   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 George Washington, John Quincy Adams, Thomas Jeffe... \u2502 1800-1900                     \u2502\n\u2502 Sabrina Carpenter, Charli XCX, Elon Musk              \u2502 2000-Now                      \u2502\n\u2502 Michelle Obama, Elvis Presley                         \u2502 1900-2000                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[23]: Copied! <pre># Setting `infer_gen_constraints=False` - otherwise, this counter-example would work\nsmoothie = blend(\"\"\"\nSELECT * FROM People\nWHERE People.Name IN {{LLMQA('First 3 presidents of the U.S?', output_type='List[str]')}}\n\"\"\", infer_gen_constraints=False)\n# The final query 'SELECT * FROM People WHERE Name IN  ('George Washington','John Adams','Thomas Jefferson')' only yields 2 rows\nprint(smoothie.df)\n</pre> # Setting `infer_gen_constraints=False` - otherwise, this counter-example would work smoothie = blend(\"\"\" SELECT * FROM People WHERE People.Name IN {{LLMQA('First 3 presidents of the U.S?', output_type='List[str]')}} \"\"\", infer_gen_constraints=False) # The final query 'SELECT * FROM People WHERE Name IN  ('George Washington','John Adams','Thomas Jefferson')' only yields 2 rows print(smoothie.df) <pre>Executing  `{{LLMQA('First 3 presidents of the U.S?', output_type='List[str]')}}`...\nFinal Query:\nSELECT * FROM People WHERE People.Name IN  ('George Washington','John Adams','Thomas Jefferson') \n</pre> <pre>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Name              \u2502 Known_For                                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 George Washington \u2502 Established federal government, First U.S. Preside... \u2502\n\u2502 Thomas Jefferson  \u2502 Louisiana Purchase, Declaration of Independence       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>Constrained decoding comes to our rescue. By specifying <code>infer_gen_constraints=True</code> (which is the default), BlendSQL infers from the surrounding SQL syntax that we expect a value from <code>People.Name</code>, and we force the generation to only select from values present in the <code>Name</code> column - which leads to the expected response.</p> In\u00a0[38]: Copied! <pre>smoothie = blend(\"\"\"\nSELECT * FROM People\nWHERE People.Name IN {{LLMQA('First 3 presidents of the U.S?')}}\n\"\"\", infer_gen_constraints=True)\nprint(smoothie.df)\n</pre> smoothie = blend(\"\"\" SELECT * FROM People WHERE People.Name IN {{LLMQA('First 3 presidents of the U.S?')}} \"\"\", infer_gen_constraints=True) print(smoothie.df) <pre>Executing  `{{LLMQA('First 3 presidents of the U.S?')}}`...\nUsing options '{'George Washington', 'James Monroe', 'Thomas Jefferson', 'James Madison', 'John Quincy Adams', 'Michelle Obama', 'Elon Musk', 'Charli XCX', 'Elvis Presley', 'Alexander Hamilton', 'Sabrina Carpenter'}'\nFinal Query:\nSELECT * FROM People WHERE People.Name IN  ('George Washington','John Quincy Adams','James Monroe') \n</pre> <pre>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Name              \u2502 Known_For                                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 George Washington \u2502 Established federal government, First U.S. Preside... \u2502\n\u2502 John Quincy Adams \u2502 XYZ Affair, Alien and Sedition Acts                   \u2502\n\u2502 James Monroe      \u2502 Monroe Doctrine, Missouri Compromise                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[26]: Copied! <pre>smoothie = blend(\"\"\"\nSELECT * FROM ( VALUES {{LLMQA('What are the first letters of the alphabet?')}} )\n\"\"\")\nprint(smoothie.df)\n</pre> smoothie = blend(\"\"\" SELECT * FROM ( VALUES {{LLMQA('What are the first letters of the alphabet?')}} ) \"\"\") print(smoothie.df) <pre>Executing  `{{LLMQA('What are the first letters of the alphabet?')}}`...\nFinal Query:\nSELECT * FROM (VALUES ( 'A' ))\n</pre> <pre>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col0   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 A      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>Ok, so we were able to generate the first letter of the alphabet... what if we want more?</p> <p>Rather than modify the prompt itself (which can be quite finicky), we can leverage the regex-inspired <code>quantifier</code> argument. This will take either the strings <code>'*'</code> (zero-or-more) or <code>'+'</code> (one-or-more), in addition to tighter bounds of <code>'{3}'</code> (exactly 3) or <code>'{1,6}'</code> (between 1 and 6).</p> In\u00a0[27]: Copied! <pre>smoothie = blend(\"\"\"\nSELECT * FROM ( VALUES {{LLMQA('What are the first letters of the alphabet?', quantifier='{3}')}} )\n\"\"\")\nprint(smoothie.df)\n</pre> smoothie = blend(\"\"\" SELECT * FROM ( VALUES {{LLMQA('What are the first letters of the alphabet?', quantifier='{3}')}} ) \"\"\") print(smoothie.df) <pre>Executing  `{{LLMQA('What are the first letters of the alphabet?', quantifier='{3}')}}`...\nFinal Query:\nSELECT * FROM (VALUES ( 'A','B','C' ))\n</pre> <pre>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col0   \u2502 col1   \u2502 col2   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 A      \u2502 B      \u2502 C      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>What if we want to generate the letters of a different alphabet? We can use the <code>options</code> argument for this, which takes either a reference to another column in the form <code>'tablename::columnname'</code>, or a set of semicolon-separated strings.</p> In\u00a0[28]: Copied! <pre>smoothie = blend(\"\"\"\nSELECT * FROM ( VALUES {{LLMQA('What are the first letters of the alphabet?', options='\u03b1;\u03b2;\u03b3;\u03b4', quantifier='{3}')}} )\n\"\"\")\nprint(smoothie.df)\n</pre> smoothie = blend(\"\"\" SELECT * FROM ( VALUES {{LLMQA('What are the first letters of the alphabet?', options='\u03b1;\u03b2;\u03b3;\u03b4', quantifier='{3}')}} ) \"\"\") print(smoothie.df) <pre>Executing  `{{LLMQA('What are the first letters of the alphabet?', options='\u03b1;\u03b2;\u03b3;\u03b4', quantifier='{3}')}}`...\nUsing options '{'\u03b3', '\u03b4', '\u03b2', '\u03b1'}'\nFinal Query:\nSELECT * FROM (VALUES ( '\u03b1','\u03b2','\u03b3' ))\n</pre> <pre>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col0   \u2502 col1   \u2502 col2   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 \u03b1      \u2502 \u03b2      \u2502 \u03b3      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[29]: Copied! <pre>smoothie = blend(\"\"\"\nWITH letter_agent_output AS (\n    SELECT * FROM (VALUES {{LLMQA('List some greek letters')}})\n) SELECT {{\n    LLMQA(\n        'What is the first letter of the alphabet?', \n        options=(SELECT * FROM letter_agent_output)\n    )}}\n\"\"\")\nprint(smoothie.df)\n</pre> smoothie = blend(\"\"\" WITH letter_agent_output AS (     SELECT * FROM (VALUES {{LLMQA('List some greek letters')}}) ) SELECT {{     LLMQA(         'What is the first letter of the alphabet?',          options=(SELECT * FROM letter_agent_output)     )}} \"\"\") print(smoothie.df) <pre>Executing  `{{ LLMQA( 'What is the first letter of the alphabet?', options=(SELECT * FROM letter_agent_output) )}}`...\nExecuting `SELECT * FROM (VALUES ({{LLMQA('List some greek letters')}}))` and setting to `letter_agent_output`\nExecuting  `{{LLMQA('List some greek letters')}}`...\nFinal Query:\nSELECT * FROM (VALUES ( 'alpha','beta','gamma','delta','epsilon','zeta','eta','theta','iota','kappa','lambda','mu','nu','xi','omicron','pi','rho','sigma','tau','upsilon','phi','chi','psi','omega' ))\nCreated temp table letter_agent_output\nNo BlendSQL ingredients found in query:\nSELECT * FROM letter_agent_output\nExecuting as vanilla SQL...\nUsing options '{'mu', 'sigma', 'kappa', 'lambda', 'eta', 'rho', 'gamma', 'theta', 'nu', 'phi', 'iota', 'zeta', 'psi', 'omega', 'upsilon', 'beta', 'xi', 'tau', 'pi', 'delta', 'chi', 'alpha', 'omicron', 'epsilon'}'\nFinal Query:\nSELECT  'alpha' \n</pre> <pre>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 'alpha'   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 alpha     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[30]: Copied! <pre>smoothie = blend(\"\"\"\nSELECT * FROM ( VALUES {{LLMQA('Count up, starting from 1', output_type='int', quantifier='+')}} )\n\"\"\")\nprint(smoothie.df)\n</pre> smoothie = blend(\"\"\" SELECT * FROM ( VALUES {{LLMQA('Count up, starting from 1', output_type='int', quantifier='+')}} ) \"\"\") print(smoothie.df) <pre>Executing  `{{LLMQA('Count up, starting from 1', output_type='int', quantifier='+')}}`...\nUsing regex '(\\d{1,18})'\nFinal Query:\nSELECT * FROM (VALUES ( '1','2' ))\n</pre> <pre>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   col0 \u2502   col1 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502      1 \u2502      2 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[5]: Copied! <pre># Give a short summary of the person who had a musical by Lin-Manuel Miranda written about them\nsmoothie = blend(\"\"\"\nSELECT {{\n    LLMQA(\n        'Give me a very short summary of this person', \n        context=(\n            SELECT * FROM People \n            WHERE People.Name = {{LLMQA('Who has a musical by Lin-Manuel Miranda written about them?', options='People::Name')}}\n        )\n    )\n}} AS \"Summary\"\n\"\"\")\nprint(smoothie.df)\n</pre> # Give a short summary of the person who had a musical by Lin-Manuel Miranda written about them smoothie = blend(\"\"\" SELECT {{     LLMQA(         'Give me a very short summary of this person',          context=(             SELECT * FROM People              WHERE People.Name = {{LLMQA('Who has a musical by Lin-Manuel Miranda written about them?', options='People::Name')}}         )     ) }} AS \"Summary\" \"\"\") print(smoothie.df) <pre>Executing  `{{ LLMQA( 'Give me a very short summary of this person', context=( SELECT * FROM People WHERE People.Name = {{LLMQA('Who has a musical by Lin-Manuel Miranda written about them?', options='People::Name')}} ) ) }}`...\nExecuting  `{{LLMQA ( 'Who has a musical by Lin-Manuel Miranda written about them?' , options= 'People::Name' ) }}`...\nUsing options '{'Elon Musk', 'James Madison', 'Elvis Presley', 'Thomas Jefferson', 'Sabrina Carpenter', 'Michelle Obama', 'John Quincy Adams', 'Alexander Hamilton', 'James Monroe', 'Charli XCX', 'George Washington'}'\nFinal Query:\nSELECT * FROM People WHERE People.Name =  'Alexander Hamilton' \n</pre> <pre>Warning: can't backtrack over \" Question\u2027:\"; this may confuse the model\n</pre> <pre>Final Query:\nSELECT  'Founder of national bank, author of Federalist Papers '  AS \"Summary\"\n</pre> <pre>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Summary                                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Founder of national bank, author of Federalist Pap... \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> In\u00a0[35]: Copied! <pre># A two-step reasoning problem:\n#   1) Identify who, out of the table, is a singer using `LLMMap`\n#   2) Where the previous step yields `TRUE`, select the one that wrote the song Espresso.\nsmoothie = blend(\"\"\"\nWITH Musicians AS \n(SELECT Name FROM People WHERE {{LLMMap('Is a singer?', 'People::Name')}} = TRUE)\nSELECT Name AS \"Espresso Singer\" FROM Musicians WHERE Musicians.Name = {{LLMQA('Who wrote the song Espresso?')}}\n\"\"\")\nprint(smoothie.df)\n</pre> # A two-step reasoning problem: #   1) Identify who, out of the table, is a singer using `LLMMap` #   2) Where the previous step yields `TRUE`, select the one that wrote the song Espresso. smoothie = blend(\"\"\" WITH Musicians AS  (SELECT Name FROM People WHERE {{LLMMap('Is a singer?', 'People::Name')}} = TRUE) SELECT Name AS \"Espresso Singer\" FROM Musicians WHERE Musicians.Name = {{LLMQA('Who wrote the song Espresso?')}} \"\"\") print(smoothie.df) <pre>Executing  `{{LLMQA('Who wrote the song Espresso?')}}`...\nExecuting `SELECT Name AS Name FROM People WHERE {{LLMMap('Is a singer?', 'People::Name')}} = TRUE` and setting to `Musicians`\nExecuting  `{{LLMMap('Is a singer?', 'People::Name')}}`...\nWhen inferring `options` in infer_gen_kwargs, encountered a column node with no table specified!\nShould probably mark `schema_qualify` arg as True\nUsing regex '(t|f)'\nMaking calls to Model with batch_size 5: |          | 3/? [00:01&lt;00:00,  2.69it/s]    \nFinished LLMMap with values:\n{\n    \"Elvis Presley\": true,\n    \"Michelle Obama\": false,\n    \"George Washington\": false,\n    \"Alexander Hamilton\": false,\n    \"John Quincy Adams\": false,\n    \"James Monroe\": false,\n    \"Elon Musk\": false,\n    \"James Madison\": false,\n    \"Sabrina Carpenter\": true,\n    \"Thomas Jefferson\": false\n}\nCombining 1 outputs for table `People`\nCreated temp table 9f31_People\nFinal Query:\nSELECT Name AS Name FROM \"9f31_People\" WHERE  \"9f31_People\".\"Is a singer?\"  = TRUE\nCreated temp table Musicians\nUsing options '{'Sabrina Carpenter', 'Charli XCX', 'Elvis Presley'}'\nFinal Query:\nSELECT Musicians.Name AS \"Espresso Singer\" FROM Musicians WHERE Musicians.Name =  'Sabrina Carpenter' \n</pre> <pre>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Espresso Singer   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Sabrina Carpenter \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>Let's ask a question that requires a bit more world-knowledge to answer.</p> In\u00a0[91]: Copied! <pre>smoothie = blend(\"\"\"\nSELECT {{LLMQA(\"Who's birthday is June 28, 1971?\")}} AS \"Answer\"\n\"\"\")\nprint(smoothie.df)\n</pre> smoothie = blend(\"\"\" SELECT {{LLMQA(\"Who's birthday is June 28, 1971?\")}} AS \"Answer\" \"\"\") print(smoothie.df) <pre>Executing  `{{LLMQA(\"Who's birthday is June 28, 1971?\")}}`...\n</pre> <pre>Warning: can't backtrack over \"\\n\"; this may confuse the model\n</pre> <pre>Final Query:\nSELECT  'Not specified in the context'  AS \"Answer\"\n</pre> <pre>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Answer                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Not specified in the context \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>Ok, that's fair.</p> <p>Now let's try again, using constrained decoding via <code>options</code> and using the <code>RAGQA</code> ingredient to fetch relevant context via a Bing web search first.</p> In\u00a0[92]: Copied! <pre>smoothie = blend(\"\"\"\nSELECT * FROM People WHERE Name = {{RAGQA(\"Who's birthday is June 28, 1971?\", source='bing', options='People::Name')}}\n\"\"\")\nprint(smoothie.df)\n</pre> smoothie = blend(\"\"\" SELECT * FROM People WHERE Name = {{RAGQA(\"Who's birthday is June 28, 1971?\", source='bing', options='People::Name')}} \"\"\") print(smoothie.df) <pre>Unpacked alias `{{RAGQA(\"Who's birthday is June 28, 1971?\", source='bing', options='People::Name')}}` to `\n{{\n    LLMQA(\n        \"Who's birthday is June 28, 1971?\", \n        (\n            SELECT {{\n                BingWebSearch(\"Who's birthday is June 28, 1971?\")\n            }} AS \"Search Results\"\n        ), options='People::Name'\n    )\n}}\n`\nExecuting  `{{RAGQA(\"Who's birthday is June 28, 1971?\", source='bing', options='People::Name')}}`...\nWhen inferring `options` in infer_gen_kwargs, encountered a column node with no table specified!\nShould probably mark `schema_qualify` arg as True\nExecuting  `{{ BingWebSearch ( \"Who's birthday is June 28, 1971?\" ) }}`...\nFinal Query:\nSELECT  '## DOCUMENT 1\n\nElon Reeve Musk was born on June 28, 1971, in Pretoria, South Africa''s administrative capital. [7] [8] He is of British and Pennsylvania Dutch ancestry.[9] [10] His mother, Maye (n\u00e9e Haldeman), is a model and dietitian born in Saskatchewan, Canada, and raised in South Africa.[11] [12] [13] His father, Errol Musk, is a South African electromechanical engineer, pilot, sailor, consultant ...\n\n## DOCUMENT 2\n\nWeekday: June 28th, 1971 was a Monday. People born on June 28th, 1971 turned 53 this year (2024). Birthdays of famous people, actors, celebrities and stars on June 28th. With 365 days 1971 is a normal year and no leap year.'  AS \"Search Results\"\nUsing options '{'Thomas Jefferson', 'Charli XCX', 'James Madison', 'Sabrina Carpenter', 'Michelle Obama', 'John Quincy Adams', 'James Monroe', 'George Washington', 'Elvis Presley', 'Elon Musk', 'Alexander Hamilton'}'\nFinal Query:\nSELECT * FROM People WHERE Name =  'Elon Musk' \n</pre> <pre>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Name      \u2502 Known_For                            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Elon Musk \u2502 Tesla, SpaceX, Twitter/X acquisition \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>Nice! Elon Musk was indeed born on June 28th, 1971. You can check out the BlendSQL logs above to validate this given the web context.</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"reference/examples/blendsql-by-example/#blendsql-by-example","title":"BlendSQL by Example\u00b6","text":"<p>This notebook introduces BlendSQL, and some of the usecases it can support.</p> <p>Importantly, the novelty of BlendSQL isn't from the ability to constrain language models according to some regular expression or context-free grammar. We can credit projects like guidance and outlines for that. Instead, the novelty of BlendSQL is its ability to infer these constraints according to the surrounding SQL syntax and closely align generation to the structure of the database.</p> <p>SQL, as a grammar, has a lot of rules. Just take these SQLite syntax diagrams for example. These rules include things like, <code>IN</code> statement should be followed by a list of items, <code>&lt;</code>, <code>&gt;</code>, should contain numerics, but <code>=</code> could contain any datatype, etc. We can use these to inform language-model functions, which we call 'ingredients', and denote in double curly brackets (<code>{{</code> and <code>}}</code>).</p>"},{"location":"reference/examples/blendsql-by-example/#a-note-on-models","title":"A Note on Models\u00b6","text":"<p>This demo, unless noted otherwise, uses the amazing Azure AI with serverside Guidance integration, described here. It allows us to access a Phi-3.5-mini on Azure, and utilize it in a constrained setting (i.e. have it follow a regular expression pattern, interleave text with generation calls, etc.)</p> <p>If you don't have an Azure access key, you can swap out the model below for any of the other model integrations that BlendSQL supports.</p>"},{"location":"reference/examples/blendsql-by-example/#the-elephant-in-the-room-arent-llm-functions-in-sql-super-slow","title":"The Elephant in the Room - Aren't LLM Functions in SQL Super Slow?\u00b6","text":"<p>Short answer - compared to nearly all native SQL operations, yes.</p> <p>However, when using remote APIs like OpenAI or Anthropic, we can dramatically speed up processing times by batching async requests. Below demonstrates that, for a table with 17,686 rows and 1,165 unique values in the column we process, it takes only about 6.5 seconds to run our query with gpt-4o-mini (or about 0.005 seconds per value).</p> <p>By default, we allow 10 concurrent async requests. Depending on your own quotas set by the API provider, you may be able to increase this number using:</p> <pre>import blendsql\n\n# Set the limit for max async calls at a given time below\nblendsql.config.set_async_limit(20)\n</pre>"},{"location":"reference/examples/blendsql-by-example/#a-note-on-query-optimizations","title":"A Note on Query Optimizations\u00b6","text":"<p>Because LLM functions are relatively slow compared to other SQL functions, when we perform query optimizations behind the scenes, we make sure to execute all native SQL functions before any LLM-based functions. This ensures the language model only receives the smallest set of data it needs to faithfully evaluate a given SQL expression</p>"},{"location":"reference/examples/blendsql-by-example/#classification-with-llmmap-and-group-by-constrained-by-a-columns-values","title":"Classification with 'LLMMap' and GROUP BY', Constrained by a Column's Values\u00b6","text":"<p>Below, we set up a BlendSQL query leveraging the <code>LLMMap</code> ingredient. This is a unary function similar to the <code>LENGTH</code> or <code>ABS</code> functions in standard SQLite. It takes a single argument (a value from a column) and returns a transformed output, which is then assigned to a new column.</p> <p>Below, we set up a language-model function which takes in the values from the <code>Name</code> column of the <code>People</code> table, and outputs a value exclusively selected from the <code>Eras::Years</code> column.</p>"},{"location":"reference/examples/blendsql-by-example/#constrained-decoding-the-presidents-challenge","title":"Constrained Decoding - The Presidents Challenge\u00b6","text":"<p>Why does constrained decoding matter? Imagine we want to select all the information we have in our table about the first 3 presidents of the U.S. In the absence of relevant data stored in our database, we turn to our language model. But one thing thwarts our plans - the language model doesn't know that we've stored the 2nd president's name in our database as <code>'John Quincy Adams'</code>, not <code>'John Adams'</code>.</p>"},{"location":"reference/examples/blendsql-by-example/#constrained-decoding-the-alphabet-challenge","title":"Constrained Decoding - The Alphabet Challenge\u00b6","text":"<p>In BlendSQL, we can utilize the power of constrained decoding to guide a language model's generation towards the structure we expect. In other words, rather than taking a \"prompt-and-pray\" approach in which we meticulously craft a natural language prompt which (hopefully) generates a list of 3 strings, we can interact with the logit space to ensure this is the case<sup>1</sup>.</p> <p>[!NOTE] These guarantees are only made possible with open models, i.e. where we can access the underlying logits. For closed-models like OpenAI and Anthropic, we rely on prompting (i.e. 'Datatype: List[str]') and make predictions \"optimistically\"</p> <p>To demonstrate this, we can use the <code>LLMQA</code> ingredient. This ingredient optionally takes in a table subset as context, and returns either a scalar value or a list of scalars.</p> <p>Since BlendSQL can infer the shape of a valid generation according to the surrounding SQL syntax, when we use the <code>LLMQA</code> ingredient in a <code>VALUES</code> or <code>IN</code> clause, it will generate a list by default.</p>"},{"location":"reference/examples/blendsql-by-example/#agent-based-inference-with-cte-expressions","title":"Agent-Based Inference with CTE Expressions\u00b6","text":"<p>The above example opens up the opportunity to rewrite the query as more of an agent-based flow. SQL is a bit odd in that it's executed bottom-up, i.e. to execute the following query:</p> <pre>SELECT the_answer FROM final_table WHERE final_table.x IN \n    (SELECT some_field FROM initial_table)\n</pre> <p>...We first gather <code>some_field</code> from <code>initial_table</code>, and then go and fetch <code>the_answer</code>, despite the author (human or AI) having written the second step, first. This is similar to the point made by Google in the pipe-syntax paper about how SQL syntactic clause order doesn't match semantic evaluation order.</p> <p>At the end of the day, we have two agents performing the following tasks -</p> <ol> <li>Brainstorm some greek letters</li> <li>Using the output of the previous task, select only the first 3</li> </ol> <p>With BlendSQL, we can use common table expressions (CTEs) to more closely mimic this order of 'agents'.</p>"},{"location":"reference/examples/blendsql-by-example/#using-output_type-to-influence-generation","title":"Using <code>output_type</code> to Influence Generation\u00b6","text":"<p>BlendSQL does its best to infer datatytpes given surrounding syntax. Sometimes, though, the user may want to override those assumptions, or inject new ones that were unable to be inferred.</p> <p>The <code>output_type</code> argument takes a Python-style type annotation like <code>int</code>, <code>str</code>, <code>bool</code> or <code>float</code>. Below we use that to guide the generation towards one-or-more integer.</p>"},{"location":"reference/examples/blendsql-by-example/#rag-for-unstructured-reasoning","title":"RAG for Unstructured Reasoning\u00b6","text":"<p>In addition to using the <code>LLMQA</code> ingredient as a method for generating with tight syntax-aware constraints, we can also relax a bit and let the model give us an unstructured generation for things like summarization.</p> <p>Also, we can use the <code>context</code> argument to provide relevant table context. This allows us to condition generation on a curated set of data (and do cool stuff with nested reasoning).</p>"},{"location":"reference/examples/blendsql-by-example/#internet-connected-rag","title":"Internet-Connected RAG\u00b6","text":"<p>So we know how to use a table subset as a context, by writing subqueries. But what if the knowledge we need to answer a question isn't present in the universe of our table?</p> <p>For this, we have the <code>RAGQA</code> ingredient (retrieval-augmented generation question-answering). Currently it only supports Bing via Azure as a source, but the idea is that in the future, it will support more forms of unstructured retrieval.</p>"},{"location":"reference/examples/teaching-blendsql-via-in-context-learning/","title":"Teaching BlendSQL via In-Context Learning","text":"In\u00a0[14]: Copied! <pre>from typing import List\nfrom textwrap import dedent\nimport outlines\n\nfrom blendsql import blend\nfrom blendsql.ingredients import LLMMap, LLMJoin, LLMQA\nfrom blendsql.models import OpenaiLLM\nfrom blendsql.models._model import Model\nfrom blendsql._program import Program\nfrom blendsql.db import SQLite\nfrom blendsql.utils import fetch_from_hub\n</pre> from typing import List from textwrap import dedent import outlines  from blendsql import blend from blendsql.ingredients import LLMMap, LLMJoin, LLMQA from blendsql.models import OpenaiLLM from blendsql.models._model import Model from blendsql._program import Program from blendsql.db import SQLite from blendsql.utils import fetch_from_hub In\u00a0[15]: Copied! <pre># 1) Define our few-shot examples\nexamples = [\n   {\n        \"serialized_db\": 'CREATE TABLE \"w\" (\\n\"index\" INTEGER,\\n  \"name\" TEXT,\\n  \"province\" TEXT,\\n  \"city\" TEXT,\\n  \"year\" TEXT,\\n  \"remarks\" TEXT\\n)\\n/*\\n3 example rows:\\nSELECT * FROM w LIMIT 3\\n index                      name          province     city year                                                         remarks\\n     0       abdul rahman mosque    kabul province    kabul 2009                                   largest mosque in afghanistan\\n     1 friday mosque of kandahar kandahar province kandahar 1750                houses the cloak of the islamic prophet muhammad\\n     2     omar al-farooq mosque kandahar province kandahar 2014 built on the site that was a popular cinema of kandahar . [ 1 ]\\n*/\\n\\nCREATE VIRTUAL TABLE \"documents\" USING fts5(title, content, tokenize = \\'trigram\\')',\n        \"question\": \"Who were the builders of the mosque in Herat with fire temples ?\",\n        \"blendsql\": \"\"\"\n        {{\n            LLMQA(\n                'Who were the builders of the mosque?',\n                (\n                    SELECT documents.title AS 'Building', documents.content FROM documents\n                    JOIN {{\n                        LLMJoin(\n                            left_on='w::name',\n                            right_on='documents::title'\n                        )\n                    }}\n                    WHERE w.city = 'herat' AND w.remarks LIKE '%fire temple%'\n                )\n            )\n        }}\n        \"\"\",\n    },\n    {\n        \"serialized_db\": 'CREATE TABLE \"w\" (\\n\"index\" INTEGER,\\n  \"no\" INTEGER,\\n  \"rider\" TEXT,\\n  \"team\" TEXT,\\n  \"motorcycle\" TEXT\\n)\\n/*\\n3 example rows:\\nSELECT * FROM w LIMIT 3\\n index  no          rider                 team      motorcycle\\n     0   1   carl fogarty   ducati performance      ducati 996\\n     1   4 akira yanagawa kawasaki racing team kawasaki zx-7rr\\n     2   5  colin edwards        castrol honda      honda rc45\\n*/\\n\\nCREATE VIRTUAL TABLE \"documents\" USING fts5(title, content, tokenize = \\'trigram\\')',\n        \"question\": \"After what season did the number 7 competitor retire ?\",\n        \"blendsql\": \"\"\"\n        {{\n            LLMQA(\n                'When did the competitor retire?',\n                (\n                    SELECT documents.title AS 'Competitor', documents.content FROM documents\n                    JOIN {{\n                        LLMJoin(\n                            left_on='w::rider',\n                            right_on='documents::title'\n                        )\n                    }}\n                    WHERE w.no = 7\n                )\n            )\n        }}\n        \"\"\",\n    },\n    {\n        \"serialized_db\": 'CREATE TABLE \"w\" (\\n\"index\" INTEGER,\\n  \"year\" TEXT,\\n  \"winner\" TEXT,\\n  \"position\" TEXT,\\n  \"school\" TEXT\\n)\\n/*\\n3 example rows:\\nSELECT * FROM w LIMIT 3\\n index    year         winner   position     school\\n     0 1961-62       ron ryan right wing      colby\\n     1 1962-63 bob brinkworth     center rensselaer\\n     2 1963-64 bob brinkworth     center rensselaer\\n*/\\n\\nCREATE VIRTUAL TABLE \"documents\" USING fts5(title, content, tokenize = \\'trigram\\')',\n        \"question\": \"What year was the 1971-72 ECAC Hockey Player of the Year born ?\",\n        \"blendsql\": \"\"\"\n        {{\n            LLMQA(\n                'What year was the player born?',\n                (\n                    SELECT documents.title AS 'Player', documents.content FROM documents\n                    JOIN {{\n                        LLMJoin(\n                            left_on = 'w::winner',\n                            right_on = 'documents::title'\n                        )\n                    }}\n                    WHERE w.year = '1971-72'\n                )\n            )\n        }}\n        \"\"\",\n    },\n    {\n        \"serialized_db\": 'CREATE TABLE \"w\" (\\n\"index\" INTEGER,\\n  \"date\" TEXT,\\n  \"language\" TEXT,\\n  \"language family\" TEXT,\\n  \"region\" TEXT\\n)\\n/*\\n3 example rows:\\nSELECT * FROM w LIMIT 3\\n index                     date language language family      region\\n     0 early 2nd millennium bce sumerian         isolate mesopotamia\\n     1       2nd millennium bce  eblaite         semitic       syria\\n     2            ca . 1100 bce  hittite       anatolian    anatolia\\n*/\\n\\nCREATE VIRTUAL TABLE \"documents\" USING fts5(title, content, tokenize = \\'trigram\\')',\n        \"question\": \"What was the language family that was used in Hattusa , as well as parts of the northern Levant and Upper Mesopotamia ?\",\n        \"blendsql\": \"\"\"\n        SELECT \"language family\" FROM w\n        WHERE language = {{\n            LLMQA(\n                'Which language was used in Hattusa, as well as parts of the northern Levant and Upper Mesopotamia ?',\n                (SELECT title, content FROM documents WHERE documents MATCH 'hattusa'),\n                options='w::language'\n            )\n        }}\n       \"\"\",\n    },\n]\n</pre> # 1) Define our few-shot examples examples = [    {         \"serialized_db\": 'CREATE TABLE \"w\" (\\n\"index\" INTEGER,\\n  \"name\" TEXT,\\n  \"province\" TEXT,\\n  \"city\" TEXT,\\n  \"year\" TEXT,\\n  \"remarks\" TEXT\\n)\\n/*\\n3 example rows:\\nSELECT * FROM w LIMIT 3\\n index                      name          province     city year                                                         remarks\\n     0       abdul rahman mosque    kabul province    kabul 2009                                   largest mosque in afghanistan\\n     1 friday mosque of kandahar kandahar province kandahar 1750                houses the cloak of the islamic prophet muhammad\\n     2     omar al-farooq mosque kandahar province kandahar 2014 built on the site that was a popular cinema of kandahar . [ 1 ]\\n*/\\n\\nCREATE VIRTUAL TABLE \"documents\" USING fts5(title, content, tokenize = \\'trigram\\')',         \"question\": \"Who were the builders of the mosque in Herat with fire temples ?\",         \"blendsql\": \"\"\"         {{             LLMQA(                 'Who were the builders of the mosque?',                 (                     SELECT documents.title AS 'Building', documents.content FROM documents                     JOIN {{                         LLMJoin(                             left_on='w::name',                             right_on='documents::title'                         )                     }}                     WHERE w.city = 'herat' AND w.remarks LIKE '%fire temple%'                 )             )         }}         \"\"\",     },     {         \"serialized_db\": 'CREATE TABLE \"w\" (\\n\"index\" INTEGER,\\n  \"no\" INTEGER,\\n  \"rider\" TEXT,\\n  \"team\" TEXT,\\n  \"motorcycle\" TEXT\\n)\\n/*\\n3 example rows:\\nSELECT * FROM w LIMIT 3\\n index  no          rider                 team      motorcycle\\n     0   1   carl fogarty   ducati performance      ducati 996\\n     1   4 akira yanagawa kawasaki racing team kawasaki zx-7rr\\n     2   5  colin edwards        castrol honda      honda rc45\\n*/\\n\\nCREATE VIRTUAL TABLE \"documents\" USING fts5(title, content, tokenize = \\'trigram\\')',         \"question\": \"After what season did the number 7 competitor retire ?\",         \"blendsql\": \"\"\"         {{             LLMQA(                 'When did the competitor retire?',                 (                     SELECT documents.title AS 'Competitor', documents.content FROM documents                     JOIN {{                         LLMJoin(                             left_on='w::rider',                             right_on='documents::title'                         )                     }}                     WHERE w.no = 7                 )             )         }}         \"\"\",     },     {         \"serialized_db\": 'CREATE TABLE \"w\" (\\n\"index\" INTEGER,\\n  \"year\" TEXT,\\n  \"winner\" TEXT,\\n  \"position\" TEXT,\\n  \"school\" TEXT\\n)\\n/*\\n3 example rows:\\nSELECT * FROM w LIMIT 3\\n index    year         winner   position     school\\n     0 1961-62       ron ryan right wing      colby\\n     1 1962-63 bob brinkworth     center rensselaer\\n     2 1963-64 bob brinkworth     center rensselaer\\n*/\\n\\nCREATE VIRTUAL TABLE \"documents\" USING fts5(title, content, tokenize = \\'trigram\\')',         \"question\": \"What year was the 1971-72 ECAC Hockey Player of the Year born ?\",         \"blendsql\": \"\"\"         {{             LLMQA(                 'What year was the player born?',                 (                     SELECT documents.title AS 'Player', documents.content FROM documents                     JOIN {{                         LLMJoin(                             left_on = 'w::winner',                             right_on = 'documents::title'                         )                     }}                     WHERE w.year = '1971-72'                 )             )         }}         \"\"\",     },     {         \"serialized_db\": 'CREATE TABLE \"w\" (\\n\"index\" INTEGER,\\n  \"date\" TEXT,\\n  \"language\" TEXT,\\n  \"language family\" TEXT,\\n  \"region\" TEXT\\n)\\n/*\\n3 example rows:\\nSELECT * FROM w LIMIT 3\\n index                     date language language family      region\\n     0 early 2nd millennium bce sumerian         isolate mesopotamia\\n     1       2nd millennium bce  eblaite         semitic       syria\\n     2            ca . 1100 bce  hittite       anatolian    anatolia\\n*/\\n\\nCREATE VIRTUAL TABLE \"documents\" USING fts5(title, content, tokenize = \\'trigram\\')',         \"question\": \"What was the language family that was used in Hattusa , as well as parts of the northern Levant and Upper Mesopotamia ?\",         \"blendsql\": \"\"\"         SELECT \"language family\" FROM w         WHERE language = {{             LLMQA(                 'Which language was used in Hattusa, as well as parts of the northern Levant and Upper Mesopotamia ?',                 (SELECT title, content FROM documents WHERE documents MATCH 'hattusa'),                 options='w::language'             )         }}        \"\"\",     }, ] In\u00a0[16]: Copied! <pre># 2) Define our prompt to the Parser LLM\nclass ParserProgram(Program):\n    def __call__(self, model: Model, examples: List[dict], serialized_db: str, question: str, **kwargs):\n        prompt = \"\"\n        prompt += dedent(\"\"\"\n        Generate BlendSQL given the question, table, and passages to answer the question correctly.\n        BlendSQL is a superset of SQLite, which adds external function calls for information not found within native SQLite.\n        These external functions should be wrapped in double curly brackets.\n\n        If question-relevant column(s) contents are not suitable for SQL comparisons or calculations, map it to a new column with clean content by a new grammar:\n            `LLMMap('question', '{table}::{column}')`\n\n        If mapping to a new column still cannot answer the question with valid SQL, turn to an end-to-end solution using a new grammar:\n            `LLMQA('{question}', ({blendsql}))`\n\n        If we need to do a `join` operation where there is imperfect alignment between table values, use the new grammar:\n            `LLMJoin(({blendsql}), options='{table}::{column}')`\n\n        ONLY use these BlendSQL ingredients if necessary.\n        Answer parts of the question in vanilla SQL, if possible.\n\n        Examples:\\n\n        \"\"\")\n        for example in examples:\n            prompt += f\"{example['serialized_db']}\\n\\n\"\n            prompt += f\"Question: {example['question']}\\n\"\n            prompt += f\"BlendSQL: {example['blendsql']}\\n\"\n        prompt += f\"{serialized_db}\\n\\n\"\n        prompt += f\"Question: {question}\\n\"\n        prompt += f\"BlendSQL: \"\n        generator = outlines.generate.text(model.model_obj)\n        result = generator(prompt)\n        return (result, prompt)\n</pre> # 2) Define our prompt to the Parser LLM class ParserProgram(Program):     def __call__(self, model: Model, examples: List[dict], serialized_db: str, question: str, **kwargs):         prompt = \"\"         prompt += dedent(\"\"\"         Generate BlendSQL given the question, table, and passages to answer the question correctly.         BlendSQL is a superset of SQLite, which adds external function calls for information not found within native SQLite.         These external functions should be wrapped in double curly brackets.          If question-relevant column(s) contents are not suitable for SQL comparisons or calculations, map it to a new column with clean content by a new grammar:             `LLMMap('question', '{table}::{column}')`          If mapping to a new column still cannot answer the question with valid SQL, turn to an end-to-end solution using a new grammar:             `LLMQA('{question}', ({blendsql}))`          If we need to do a `join` operation where there is imperfect alignment between table values, use the new grammar:             `LLMJoin(({blendsql}), options='{table}::{column}')`          ONLY use these BlendSQL ingredients if necessary.         Answer parts of the question in vanilla SQL, if possible.          Examples:\\n         \"\"\")         for example in examples:             prompt += f\"{example['serialized_db']}\\n\\n\"             prompt += f\"Question: {example['question']}\\n\"             prompt += f\"BlendSQL: {example['blendsql']}\\n\"         prompt += f\"{serialized_db}\\n\\n\"         prompt += f\"Question: {question}\\n\"         prompt += f\"BlendSQL: \"         generator = outlines.generate.text(model.model_obj)         result = generator(prompt)         return (result, prompt) In\u00a0[17]: Copied! <pre>def few_shot_blendsql(question: str, db: SQLite, parser: Model, blender: Model):\n    # 3) Call the parser with our prompt\n    predicted_query = parser.predict(\n        program=ParserProgram,\n        serialized_db=db.to_serialized(),\n        question=question,\n        examples=examples\n    )\n    # 4) Execute the BlendSQL query to get the final answer\n    smoothie = blend(\n        query=predicted_query,\n        db=db,\n        ingredients={LLMMap, LLMQA, LLMJoin},\n        verbose=False,\n        default_model=blender\n    )\n    return (predicted_query, smoothie)\n</pre> def few_shot_blendsql(question: str, db: SQLite, parser: Model, blender: Model):     # 3) Call the parser with our prompt     predicted_query = parser.predict(         program=ParserProgram,         serialized_db=db.to_serialized(),         question=question,         examples=examples     )     # 4) Execute the BlendSQL query to get the final answer     smoothie = blend(         query=predicted_query,         db=db,         ingredients={LLMMap, LLMQA, LLMJoin},         verbose=False,         default_model=blender     )     return (predicted_query, smoothie) In\u00a0[18]: Copied! <pre>blendsql, smoothie = few_shot_blendsql(\n    question=\"What team did New Zealand play in the city featuring the Mount Panorama racetrack ?\",\n    db=SQLite(fetch_from_hub(\"1884_New_Zealand_rugby_union_tour_of_New_South_Wales_1.db\")),\n    default_model=OpenaiLLM(\"gpt-3.5-turbo\"),\n    parser=OpenaiLLM(\"gpt-3.5-turbo\")\n)\n</pre> blendsql, smoothie = few_shot_blendsql(     question=\"What team did New Zealand play in the city featuring the Mount Panorama racetrack ?\",     db=SQLite(fetch_from_hub(\"1884_New_Zealand_rugby_union_tour_of_New_South_Wales_1.db\")),     default_model=OpenaiLLM(\"gpt-3.5-turbo\"),     parser=OpenaiLLM(\"gpt-3.5-turbo\") ) In\u00a0[19]: Copied! <pre>print(blendsql)\n</pre> print(blendsql) <pre>SELECT rival \nFROM w \nWHERE city = {{\n    LLMQA(\n        'What city features the Mount Panorama racetrack?',\n        (SELECT title, content FROM documents WHERE documents MATCH 'mount panorama racetrack'),\n        options='w::city'\n    )\n}}\n</pre> In\u00a0[20]: Copied! <pre>smoothie.df\n</pre> smoothie.df Out[20]: rival 0 western districts"},{"location":"reference/examples/teaching-blendsql-via-in-context-learning/#teaching-blendsql-via-in-context-learning","title":"Teaching BlendSQL via In-Context Learning\u00b6","text":"<p>As described in our paper, the real power of BlendSQL comes when it is used as an intermediate representation for tasks requiring complex reasoning across many different forms of data.</p> <p>In this notebook, we show an example of how we can 'teach' an instruction-finetuned language model how to write with this new dialect of SQL. Our pipeline can be summarized as:</p> <ol> <li>Define few-shot examples, using our dataset</li> <li>Design a prompt for our Parser LLM, which explains the task we want it to achieve</li> <li>Call our Parser with our prompt + a question to get a BlendSQL query</li> <li>Execute the BlendSQL query with <code>blend()</code> to retrieve the final answer</li> </ol>"},{"location":"reference/examples/vqa-ingredient/","title":"Custom VQA Ingredient with LLaVA","text":"In\u00a0[1]: Copied! <pre>from typing import List\nfrom blendsql import blend\nfrom blendsql.models import TransformersLLM, ModelObj\nfrom blendsql.ingredients import MapIngredient, IngredientException\nfrom blendsql.utils import fetch_from_hub\nfrom blendsql.db import SQLite\n</pre> from typing import List from blendsql import blend from blendsql.models import TransformersLLM, ModelObj from blendsql.ingredients import MapIngredient, IngredientException from blendsql.utils import fetch_from_hub from blendsql.db import SQLite In\u00a0[2]: Copied! <pre>db = SQLite(fetch_from_hub(\"Fountains_in_Portland,_Oregon_0.db\"))\n</pre> db = SQLite(fetch_from_hub(\"Fountains_in_Portland,_Oregon_0.db\")) In\u00a0[3]: Copied! <pre>db.execute_to_df(\"SELECT * FROM w;\")\n</pre> db.execute_to_df(\"SELECT * FROM w;\") Out[3]: index title designer ( s ) year 0 0 animals in pools georgia gerber 1986 1 1 the car wash ( officially untitled ) carter , hull , nishita , mcculley and baxter 1977 2 2 the dreamer manuel izquierdo 1979 3 3 elk roland hinton perry 1900 4 4 holladay park fountain tim clemen ( murase associates ) 2000 5 5 keller fountain angela danadjieba ( lawrence halprin associates ) 1971 6 6 kelly fountain lee kelly 1977 7 7 lovejoy fountain lawrence halprin associates 1968 8 8 mccoy fountain murase associates 2000 9 9 pioneer courthouse square waterfall fountain will martin 1983 10 10 the rose petal none 1978 11 11 salmon street springs robert perron landscape architects 1988 12 12 shemanski fountain ( rebecca at the well ) carl l. linde oliver laurence barrett 1926 ( 1928 ) 13 13 skidmore fountain olin levi warner 1888 In\u00a0[29]: Copied! <pre>try:\n    from PIL import Image\nexcept:\n    print(\"Installing pillow...\")\n    !pip install pillow\n    from PIL import Image\n# Create our custom ingredient as a child of `MapIngredient`\nfrom io import BytesIO\nfrom transformers import pipeline\n\nclass VQAModel(TransformersLLM):\n    \n    def _load_model(self) -&gt; ModelObj:\n        return pipeline(\"image-to-text\", model=self.model_name_or_path)\n\n    def predict(self, question: str, img_bytes: List[bytes]) -&gt; str:\n        prompt = f\"USER: &lt;image&gt;\\n{question}\"\n        model_output = self.model_obj(\n            images=[\n                Image.open(BytesIO(value)) for value in img_bytes\n            ],\n            prompt=prompt,\n            generate_kwargs={\"max_new_tokens\": 200}\n        )\n        return [output[0][\"generated_text\"].lstrip(prompt).strip() for output in model_output]\n\nclass VQA(MapIngredient):\n    def run(self, model: VQAModel, question: str, values: List[bytes], **kwargs):\n        \"\"\"Given a list of byte arrays, calls a tiny Llava model\n        to answer a given question.\n        \"\"\"\n        if not all(isinstance(value, bytes) for value in values):\n            raise IngredientException(f\"All values must be 'byte' type for LlavaVQA!\")\n        model_output = model.predict(question=question, img_bytes=values)\n        return model_output\n</pre> try:     from PIL import Image except:     print(\"Installing pillow...\")     !pip install pillow     from PIL import Image # Create our custom ingredient as a child of `MapIngredient` from io import BytesIO from transformers import pipeline  class VQAModel(TransformersLLM):          def _load_model(self) -&gt; ModelObj:         return pipeline(\"image-to-text\", model=self.model_name_or_path)      def predict(self, question: str, img_bytes: List[bytes]) -&gt; str:         prompt = f\"USER: \\n{question}\"         model_output = self.model_obj(             images=[                 Image.open(BytesIO(value)) for value in img_bytes             ],             prompt=prompt,             generate_kwargs={\"max_new_tokens\": 200}         )         return [output[0][\"generated_text\"].lstrip(prompt).strip() for output in model_output]  class VQA(MapIngredient):     def run(self, model: VQAModel, question: str, values: List[bytes], **kwargs):         \"\"\"Given a list of byte arrays, calls a tiny Llava model         to answer a given question.         \"\"\"         if not all(isinstance(value, bytes) for value in values):             raise IngredientException(f\"All values must be 'byte' type for LlavaVQA!\")         model_output = model.predict(question=question, img_bytes=values)         return model_output In\u00a0[30]: Copied! <pre># Initialize our VQA model\nmodel = VQAModel(model_name_or_path=\"bczhou/tiny-llava-v1-hf\")\n</pre> # Initialize our VQA model model = VQAModel(model_name_or_path=\"bczhou/tiny-llava-v1-hf\") <pre>Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n</pre> In\u00a0[31]: Copied! <pre>b = db.execute_to_list(\"SELECT img_bytes FROM images WHERE title = 'the car wash ( officially untitled )'\")[0]\nImage.open(BytesIO(b))\n</pre> b = db.execute_to_list(\"SELECT img_bytes FROM images WHERE title = 'the car wash ( officially untitled )'\")[0] Image.open(BytesIO(b)) Out[31]: In\u00a0[\u00a0]: Copied! <pre>smoothie = blend(\n    query=\"\"\"\n    SELECT {{VQA('What is in this image?', 'images::img_bytes')}}\n        FROM images WHERE title = 'the car wash ( officially untitled )'\n    \"\"\",\n    db=db,\n    ingredients={VQA},\n    default_model=model\n)\n</pre> smoothie = blend(     query=\"\"\"     SELECT {{VQA('What is in this image?', 'images::img_bytes')}}         FROM images WHERE title = 'the car wash ( officially untitled )'     \"\"\",     db=db,     ingredients={VQA},     default_model=model ) In\u00a0[33]: Copied! <pre>smoothie.df.values[0][0]\n</pre> smoothie.df.values[0][0] Out[33]: <pre>'A large, curved, waterfall-like fountain is located in a park. The fountain is surrounded by a concrete walkway, and it is surrounded by trees.'</pre> In\u00a0[20]: Copied! <pre>b = db.execute_query(\"SELECT img_bytes FROM images WHERE title = 'animals in pools'\").values[0][0]\nImage.open(BytesIO(b))\n</pre> b = db.execute_query(\"SELECT img_bytes FROM images WHERE title = 'animals in pools'\").values[0][0] Image.open(BytesIO(b)) Out[20]: In\u00a0[22]: Copied! <pre># How many animals are in the fountain designed by Georgia Gerber?\nsmoothie = blend(\n    query=\"\"\"\n    SELECT w.title, w.\"designer ( s )\", {{VQA('How many animals are in this fountain?', 'images::img_bytes')}}\n        FROM images JOIN w ON w.title = images.title\n        WHERE \"designer ( s )\" = 'georgia gerber'\n    \"\"\",\n    db=db,\n    ingredients={VQA},\n    default_model=model\n)\n</pre> # How many animals are in the fountain designed by Georgia Gerber? smoothie = blend(     query=\"\"\"     SELECT w.title, w.\"designer ( s )\", {{VQA('How many animals are in this fountain?', 'images::img_bytes')}}         FROM images JOIN w ON w.title = images.title         WHERE \"designer ( s )\" = 'georgia gerber'     \"\"\",     db=db,     ingredients={VQA},     default_model=model ) In\u00a0[23]: Copied! <pre>smoothie.df\n</pre> smoothie.df Out[23]: title designer ( s ) How many animals are in this fountain? 0 animals in pools georgia gerber There are three animals in the fountain."},{"location":"reference/examples/vqa-ingredient/#custom-vqa-ingredient-with-llava","title":"Custom VQA Ingredient with LLaVA\u00b6","text":"<p>Below, we use BlendSQL on a multi-table database containing data from https://en.wikipedia.org/wiki/Fountains_in_Portland,_Oregon.</p> <ul> <li><code>w</code>: Structured data</li> <li><code>documents</code>: Unstructured article content</li> <li><code>images</code>: Images stored as bytes from the article</li> </ul> <p>We demonstrate how BlendSQL can be used to call a tiny VQA (visual question-answering) model (https://huggingface.co/bczhou/tiny-llava-v1-hf) and do reasoning over various forms of data.</p> <p>This is a simple example of the approach taken in EHRXQA: A Multi-Modal Question Answering Dataset for Electronic Health Records with Chest X-ray Images</p>"},{"location":"reference/examples/vqa-ingredient/#simple-image-description","title":"Simple Image Description\u00b6","text":""},{"location":"reference/examples/vqa-ingredient/#multi-hop-multi-modal-reasoning","title":"Multi-hop, Multi-modal Reasoning\u00b6","text":""},{"location":"reference/ingredients/creating-custom-ingredients/","title":"Creating Custom BlendSQL Ingredients","text":"<p>All the built-in LLM ingredients inherit from the base classes <code>QAIngredient</code>, <code>MapIngredient</code>, <code>JoinIngredient</code>, and <code>AliasIngredient</code>.</p> <p>These are intended to be helpful abstractions, so that the user can easily implement their own functions to run within a BlendSQL script.</p> <p>The processing logic for a custom ingredient should go in a <code>run()</code> class function, and accept <code>**kwargs</code> in their signature.</p>"},{"location":"reference/ingredients/creating-custom-ingredients/#aliasingredient","title":"AliasIngredient","text":"<p>               Bases: <code>Ingredient</code></p> <p>This ingredient performs no other function than to act as a stand-in for complex chainings of other ingredients. This allows us (or our lms) to write less verbose BlendSQL queries, while maximizing the information we embed.</p> <p>The <code>run()</code> function should return a tuple containing both the query text that should get subbed in, and any ingredient classes which are dependencies for executing the aliased query.</p> <p>Examples:</p> <pre><code>from textwrap import dedent\nfrom typing import Tuple, Collection\n\nfrom blendsql.ingredients import AliasIngredient, LLMQA\n\nclass FetchDefinition(AliasIngredient):\n    def run(self, term: str, *args, **kwargs) -&gt; Tuple[str, Collection[Ingredient]]:\n        new_query = dedent(\n        f\"\"\"\n        {{{{\n            LLMQA(\n                \"What does {term} mean?\"\n            )\n        }}}}\n        \"\"\")\n        ingredient_dependencies = {LLMQA}\n        return (new_query, ingredient_dependencies)\n\n# Now, we can use the ingredient like below\nblendsql_query = \"\"\"\nSELECT {{FetchDefinition('delve')}} AS \"Definition\"\n\"\"\"\n</code></pre> Source code in <code>blendsql/ingredients/ingredient.py</code> <pre><code>@attrs\nclass AliasIngredient(Ingredient):\n    '''This ingredient performs no other function than to act as a stand-in for\n    complex chainings of other ingredients. This allows us (or our lms) to write less verbose\n    BlendSQL queries, while maximizing the information we embed.\n\n    The `run()` function should return a tuple containing both the query text that should get subbed in,\n    and any ingredient classes which are dependencies for executing the aliased query.\n\n    Examples:\n        ```python\n        from textwrap import dedent\n        from typing import Tuple, Collection\n\n        from blendsql.ingredients import AliasIngredient, LLMQA\n\n        class FetchDefinition(AliasIngredient):\n            def run(self, term: str, *args, **kwargs) -&gt; Tuple[str, Collection[Ingredient]]:\n                new_query = dedent(\n                f\"\"\"\n                {{{{\n                    LLMQA(\n                        \"What does {term} mean?\"\n                    )\n                }}}}\n                \"\"\")\n                ingredient_dependencies = {LLMQA}\n                return (new_query, ingredient_dependencies)\n\n        # Now, we can use the ingredient like below\n        blendsql_query = \"\"\"\n        SELECT {{FetchDefinition('delve')}} AS \"Definition\"\n        \"\"\"\n        ```\n    '''\n\n    ingredient_type: str = IngredientType.ALIAS.value\n    allowed_output_types: t.Tuple[t.Type] = (t.Tuple[str, Collection[Ingredient]],)\n\n    def __call__(self, *args, **kwargs):\n        return self._run(*args, **kwargs)\n</code></pre>"},{"location":"reference/ingredients/creating-custom-ingredients/#qaingredient","title":"QAIngredient","text":"<p>               Bases: <code>Ingredient</code></p> <p>Given a table subset in the form of a pd.DataFrame 'context', returns a scalar or array of scalars (in the form of a tuple).</p> <p>Useful for end-to-end question answering tasks.</p> Source code in <code>blendsql/ingredients/ingredient.py</code> <pre><code>@attrs\nclass QAIngredient(Ingredient):\n    \"\"\"\n    Given a table subset in the form of a pd.DataFrame 'context',\n    returns a scalar or array of scalars (in the form of a tuple).\n\n    Useful for end-to-end question answering tasks.\n    \"\"\"\n\n    ingredient_type: str = IngredientType.QA.value\n    allowed_output_types: t.Tuple[t.Type] = (t.Union[str, int, float, tuple],)\n\n    def __call__(\n        self,\n        question: t.Optional[str] = None,\n        *context: t.Union[str, pd.DataFrame],\n        options: t.Optional[t.Union[list, str]] = None,\n        **kwargs,\n    ) -&gt; t.Tuple[t.Union[str, int, float, tuple], t.Optional[exp.Expression]]:\n        # Unpack kwargs\n        # Extract single `context` from kwargs if provided\n        if \"context\" in kwargs:\n            context_kwarg = kwargs.pop(\"context\")\n            # Combine positional and keyword context\n            if isinstance(context_kwarg, (list, tuple)):\n                context = context + tuple(context_kwarg)\n            else:\n                context = context + (context_kwarg,)\n        aliases_to_tablenames: t.Dict[str, str] = kwargs[\"aliases_to_tablenames\"]\n\n        subtables: t.List[pd.DataFrame] = []\n        for _context in context:\n            if isinstance(_context, ColumnRef):\n                tablename, colname = utils.get_tablename_colname(_context)\n                tablename = aliases_to_tablenames.get(tablename, tablename)\n                # Optionally materialize a CTE\n                if tablename in self.db.lazy_tables:\n                    materialized_smoothie = self.db.lazy_tables.pop(tablename).collect()\n                    self.num_values_passed += (\n                        materialized_smoothie.meta.num_values_passed\n                    )\n                    subtable: pd.DataFrame = pd.DataFrame(\n                        materialized_smoothie.df[colname]\n                    )\n                else:\n                    subtable: pd.DataFrame = self.db.execute_to_df(\n                        f'SELECT \"{colname}\" FROM \"{tablename}\"'\n                    )\n            elif isinstance(_context, pd.DataFrame):\n                subtable: pd.DataFrame = _context\n            else:\n                subtable = pd.DataFrame([{\"_col\": _context}])\n            if subtable.empty:\n                raise IngredientException(\"Empty subtable passed to QAIngredient!\")\n            self.num_values_passed += len(subtable)\n            subtables.append(subtable)\n\n        if options is not None:\n            options = self.unpack_options(\n                options=options,\n                aliases_to_tablenames=aliases_to_tablenames,\n            )\n\n        if question is not None:\n            if \"{}\" in question:\n                if len(subtables) == 0:\n                    raise IngredientException(\n                        f\"Passed question with string template '{question}', but no context was passed to fill!\"\n                    )\n                unpacked_values = []\n                for subtable in subtables:\n                    curr_values = list(subtable.values.flat)\n                    if len(curr_values) &gt; 1:\n                        logger.debug(\n                            Fore.RED\n                            + f\"More than 1 value found in {question}: {curr_values[:10]}\\nThis could be a sign of a malformed query.\"\n                            + Fore.RESET\n                        )\n                    unpacked_values.append(curr_values[0])\n                question = question.format(*unpacked_values)\n                logger.debug(\n                    Fore.LIGHTBLACK_EX\n                    + f\"Unpacked question to '{question}'\"\n                    + Fore.RESET\n                )\n                # This will now override whatever context we passed\n                subtables = []\n\n        response: t.Union[str, int, float, tuple] = self._run(\n            question=question,\n            context=subtables if len(subtables) &gt; 0 else None,\n            options=options,\n            **self.__dict__ | kwargs,\n        )\n        if isinstance(response, tuple):\n            response = format_tuple(\n                response, kwargs.get(\"wrap_tuple_in_parentheses\", True)\n            )\n        return response\n\n    @abstractmethod\n    def run(self, *args, **kwargs) -&gt; t.Union[str, int, float, tuple]:\n        ...\n</code></pre>"},{"location":"reference/ingredients/creating-custom-ingredients/#mapingredient","title":"MapIngredient","text":"<p>               Bases: <code>Ingredient</code></p> <p>For a given table/column pair, maps an external function to each of the given values, creating a new column.</p> <p>Examples:</p> <pre><code>from typing import List\nfrom blendsql.ingredients import MapIngredient\nimport requests\n\n\nclass GetQRCode(MapIngredient):\n    \"\"\"Calls API to generate QR code for a given URL.\n    Saves bytes to file in qr_codes/ and returns list of paths.\n    https://goqr.me/api/doc/create-qr-code/\"\"\"\n\n\n    def run(self, values: List[str], **kwargs) -&gt; List[str]:\n        imgs_as_bytes = []\n        for value in values:\n            qr_code_bytes = requests.get(\n                \"https://api.qrserver.com/v1/create-qr-code/?data=https://{}/&amp;size=100x100\".format(value)\n            ).content\n            imgs_as_bytes.append(qr_code_bytes)\n        return imgs_as_bytes\n\n\n    if __name__ == \"__main__\":\n        from blendsql import BlendSQL\n        from blendsql.db import SQLite\n        from blendsql.utils import fetch_from_hub\n\n        bsql = BlendSQL(fetch_from_hub('urls.db'), ingredients={GetQRCode})\n\n        smoothie = bsql.execute(\"SELECT genre, url, {{GetQRCode('QR Code as Bytes:', 'w::url')}} FROM w WHERE genre = 'social'\")\n\n        smoothie.df\n        # | genre  | url           | QR Code as Bytes:      |\n        # |--------|---------------|-----------------------|\n        # | social | facebook.com  | b'...'                |\n</code></pre> Source code in <code>blendsql/ingredients/ingredient.py</code> <pre><code>@attrs\nclass MapIngredient(Ingredient):\n    '''For a given table/column pair, maps an external function\n    to each of the given values, creating a new column.\n\n    Examples:\n        ```python\n        from typing import List\n        from blendsql.ingredients import MapIngredient\n        import requests\n\n\n        class GetQRCode(MapIngredient):\n            \"\"\"Calls API to generate QR code for a given URL.\n            Saves bytes to file in qr_codes/ and returns list of paths.\n            https://goqr.me/api/doc/create-qr-code/\"\"\"\n\n\n            def run(self, values: List[str], **kwargs) -&gt; List[str]:\n                imgs_as_bytes = []\n                for value in values:\n                    qr_code_bytes = requests.get(\n                        \"https://api.qrserver.com/v1/create-qr-code/?data=https://{}/&amp;size=100x100\".format(value)\n                    ).content\n                    imgs_as_bytes.append(qr_code_bytes)\n                return imgs_as_bytes\n\n\n            if __name__ == \"__main__\":\n                from blendsql import BlendSQL\n                from blendsql.db import SQLite\n                from blendsql.utils import fetch_from_hub\n\n                bsql = BlendSQL(fetch_from_hub('urls.db'), ingredients={GetQRCode})\n\n                smoothie = bsql.execute(\"SELECT genre, url, {{GetQRCode('QR Code as Bytes:', 'w::url')}} FROM w WHERE genre = 'social'\")\n\n                smoothie.df\n                # | genre  | url           | QR Code as Bytes:      |\n                # |--------|---------------|-----------------------|\n                # | social | facebook.com  | b'...'                |\n        ```\n    '''\n\n    ingredient_type: str = IngredientType.MAP.value\n    allowed_output_types: t.Tuple[t.Type] = (t.Iterable[t.Any],)\n\n    def unpack_default_kwargs(self, **kwargs):\n        return unpack_default_kwargs(**kwargs)\n\n    def __call__(\n        self,\n        question: t.Optional[str] = None,\n        values: t.Optional[t.Union[ColumnRef]] = None,\n        *context: t.Union[str, pd.DataFrame],\n        options: t.Optional[t.Union[ColumnRef, list]] = None,\n        **kwargs,\n    ) -&gt; tuple:\n        \"\"\"Returns tuple with format (arg, tablename, colname, new_table)\"\"\"\n        # Unpack kwargs\n        # Extract single `context` from kwargs if provided\n        if \"context\" in kwargs:\n            context_kwarg = kwargs.pop(\"context\")\n            # Combine positional and keyword context\n            if isinstance(context_kwarg, (list, tuple)):\n                context = context + tuple(context_kwarg)\n            else:\n                context = context + (context_kwarg,)\n\n        context_was_passed = len(context) &gt; 0\n        aliases_to_tablenames: t.Dict[str, str] = kwargs[\"aliases_to_tablenames\"]\n        get_temp_subquery_table: t.Callable = kwargs[\"get_temp_subquery_table\"]\n        get_temp_session_table: t.Callable = kwargs[\"get_temp_session_table\"]\n        prev_subquery_map_columns: t.Set[str] = kwargs[\"prev_subquery_map_columns\"]\n\n        # TODO: make sure we support all types of ValueArray references here\n        tablename, colname = utils.get_tablename_colname(values)\n        tablename = aliases_to_tablenames.get(tablename, tablename)\n\n        # Check for previously created temporary tables\n        value_source_tablename, _ = self.maybe_get_temp_table(\n            temp_table_func=get_temp_subquery_table, tablename=tablename\n        )\n        temp_session_tablename, temp_session_table_exists = self.maybe_get_temp_table(\n            temp_table_func=get_temp_session_table, tablename=tablename\n        )\n\n        # Optionally materialize a CTE\n        if tablename in self.db.lazy_tables:\n            materialized_smoothie = self.db.lazy_tables.pop(tablename).collect()\n            self.num_values_passed += materialized_smoothie.meta.num_values_passed\n            original_table = materialized_smoothie.df\n        else:\n            original_table = self.db.execute_to_df(\n                select_all_from_table_query(tablename)\n            )\n\n        # Need to be sure the new column doesn't already exist here\n        new_arg_column = question or str(uuid.uuid4())[:4]\n        while (\n            new_arg_column in set(self.db.iter_columns(tablename))\n            or new_arg_column in prev_subquery_map_columns\n        ):\n            new_arg_column = \"_\" + new_arg_column\n\n        if context_was_passed:\n            all_context_colnames = []\n            for _context in context:\n                if isinstance(_context, ColumnRef):\n                    _, context_colname = utils.get_tablename_colname(_context)\n                    all_context_colnames.append(context_colname)\n                else:\n                    raise ValueError(\n                        f\"Not sure what to do with context arg passed to MapIngredient: {_context}\"\n                    )\n            select_distinct_fn = lambda q: self.db.execute_to_df(q)\n            select_distinct_arg = (\n                f'\"{colname}\"'\n                + \", \"\n                + \", \".join([f'\"{c}\"' for c in all_context_colnames])\n            )\n        else:\n            select_distinct_fn = lambda q: self.db.execute_to_list(q)\n            select_distinct_arg = f'\"{colname}\"'\n\n        # Get a list of values to map\n        # First, check if we've already dumped some `MapIngredient` output to the main session table\n        if temp_session_table_exists:\n            temp_session_table = self.db.execute_to_df(\n                select_all_from_table_query(temp_session_tablename)\n            )\n            # We don't need to run this function on everything,\n            #   if a previous subquery already got to certain values\n            if new_arg_column in temp_session_table.columns:\n                distinct_values = select_distinct_fn(\n                    f'SELECT DISTINCT {select_distinct_arg} FROM \"{temp_session_tablename}\" WHERE \"{new_arg_column}\" IS NULL',\n                )\n            # Base case: this is the first time we've used this particular ingredient\n            # BUT, temp_session_tablename still exists\n            else:\n                distinct_values = select_distinct_fn(\n                    f'SELECT DISTINCT {select_distinct_arg} FROM \"{temp_session_tablename}\"',\n                )\n        else:\n            distinct_values = select_distinct_fn(\n                f'SELECT DISTINCT {select_distinct_arg} FROM \"{value_source_tablename}\"',\n            )\n\n        context_subtables = []\n        if context_was_passed:\n            unpacked_values: list = distinct_values[colname].tolist()\n            context_subtables = [\n                pd.DataFrame(distinct_values[c])\n                for c in distinct_values.columns\n                if c != colname\n            ]\n        else:\n            unpacked_values: list = distinct_values\n\n        # No need to run ingredient if we have no values to map onto\n        if len(unpacked_values) == 0:\n            original_table[new_arg_column] = None\n            return (new_arg_column, tablename, colname, original_table)\n\n        if options is not None:\n            # Override any pattern with our new unpacked options\n            options = self.unpack_options(\n                options=options,\n                aliases_to_tablenames=aliases_to_tablenames,\n            )\n\n        unpacked_questions = None\n        if question is not None:\n            num_braces = question.count(\"{}\")\n            if num_braces &gt; 0:\n                # # Pop off 'context' into question, if there are &gt; 1 '{}'\n                # lists_to_zip = []\n                # for i in range(num_braces - 1):\n                #     lists_to_zip.append(context_subtables[i].values.flatten().tolist())\n                # extra_values_to_insert = list(zip(*lists_to_zip))\n\n                unpacked_questions = [\n                    question.format(value) for value in unpacked_values\n                ]\n\n                # unpacked_questions = [\n                #     question.format(value, *extra_values) for value, extra_values in\n                #     zip(unpacked_values, extra_values_to_insert)\n                # ]\n\n                logger.debug(\n                    Fore.LIGHTBLACK_EX\n                    + f\"Unpacked question to '{unpacked_questions[:10]}'\"\n                    + Fore.RESET\n                )\n\n        mapped_values: Collection[t.Any] = self._run(\n            question=question,\n            unpacked_questions=unpacked_questions,\n            values=unpacked_values,\n            context=context_subtables if len(context_subtables) &gt; 0 else None,\n            options=options,\n            tablename=tablename,\n            colname=colname,\n            **self.__dict__ | kwargs,\n        )\n        self.num_values_passed += len(mapped_values)\n        df_as_dict: t.Dict[str, list] = {colname: [], new_arg_column: []}\n        for value, mapped_value in zip(unpacked_values, mapped_values):\n            df_as_dict[colname].append(value)\n            df_as_dict[new_arg_column].append(mapped_value)\n        mapped_subtable = pd.DataFrame(df_as_dict)\n        if all(\n            isinstance(x, (int, type(None))) and not isinstance(x, bool)\n            for x in mapped_values\n        ):\n            mapped_subtable[new_arg_column] = mapped_subtable[new_arg_column].astype(\n                \"Int64\"\n            )\n        # Add new_table to original table\n        if context_was_passed:\n            _mapped_subtable = distinct_values\n            _mapped_subtable[new_arg_column] = mapped_subtable[new_arg_column]\n            new_table = original_table.merge(\n                _mapped_subtable, how=\"left\", on=[colname] + all_context_colnames\n            )\n        else:\n            new_table = original_table.merge(mapped_subtable, how=\"left\", on=colname)\n        if new_table.shape[0] != original_table.shape[0]:\n            raise IngredientException(\n                f\"subtable from MapIngredient.run() needs same length as # rows from original\\nOriginal has {original_table.shape[0]}, new_table has {new_table.shape[0]}\"\n            )\n        # Now, new table has original columns + column with the name of the question we answered\n        return (new_arg_column, tablename, colname, new_table)\n\n    @abstractmethod\n    def run(self, *args, **kwargs) -&gt; Iterable[t.Any]:\n        ...\n</code></pre>"},{"location":"reference/ingredients/creating-custom-ingredients/#joiningredient","title":"JoinIngredient","text":"<p>               Bases: <code>Ingredient</code></p> <p>Executes an <code>INNER JOIN</code> using dict mapping. 'Join on color of food'</p> <p>Examples:</p> <pre><code>from blendsql.ingredients import JoinIngredient\n\nclass do_join(JoinIngredient):\n    \"\"\"A very silly, overcomplicated way to do a traditional SQL join.\n    But useful for testing.\n    \"\"\"\n\n    def run(self, left_values: List[str], right_values: List[str], **kwargs) -&gt; dict:\n        return {left_value: left_value for left_value in left_values}\n\nblendsql_query = \"\"\"\nSELECT Account, Quantity FROM returns r\nJOIN account_history ah ON {{\n    do_join(\n        left_on=ah.Symbol,\n        right_on=r.Symbol\n    )\n}}\n\"\"\"\n</code></pre> Source code in <code>blendsql/ingredients/ingredient.py</code> <pre><code>@attrs\nclass JoinIngredient(Ingredient):\n    '''Executes an `INNER JOIN` using dict mapping.\n    'Join on color of food'\n    {\"tomato\": \"red\", \"broccoli\": \"green\", \"lemon\": \"yellow\"}\n\n    Examples:\n        ```python\n        from blendsql.ingredients import JoinIngredient\n\n        class do_join(JoinIngredient):\n            \"\"\"A very silly, overcomplicated way to do a traditional SQL join.\n            But useful for testing.\n            \"\"\"\n\n            def run(self, left_values: List[str], right_values: List[str], **kwargs) -&gt; dict:\n                return {left_value: left_value for left_value in left_values}\n\n        blendsql_query = \"\"\"\n        SELECT Account, Quantity FROM returns r\n        JOIN account_history ah ON {{\n            do_join(\n                left_on=ah.Symbol,\n                right_on=r.Symbol\n            )\n        }}\n        \"\"\"\n        ```\n    '''\n\n    use_skrub_joiner: bool = attrib(default=True)\n\n    ingredient_type: str = IngredientType.JOIN.value\n    allowed_output_types: t.Tuple[t.Type] = (dict,)\n\n    def __call__(\n        self,\n        left_on: t.Optional[str] = None,\n        right_on: t.Optional[str] = None,\n        join_criteria: t.Optional[str] = None,\n        *args,\n        **kwargs,\n    ) -&gt; tuple:\n        # Unpack kwargs\n        aliases_to_tablenames: t.Dict[str, str] = kwargs[\"aliases_to_tablenames\"]\n        get_temp_subquery_table: t.Callable = kwargs[\"get_temp_subquery_table\"]\n        get_temp_session_table: t.Callable = kwargs[\"get_temp_session_table\"]\n        # Depending on the size of the underlying data, it may be optimal to swap\n        #   the order of 'left_on' and 'right_on' columns during processing\n        swapped = False\n        values = []\n        original_lr_identifiers = []\n        modified_lr_identifiers = []\n        mapping: t.Dict[str, str] = {}\n        for on_arg in [left_on, right_on]:\n            # Since LLMJoin is unique, in that we need to inject the referenced tablenames back to the query,\n            #   make sure we keep the `referenced_tablename` variable.\n            # So the below works:\n            #     SELECT f.name, colors.name FROM fruits f\n            #     JOIN colors c ON {{LLMJoin(f.name, c.name, join_criteria='Align the fruit to its color')}}\n            referenced_tablename, colname = utils.get_tablename_colname(on_arg)\n            tablename = aliases_to_tablenames.get(\n                referenced_tablename, referenced_tablename\n            )\n            original_lr_identifiers.append((referenced_tablename, colname))\n            tablename, _ = self.maybe_get_temp_table(\n                temp_table_func=get_temp_subquery_table,\n                tablename=tablename,\n            )\n            values.append(\n                self.db.execute_to_list(\n                    f'SELECT DISTINCT \"{colname}\" FROM \"{tablename}\"', to_type=str\n                )\n            )\n            modified_lr_identifiers.append((tablename, colname))\n\n        sorted_values = values\n        swapped = False\n        if join_criteria is None:\n            # Only do order optimization if we haven't passed a custom `join_criteria`\n            sorted_values = sorted(values, key=len)\n            # check swapping only once, at the beginning\n            if sorted_values != values:\n                swapped = True\n            # First, check which values we actually need to call Model on\n            # We don't want to join when there's already an intuitive alignment\n            # First, make sure outer loop is shorter of the two lists\n            outer, inner = sorted_values\n            _outer = []\n            inner = set(inner)\n            mapping = {}\n            for l in outer:\n                if l in inner:\n                    # Define this mapping, and remove from Model inference call\n                    mapping[l] = l\n                    inner.remove(l)\n                else:\n                    _outer.append(l)\n                if len(inner) == 0:\n                    break\n            # Remained _outer and inner lists preserved the sorting order in length:\n            # len(_outer) = len(outer) - #matched &lt;= len(inner original) - matched = len(inner)\n            if self.use_skrub_joiner and all(len(x) &gt; 1 for x in [inner, _outer]):\n                from skrub import Joiner\n\n                # Create the main_table DataFrame\n                main_table = pd.DataFrame(_outer, columns=[\"out\"])\n                # Create the aux_table DataFrame\n                aux_table = pd.DataFrame(inner, columns=[\"in\"])\n                joiner = Joiner(\n                    aux_table,\n                    main_key=\"out\",\n                    aux_key=\"in\",\n                    max_dist=0.9,\n                    add_match_info=False,\n                )\n                res = joiner.fit_transform(main_table)\n                # Below is essentially set.difference on aux_table and those paired in res\n                inner = aux_table.loc[~aux_table[\"in\"].isin(res[\"in\"]), \"in\"].tolist()\n                # length(new inner) = length(inner) - #matched by fuzzy join\n                _outer = res[\"out\"][res[\"in\"].isnull()].to_list()\n                # length(new _outer) = length(_outer) - #matched by fuzzy join\n                _skrub_mapping = (\n                    res.dropna(subset=[\"in\"]).set_index(\"out\")[\"in\"].to_dict()\n                )\n                logger.debug(\n                    Fore.YELLOW\n                    + \"Made the following alignment with `skrub.Joiner`:\"\n                    + Fore.RESET\n                )\n                logger.debug(\n                    Fore.YELLOW + json.dumps(_skrub_mapping, indent=4) + Fore.RESET\n                )\n                mapping = mapping | _skrub_mapping\n            # order by length is still preserved regardless of using fuzzy join, so after initial matching and possible fuzzy join matching\n            # This is because the lengths of each list will decrease at the same rate, so whichever list was larger at the beginning,\n            # will be larger here at the end.\n            # len(_outer) &lt;= len(inner)\n            sorted_values = [_outer, inner]\n\n        # Now, we have our final values to process.\n        left_values, right_values = sorted_values\n        # right_values, left_values = sorted_values\n\n        (left_tablename, left_colname), (\n            right_tablename,\n            right_colname,\n        ) = original_lr_identifiers\n        (_left_tablename, _left_colname), (\n            _right_tablename,\n            _right_colname,\n        ) = modified_lr_identifiers\n\n        if all(len(x) &gt; 0 for x in [left_values, right_values]):\n            # Some alignment still left to do\n            self.num_values_passed += len(left_values) + len(right_values)\n\n            _predicted_mapping: t.Dict[str, str] = self._run(\n                left_values=left_values,\n                right_values=right_values,\n                join_criteria=join_criteria,\n                *args,\n                **self.__dict__ | kwargs,\n            )\n            mapping = mapping | _predicted_mapping\n        # Using mapped left/right values, create intermediary mapping table\n        temp_join_tablename = get_temp_session_table(str(uuid.uuid4())[:4])\n        # Below, we check to see if 'swapped' is True\n        # If so, we need to inverse what is 'left', and what is 'right'\n        joined_values_df = pd.DataFrame(\n            data={\n                \"left\" if not swapped else \"right\": mapping.keys(),\n                \"right\" if not swapped else \"left\": mapping.values(),\n            }\n        )\n        self.db.to_temp_table(df=joined_values_df, tablename=temp_join_tablename)\n        if right_tablename in aliases_to_tablenames:\n            join_right_clause = f\"\"\"JOIN \"{aliases_to_tablenames[right_tablename]}\" AS \"{right_tablename}\" ON \"{right_tablename}\".\"{right_colname}\" = \"{temp_join_tablename}\".right\"\"\"\n        else:\n            join_right_clause = f\"\"\"JOIN \"{right_tablename}\" ON \"{right_tablename}\".\"{right_colname}\" = \"{temp_join_tablename}\".right\"\"\"\n        return (\n            left_tablename,\n            right_tablename,\n            f\"\"\"JOIN \"{temp_join_tablename}\" ON \"{left_tablename}\".\"{left_colname}\" = \"{temp_join_tablename}\".left\\n{join_right_clause}\"\"\",\n            temp_join_tablename,\n        )\n\n    @abstractmethod\n    def run(self, *args, **kwargs) -&gt; dict:\n        ...\n</code></pre>"},{"location":"reference/ingredients/ingredients/","title":"Ingredients","text":"<p>Ingredients are at the core of a BlendSQL script. </p> <p>They are callable functions that perform one the task paradigms defined in ingredient.py.</p> <p>At their core, these are not a new concept. User-defined functions (UDFs), or Application-Defined Functions in SQLite have existed for quite some time. </p> <p>However, ingredients in BlendSQL are intended to be optimized towards LLM-based functions, defining an order of operations for traversing the AST such that the minimal amount of data is passed into your expensive GPT-4/Llama 2/Mistral 7b/etc. prompt.</p> <p>Ingredient calls are denoted by wrapping them in double curly brackets, <code>{{ingredient}}</code>.</p>"},{"location":"reference/models/litellm/","title":"LiteLLM","text":"<p>Environment</p> <p>In order to use this Model, we expect that you have a .env file created with all required API keys.</p> <p>               Bases: <code>UnconstrainedModel</code></p> <p>Class for LiteLLM remote model integration. https://github.com/BerriAI/litellm</p> <p>Parameters:</p> Name Type Description Default <code>model_name_or_path</code> <code>str</code> <p>Name or identifier of the model to use with LiteLLM. Should begin with provider, e.g. <code>openai/gpt-3.5-turbo</code>, <code>gemini/gemini-2.0-flash-exp</code>, <code>anthropic/claude-3-7-sonnet-20250219</code>.</p> required <code>env</code> <code>str</code> <p>Environment path, defaults to current directory (\".\")</p> <code>'.'</code> <code>config</code> <code>Optional[dict]</code> <p>Optional dictionary containing model configuration parameters</p> <code>None</code> <code>caching</code> <code>bool</code> <p>Bool determining whether to enable response caching</p> <code>True</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to the model</p> <code>{}</code> <p>Examples:</p> <pre><code>from blendsql.models import LiteLLM\nmodel = LiteLLM(\"openai/gpt-4o-mini\", config={\"temperature\": 0.7})\n</code></pre> Source code in <code>blendsql/models/unconstrained/litellm.py</code> <pre><code>class LiteLLM(UnconstrainedModel):\n    \"\"\"Class for LiteLLM remote model integration.\n    https://github.com/BerriAI/litellm\n\n    Args:\n        model_name_or_path: Name or identifier of the model to use with LiteLLM.\n            Should begin with provider, e.g. `openai/gpt-3.5-turbo`, `gemini/gemini-2.0-flash-exp`, `anthropic/claude-3-7-sonnet-20250219`.\n        env: Environment path, defaults to current directory (\".\")\n        config: Optional dictionary containing model configuration parameters\n        caching: Bool determining whether to enable response caching\n        **kwargs: Additional keyword arguments to pass to the model\n\n    Examples:\n        ```python\n        from blendsql.models import LiteLLM\n        model = LiteLLM(\"openai/gpt-4o-mini\", config={\"temperature\": 0.7})\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        model_name_or_path: str,\n        env: str = \".\",\n        config: Optional[dict] = None,\n        caching: bool = True,\n        **kwargs,\n    ):\n        if config is None:\n            config = {}\n        super().__init__(\n            model_name_or_path=model_name_or_path,\n            requires_config=False if model_name_or_path.startswith(\"ollama\") else True,\n            config=DEFAULT_CONFIG | config,\n            env=env,\n            caching=caching,\n            **kwargs,\n        )\n        self.model_obj = None\n\n    async def _generate(\n        self,\n        messages_list: List[List[dict]],\n        max_tokens: Optional[int] = None,\n        stop_at: Optional[List[str]] = None,\n        **kwargs,\n    ):\n        sem = Semaphore(int(os.getenv(ASYNC_LIMIT_KEY, DEFAULT_ASYNC_LIMIT)))\n        async with sem:\n            responses = [\n                acompletion(\n                    model=self.model_name_or_path,\n                    messages=messages,\n                    max_tokens=max_tokens,\n                    stop=stop_at,\n                    **self.config,\n                )\n                for messages in messages_list\n            ]\n            return [m for m in await asyncio.gather(*responses)]\n\n    def generate(self, *args, **kwargs) -&gt; List[str]:\n        \"\"\"Handles cache lookup and generation using LiteLLM.\"\"\"\n        responses, key = None, None\n        if self.caching:\n            responses, key = self.check_cache(*args, **kwargs)\n        if responses is None:\n            asyncio.set_event_loop(asyncio.new_event_loop())\n            responses = asyncio.get_event_loop().run_until_complete(\n                self._generate(*args, **kwargs)\n            )  # type: ignore\n            self.num_generation_calls += 1\n        self.prompt_tokens += sum([r.usage.prompt_tokens for r in responses])\n        self.completion_tokens += sum([r.usage.completion_tokens for r in responses])\n        if self.caching:\n            self.cache[key] = responses\n        return [r.choices[0].message.content for r in responses]\n</code></pre>"},{"location":"reference/models/models/","title":"Models","text":"<p>We enable integration with many existing LLMs by building on top of <code>guidance</code> models.</p> <p>Certain models may be better geared towards some BlendSQL tasks than others, so choose carefully!</p>"},{"location":"reference/models/models/#model","title":"<code>Model</code>","text":"<p>Parent class for all BlendSQL Models.</p> Source code in <code>blendsql/models/model.py</code> <pre><code>@attrs\nclass Model:\n    \"\"\"Parent class for all BlendSQL Models.\"\"\"\n\n    model_name_or_path: str = attrib()\n    tokenizer: Any = attrib(default=None)\n    requires_config: bool = attrib(default=False)\n    refresh_interval_min: Optional[int] = attrib(default=None)\n    config: dict = attrib(default=None)\n    env: str = attrib(default=\".\")\n    caching: bool = attrib(default=True)\n\n    model_obj: Generic[ModelObj] = attrib(init=False)\n    prompts: List[dict] = attrib(factory=list)\n    raw_prompts: List[str] = attrib(factory=list)\n    cache: Optional[Cache] = attrib(default=None)\n    run_setup_on_load: bool = attrib(default=True)\n\n    prompt_tokens: int = 0\n    completion_tokens: int = 0\n    num_generation_calls: int = 0\n\n    def __attrs_post_init__(self):\n        self.cache = Cache(\n            Path(platformdirs.user_cache_dir(\"blendsql\"))\n            / f\"{self.model_name_or_path}.diskcache\"\n        )\n        if self.config is None:\n            self.config = {}\n        if self.requires_config:\n            if self.env is None:\n                self.env = \".\"\n            _env = Path(self.env)\n            env_filepath = _env / \".env\" if _env.is_dir() else _env\n            if env_filepath.is_file():\n                load_dotenv(str(env_filepath))\n            else:\n                raise FileNotFoundError(\n                    f\"{self.__class__} requires a .env file to be present at '{env_filepath}' with necessary environment variables\\nPut it somewhere else? Use the `env` argument to point me to the right directory.\"\n                )\n        if self.refresh_interval_min:\n            timer = TokenTimer(\n                init_fn=self._setup, refresh_interval_min=self.refresh_interval_min\n            )\n            timer.start()\n        if self.tokenizer is not None:\n            assert hasattr(self.tokenizer, \"encode\") and callable(\n                self.tokenizer.encode\n            ), f\"`tokenizer` passed to {self.__class__} should have `encode` method!\"\n        if self.run_setup_on_load:\n            self._setup()\n\n    def _create_key(\n        self, *args, funcs: Optional[Sequence[Callable]] = None, **kwargs\n    ) -&gt; str:\n        \"\"\"Generates a hash to use in diskcache Cache.\n        This way, we don't need to send our prompts to the same Model\n        if our context of Model + args + kwargs is the same.\n\n        Returns:\n            md5 hash used as key in diskcache\n        \"\"\"\n        hasher = hashlib.md5()\n        params_str = \"\"\n        if len(kwargs) &gt; 0:\n            params_str += str(sorted([(k, str(v)) for k, v in kwargs.items()]))\n        if len(args) &gt; 0:\n            params_str += str([arg for arg in args])\n        if funcs:\n            params_str += \"\\n\".join([dedent(inspect.getsource(func)) for func in funcs])\n        combined_str = \"{}||{}\".format(\n            f\"{self.model_name_or_path}||{type(self)}\",\n            params_str,\n        ).encode()\n        hasher.update(combined_str)\n        return hasher.hexdigest()\n\n    def check_cache(\n        self, *args, funcs: Optional[Sequence[Callable]] = None, **kwargs\n    ) -&gt; Tuple[Any, str]:\n        response: Dict[str, str] = None  # type: ignore\n        key: str = self._create_key(funcs=funcs, *args, **kwargs)\n        if key in self.cache:\n            logger.debug(Fore.MAGENTA + \"Using model cache...\" + Fore.RESET)\n            response = self.cache.get(key)  # type: ignore\n        return (response, key)\n\n    def reset_stats(self):\n        self.prompt_tokens = 0\n        self.completion_tokens = 0\n        self.num_generation_calls = 0\n\n    @staticmethod\n    def format_prompt(response: str, **kwargs) -&gt; dict:\n        d: Dict[str, Any] = {\"answer\": response}\n        if \"question\" in kwargs:\n            d[\"question\"] = kwargs.get(\"question\")\n        if \"context\" in kwargs:\n            context = kwargs.get(\"context\")\n            if isinstance(context, pd.DataFrame):\n                context = truncate_df_content(context, CONTEXT_TRUNCATION_LIMIT)\n                d[\"context\"] = context.to_dict(orient=\"records\")\n        if \"values\" in kwargs:\n            d[\"values\"] = kwargs.get(\"values\")\n        return d\n\n    @abstractmethod\n    def _setup(self, *args, **kwargs) -&gt; None:\n        \"\"\"Any additional setup required to get this Model up and functioning\n        should go here. For example, in the AzureOpenaiLLM, we have some logic\n        to refresh our client secrets every 30 min.\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def _load_model(self, *args, **kwargs) -&gt; ModelObj:\n        \"\"\"Logic for instantiating the model class goes here.\n        Will most likely be a guidance model object,\n        but in some cases (like OllamaLLM) we make an exception.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"reference/models/transformers/","title":"Transformers","text":"<p>Installation</p> <p>You need to install <code>transformers</code> and <code>torch</code> to use this in blendsql. </p>"},{"location":"reference/models/transformers/#transformersllm","title":"TransformersLLM","text":"<p>               Bases: <code>ConstrainedModel</code></p> <p>Class for Transformers local Model.</p> <p>Parameters:</p> Name Type Description Default <code>model_name_or_path</code> <code>str</code> <p>Name of the model on HuggingFace, or the path to a local model</p> required <code>caching</code> <code>bool</code> <p>Bool determining whether we access the model's cache</p> <code>True</code> <p>Examples:</p> <pre><code>from blendsql.models import TransformersLLM\nmodel = TransformersLLM(\"Qwen/Qwen1.5-0.5B\")\n</code></pre> Source code in <code>blendsql/models/constrained/guidance.py</code> <pre><code>class TransformersLLM(ConstrainedModel):\n    \"\"\"Class for Transformers local Model.\n\n    Args:\n        model_name_or_path: Name of the model on HuggingFace, or the path to a local model\n        caching: Bool determining whether we access the model's cache\n\n    Examples:\n        ```python\n        from blendsql.models import TransformersLLM\n        model = TransformersLLM(\"Qwen/Qwen1.5-0.5B\")\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        model_name_or_path: str,\n        config: Optional[dict] = None,\n        caching: bool = True,\n        **kwargs,\n    ):\n        import transformers\n\n        transformers.logging.set_verbosity_error()\n        if config is None:\n            config = {}\n\n        super().__init__(\n            model_name_or_path=model_name_or_path,\n            requires_config=False,\n            tokenizer=transformers.AutoTokenizer.from_pretrained(model_name_or_path),\n            config=DEFAULT_KWARGS | config,\n            caching=caching,\n            **kwargs,\n        )\n\n    def _load_model(self) -&gt; ModelObj:\n        # https://huggingface.co/blog/how-to-generate\n        # from guidance.models._transformers import Transformers\n        from guidance.models import Transformers\n\n        lm = Transformers(\n            self.model_name_or_path,\n            echo=False,\n            device_map=self.config.pop(\"device_map\", None),\n            **self.config,\n        )\n        # Try to infer if we're in chat mode\n        if lm.engine.tokenizer._orig_tokenizer.chat_template is None:\n            logger.debug(\n                Fore.YELLOW\n                + \"chat_template not found in tokenizer config.\\nBlendSQL currently only works with chat models\"\n                + Fore.RESET\n            )\n        return lm\n</code></pre>"}]}